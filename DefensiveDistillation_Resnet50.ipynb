{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DefensiveDistillation_Resnet50.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7I+geWdhOjuEBrivPrLgv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirath2205/Final-Year-Project/blob/main/DefensiveDistillation_Resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "WbPD7Y3J67a_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPYPzHr-8SfZ",
        "outputId": "a4d8345d-df32-4efc-a584-df987b67a631"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: Keras-applications in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras-applications) (1.19.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras-applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras-applications) (1.15.0)\n",
            "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D , UpSampling3D\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.datasets import cifar100,cifar10,fashion_mnist\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.transform import resize\n",
        "from keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50 , preprocess_input , decode_predictions\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "Fg23Z7qO8WxD"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "def select_dataset(index=1): #1 for cifar10 , 2 for cifar100 , 3 for fashion mnist\n",
        "  if(index == 1):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    channel = 3\n",
        "    num_classes = 10\n",
        "    model = keras.models.load_model('desktop/Trained_models/resnet50_cifar10.h5')\n",
        "  if(index == 2):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "    num_classes = 100\n",
        "    channel = 3\n",
        "    model = keras.models.load_model('desktop/Trained_models/resnet50_cifar100.h5')\n",
        "  if(index == 3):\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "    x_train = x_train.reshape((60000, 28, 28, 1))\n",
        "    x_test =  x_test.reshape((10000, 28, 28, 1))\n",
        "    num_classes = 10\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "    channel = 1\n",
        "    model = keras.models.load_model('desktop/Trained_models/resnet50_mnist.h5')\n",
        "    return (x_train , y_train , x_test , y_test , num_classes , channel)\n",
        "\n",
        "  #Pre-process the data\n",
        "  x_train = preprocess_input(x_train)\n",
        "  x_test = preprocess_input(x_test)\n",
        "  y_train_temp = []\n",
        "\n",
        "  datagen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
        "  datagen.fit(x_train)\n",
        "  for image_index in range(len(x_train)):\n",
        "    image = x_train[image_index]\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape(1, 32, 32, 3)\n",
        "    y_train_temp.append(model.predict(image))\n",
        "  '''for image_index in range(len(x_test)):\n",
        "    image = x_test[image_index]\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape(1, 32, 32, 3)\n",
        "    y_test_temp.append(model.predict(image))'''\n",
        "  y_train = np.asarray(y_train_temp, dtype=np.float32)\n",
        "  #y_test = np.asarray(y_test_temp, dtype=np.float32)\n",
        "  #y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "  y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "  return (x_train , y_train , x_test , y_test , num_classes , channel , datagen)"
      ],
      "metadata": {
        "id": "-XbKi7eq8ZkV"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Resnet50(num_classes , channel=3):\n",
        "  if(channel == 3):\n",
        "    resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "  else:\n",
        "    resnet_model = ResNet50(weights='imagenet', input_shape=(196,196,3),include_top=False)\n",
        "\n",
        "  for layer in resnet_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "      layer.trainable = True\n",
        "    else:\n",
        "      layer.trainable = False\n",
        "  model = Sequential()\n",
        "  if(channel==1):\n",
        "    model.add(UpSampling3D((7,7,3)))\n",
        "  else:\n",
        "    model.add(UpSampling2D((7,7)))\n",
        "  model.add(resnet_model)\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "  if(channel==3):\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(.25))\n",
        "    model.add(BatchNormalization())\n",
        "  else:\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dropout(.1))\n",
        "  \n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "Uj7-kdaQ8cEU"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "x_train , y_train , x_test , y_test , num_classes ,channel , datagen = select_dataset(index)\n",
        "model = Resnet50(num_classes,channel)\n",
        "y_train = np.squeeze(y_train)\n",
        "#y_test = np.squeeze(y_test)\n",
        "model_name = 'desktop/Trained_models/defensive_distillation_resnet50_cifar10'\n",
        "model_path = 'desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5'\n"
      ],
      "metadata": {
        "id": "oysPpPgH8d_j"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 2\n",
        "x_train , y_train , x_test , y_test , num_classes ,channel , datagen = select_dataset(index)\n",
        "model = Resnet50(num_classes,channel)\n",
        "model_name = 'desktop/Trained_models/defensive_distillation_resnet50_cifar100'\n",
        "model_path = 'desktop/Trained_models/defensive_distillation_resnet50_cifar100.h5'"
      ],
      "metadata": {
        "id": "gzxMXZjt8gpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 3\n",
        "x_train , y_train , x_test , y_test , num_classes ,channel  = select_dataset(index)\n",
        "model = Resnet50(num_classes,channel)\n",
        "model_name = 'desktop/Trained_models/defensive_distillation_resnet50_mnist'\n",
        "model_path = 'desktop/Trained_models/defensive_distillation_resnet50_mnist.h5'"
      ],
      "metadata": {
        "id": "aP1HLxfr8iiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128 # 256 for mnist , 128 for cifar-10 , 64 for cifar-100\n",
        "epochs = 100\n",
        "callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.7, patience = 7, min_lr = 0.000001, verbose = 1 ), #patience = 7 and 20 for cifar-100 , patience = 5 and 10 for cifar-10\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy' , patience = 20)\n",
        "  ]\n",
        "if(channel == 3):\n",
        "  history = model.fit(x_train , y_train , batch_size=batch_size,steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,validation_data=(x_test, y_test),callbacks=callbacks)\n",
        "  '''history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                                  steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                                  epochs=epochs,\n",
        "                                  validation_data=(x_test, y_test),\n",
        "                                  callbacks = callbacks)'''\n",
        "                        \n",
        "\n",
        "  model.save(model_path)\n",
        "else:\n",
        "  history = model.fit(x_train , y_train , batch_size=batch_size ,steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs, validation_data=(x_test, y_test),callbacks=callbacks)\n",
        "  #model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4adFHrL_2A1",
        "outputId": "82a8742e-2858-4c28-e6c7-5846d792ce30"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.8359\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88610, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 162s 416ms/step - loss: 0.4838 - accuracy: 0.8359 - val_loss: 0.3304 - val_accuracy: 0.8861 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9214\n",
            "Epoch 00002: val_accuracy improved from 0.88610 to 0.92860, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 163s 419ms/step - loss: 0.2324 - accuracy: 0.9214 - val_loss: 0.2098 - val_accuracy: 0.9286 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.9437\n",
            "Epoch 00003: val_accuracy improved from 0.92860 to 0.92920, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 421ms/step - loss: 0.1649 - accuracy: 0.9437 - val_loss: 0.2190 - val_accuracy: 0.9292 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9569\n",
            "Epoch 00004: val_accuracy improved from 0.92920 to 0.93610, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 421ms/step - loss: 0.1272 - accuracy: 0.9569 - val_loss: 0.2007 - val_accuracy: 0.9361 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9655\n",
            "Epoch 00005: val_accuracy improved from 0.93610 to 0.93760, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 420ms/step - loss: 0.1010 - accuracy: 0.9655 - val_loss: 0.1883 - val_accuracy: 0.9376 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9730\n",
            "Epoch 00006: val_accuracy improved from 0.93760 to 0.93800, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 419ms/step - loss: 0.0819 - accuracy: 0.9730 - val_loss: 0.1928 - val_accuracy: 0.9380 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9774\n",
            "Epoch 00007: val_accuracy improved from 0.93800 to 0.93860, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 163s 419ms/step - loss: 0.0660 - accuracy: 0.9774 - val_loss: 0.2047 - val_accuracy: 0.9386 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9808\n",
            "Epoch 00008: val_accuracy did not improve from 0.93860\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0580 - accuracy: 0.9808 - val_loss: 0.2120 - val_accuracy: 0.9382 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9850\n",
            "Epoch 00009: val_accuracy improved from 0.93860 to 0.93910, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 420ms/step - loss: 0.0478 - accuracy: 0.9850 - val_loss: 0.2190 - val_accuracy: 0.9391 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9869\n",
            "Epoch 00010: val_accuracy improved from 0.93910 to 0.94160, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 420ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.2291 - val_accuracy: 0.9416 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9870\n",
            "Epoch 00011: val_accuracy did not improve from 0.94160\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.2340 - val_accuracy: 0.9411 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9887\n",
            "Epoch 00012: val_accuracy improved from 0.94160 to 0.94210, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
            "390/390 [==============================] - 164s 420ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.2355 - val_accuracy: 0.9421 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9927\n",
            "Epoch 00013: val_accuracy improved from 0.94210 to 0.94330, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 419ms/step - loss: 0.0263 - accuracy: 0.9927 - val_loss: 0.2206 - val_accuracy: 0.9433 - lr: 7.0000e-04\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9949\n",
            "Epoch 00014: val_accuracy improved from 0.94330 to 0.94590, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 163s 419ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.2278 - val_accuracy: 0.9459 - lr: 7.0000e-04\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9960\n",
            "Epoch 00015: val_accuracy did not improve from 0.94590\n",
            "390/390 [==============================] - 163s 419ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 0.2467 - val_accuracy: 0.9435 - lr: 7.0000e-04\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9951\n",
            "Epoch 00016: val_accuracy did not improve from 0.94590\n",
            "390/390 [==============================] - 163s 419ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.2428 - val_accuracy: 0.9451 - lr: 7.0000e-04\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9959\n",
            "Epoch 00017: val_accuracy improved from 0.94590 to 0.94620, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 420ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.2350 - val_accuracy: 0.9462 - lr: 7.0000e-04\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9957\n",
            "Epoch 00018: val_accuracy did not improve from 0.94620\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.2448 - val_accuracy: 0.9431 - lr: 7.0000e-04\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9956\n",
            "Epoch 00019: val_accuracy did not improve from 0.94620\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.2456 - val_accuracy: 0.9453 - lr: 7.0000e-04\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9967\n",
            "Epoch 00020: val_accuracy did not improve from 0.94620\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.2425 - val_accuracy: 0.9461 - lr: 4.9000e-04\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9974\n",
            "Epoch 00021: val_accuracy improved from 0.94620 to 0.94690, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 419ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.2509 - val_accuracy: 0.9469 - lr: 4.9000e-04\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9976\n",
            "Epoch 00022: val_accuracy improved from 0.94690 to 0.94720, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 419ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.2424 - val_accuracy: 0.9472 - lr: 4.9000e-04\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9976\n",
            "Epoch 00023: val_accuracy improved from 0.94720 to 0.94730, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 420ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.2511 - val_accuracy: 0.9473 - lr: 4.9000e-04\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9981\n",
            "Epoch 00024: val_accuracy did not improve from 0.94730\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 0.2455 - val_accuracy: 0.9461 - lr: 4.9000e-04\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9978\n",
            "Epoch 00025: val_accuracy did not improve from 0.94730\n",
            "390/390 [==============================] - 163s 419ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.2659 - val_accuracy: 0.9445 - lr: 4.9000e-04\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9980\n",
            "Epoch 00026: val_accuracy did not improve from 0.94730\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 0.2526 - val_accuracy: 0.9471 - lr: 4.9000e-04\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9985\n",
            "Epoch 00027: val_accuracy improved from 0.94730 to 0.94850, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 419ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.2541 - val_accuracy: 0.9485 - lr: 3.4300e-04\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9989\n",
            "Epoch 00028: val_accuracy improved from 0.94850 to 0.94870, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 419ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.2587 - val_accuracy: 0.9487 - lr: 3.4300e-04\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9990\n",
            "Epoch 00029: val_accuracy improved from 0.94870 to 0.95080, saving model to desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5\n",
            "390/390 [==============================] - 164s 419ms/step - loss: 0.0092 - accuracy: 0.9990 - val_loss: 0.2499 - val_accuracy: 0.9508 - lr: 3.4300e-04\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9989\n",
            "Epoch 00030: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.2514 - val_accuracy: 0.9479 - lr: 3.4300e-04\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9993\n",
            "Epoch 00031: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 0.2449 - val_accuracy: 0.9498 - lr: 3.4300e-04\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9991\n",
            "Epoch 00032: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.2615 - val_accuracy: 0.9491 - lr: 3.4300e-04\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9992\n",
            "Epoch 00033: val_accuracy did not improve from 0.95080\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.2536 - val_accuracy: 0.9482 - lr: 3.4300e-04\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9992\n",
            "Epoch 00034: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.2476 - val_accuracy: 0.9503 - lr: 2.4010e-04\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9991\n",
            "Epoch 00035: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 0.2520 - val_accuracy: 0.9499 - lr: 2.4010e-04\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9995\n",
            "Epoch 00036: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.2490 - val_accuracy: 0.9500 - lr: 2.4010e-04\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9995\n",
            "Epoch 00037: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.2457 - val_accuracy: 0.9508 - lr: 2.4010e-04\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9993\n",
            "Epoch 00038: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.2571 - val_accuracy: 0.9495 - lr: 2.4010e-04\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9994\n",
            "Epoch 00039: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.2524 - val_accuracy: 0.9503 - lr: 2.4010e-04\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9995\n",
            "Epoch 00040: val_accuracy did not improve from 0.95080\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.2547 - val_accuracy: 0.9495 - lr: 2.4010e-04\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9996\n",
            "Epoch 00041: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.2554 - val_accuracy: 0.9500 - lr: 1.6807e-04\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9996\n",
            "Epoch 00042: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.2568 - val_accuracy: 0.9480 - lr: 1.6807e-04\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9996\n",
            "Epoch 00043: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.2569 - val_accuracy: 0.9499 - lr: 1.6807e-04\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9996\n",
            "Epoch 00044: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 419ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.2551 - val_accuracy: 0.9496 - lr: 1.6807e-04\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9996\n",
            "Epoch 00045: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.2499 - val_accuracy: 0.9492 - lr: 1.6807e-04\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9996\n",
            "Epoch 00046: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0071 - accuracy: 0.9996 - val_loss: 0.2471 - val_accuracy: 0.9497 - lr: 1.6807e-04\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9997\n",
            "Epoch 00047: val_accuracy did not improve from 0.95080\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.2463 - val_accuracy: 0.9501 - lr: 1.6807e-04\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9997\n",
            "Epoch 00048: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 418ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.2487 - val_accuracy: 0.9497 - lr: 1.1765e-04\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9996\n",
            "Epoch 00049: val_accuracy did not improve from 0.95080\n",
            "390/390 [==============================] - 163s 419ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.2497 - val_accuracy: 0.9496 - lr: 1.1765e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(history.history['val_loss'],label='Test loss')\n",
        "plt.plot(history.history['loss'],label='Train loss')\n",
        "plt.title('Loss curve for resnet model')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(history.history['val_accuracy'],label = 'Test accuracy')\n",
        "plt.plot(history.history['accuracy'],label = 'Train accuracy')\n",
        "plt.title('Accuracy curve for resnet model')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "_sfkqzR0_3xa",
        "outputId": "8fd25304-d999-4ab1-bbbe-43b77a0ff62f"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras,os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D , Dropout\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50 , preprocess_input\n",
        "from keras import regularizers\n",
        "from absl import app, flags\n",
        "\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
        "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge4CAyRnCKnE",
        "outputId": "42e4f523-1e6d-4e81-abe2-0119b90f5f73"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: cleverhans from git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans in ./.local/lib/python3.6/site-packages (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: easydict in ./.local/lib/python3.6/site-packages (from cleverhans) (1.9)\n",
            "Requirement already satisfied: nose in ./.local/lib/python3.6/site-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-probability in ./.local/lib/python3.6/site-packages (from cleverhans) (0.14.1)\n",
            "Requirement already satisfied: joblib in ./.local/lib/python3.6/site-packages (from cleverhans) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.3.1)\n",
            "Requirement already satisfied: mnist in ./.local/lib/python3.6/site-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: pycodestyle in ./.local/lib/python3.6/site-packages (from cleverhans) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.19.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.15.0)\n",
            "Requirement already satisfied: decorator in ./.local/lib/python3.6/site-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in ./.local/lib/python3.6/site-packages (from tensorflow-probability->cleverhans) (0.1.6)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in ./.local/lib/python3.6/site-packages (from tensorflow-probability->cleverhans) (2.0.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (7.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k8W9Tz30FXXY"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bSMPybB5Ffgt"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def make_prediction(model , image , true_value):\n",
        "  true_label_index = -1\n",
        "  for i in range(len(true_value)):\n",
        "\n",
        "    if(true_value[i]==1):\n",
        "      true_label_index = i\n",
        "      break\n",
        "\n",
        "  prediction = model.predict(image)[0]\n",
        "  probability = float('-inf')\n",
        "  predicted_label_index = -1\n",
        "\n",
        "  for i in range(len(prediction)):\n",
        "\n",
        "    if(prediction[i]>probability):\n",
        "      probability = prediction[i]\n",
        "      predicted_label_index = i\n",
        "\n",
        "  if(true_label_index!=predicted_label_index):\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "model = keras.models.load_model('desktop/Trained_models/defensive_distillation_resnet50_cifar10.h5')"
      ],
      "metadata": {
        "id": "BcT_8FJPCTVh"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "epsilon_end = 0.8\n",
        "#logits_model = tf.keras.Model(model.input,model.layers[-1].output)\n",
        "total_images = 200\n",
        "\n",
        "result={}\n",
        "epsilon = 0.1\n",
        "while(epsilon <= epsilon_end):\n",
        "\n",
        "  fgsm_counter = 0\n",
        "  pgd_counter = 0\n",
        "  print(\"Epsilon value - \",epsilon)\n",
        "  print()\n",
        "  for image_index in range(total_images):\n",
        "  \n",
        "  \n",
        "    image = x_test[image_index]\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape(1, 32, 32, 3)\n",
        "    true_value = y_test[image_index]\n",
        "    original_prediction = make_prediction(model,image,true_value)\n",
        "    fgsm_sample = fast_gradient_method(model, image, epsilon, np.inf, targeted=False)\n",
        "    pgd_sample = projected_gradient_descent(model, image, epsilon, 0.01, 40, np.inf)\n",
        "    print(epsilon,' ',image_index)\n",
        "    fgsm_prediction = make_prediction(model , fgsm_sample , true_value)\n",
        "    pgd_prediction = make_prediction(model , pgd_sample , true_value)\n",
        "    pgd_counter+=pgd_prediction\n",
        "    fgsm_counter+=fgsm_prediction\n",
        "    print(pgd_counter,' ',fgsm_counter)\n",
        "  result[epsilon] = (fgsm_counter , pgd_counter)\n",
        "  epsilon+=0.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGLZqcm1CWTi",
        "outputId": "15644652-8730-4bf0-c2b5-cf30767947fd"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epsilon value -  0.1\n",
            "\n",
            "0.1   0\n",
            "0   0\n",
            "0.1   1\n",
            "0   0\n",
            "0.1   2\n",
            "0   0\n",
            "0.1   3\n",
            "0   0\n",
            "0.1   4\n",
            "0   0\n",
            "0.1   5\n",
            "0   0\n",
            "0.1   6\n",
            "0   0\n",
            "0.1   7\n",
            "0   0\n",
            "0.1   8\n",
            "0   0\n",
            "0.1   9\n",
            "0   0\n",
            "0.1   10\n",
            "1   1\n",
            "0.1   11\n",
            "1   1\n",
            "0.1   12\n",
            "2   2\n",
            "0.1   13\n",
            "2   2\n",
            "0.1   14\n",
            "2   2\n",
            "0.1   15\n",
            "2   2\n",
            "0.1   16\n",
            "2   2\n",
            "0.1   17\n",
            "2   2\n",
            "0.1   18\n",
            "2   2\n",
            "0.1   19\n",
            "2   2\n",
            "0.1   20\n",
            "2   2\n",
            "0.1   21\n",
            "2   2\n",
            "0.1   22\n",
            "2   2\n",
            "0.1   23\n",
            "2   2\n",
            "0.1   24\n",
            "2   2\n",
            "0.1   25\n",
            "2   2\n",
            "0.1   26\n",
            "3   3\n",
            "0.1   27\n",
            "3   3\n",
            "0.1   28\n",
            "3   3\n",
            "0.1   29\n",
            "3   3\n",
            "0.1   30\n",
            "3   3\n",
            "0.1   31\n",
            "3   3\n",
            "0.1   32\n",
            "3   3\n",
            "0.1   33\n",
            "4   3\n",
            "0.1   34\n",
            "4   3\n",
            "0.1   35\n",
            "5   4\n",
            "0.1   36\n",
            "5   4\n",
            "0.1   37\n",
            "5   4\n",
            "0.1   38\n",
            "5   4\n",
            "0.1   39\n",
            "5   4\n",
            "0.1   40\n",
            "5   4\n",
            "0.1   41\n",
            "5   4\n",
            "0.1   42\n",
            "5   4\n",
            "0.1   43\n",
            "5   4\n",
            "0.1   44\n",
            "5   4\n",
            "0.1   45\n",
            "5   4\n",
            "0.1   46\n",
            "5   4\n",
            "0.1   47\n",
            "6   5\n",
            "0.1   48\n",
            "6   5\n",
            "0.1   49\n",
            "6   5\n",
            "0.1   50\n",
            "6   5\n",
            "0.1   51\n",
            "6   5\n",
            "0.1   52\n",
            "7   6\n",
            "0.1   53\n",
            "7   6\n",
            "0.1   54\n",
            "7   6\n",
            "0.1   55\n",
            "7   6\n",
            "0.1   56\n",
            "7   6\n",
            "0.1   57\n",
            "7   6\n",
            "0.1   58\n",
            "7   6\n",
            "0.1   59\n",
            "8   7\n",
            "0.1   60\n",
            "8   7\n",
            "0.1   61\n",
            "8   7\n",
            "0.1   62\n",
            "8   7\n",
            "0.1   63\n",
            "8   7\n",
            "0.1   64\n",
            "8   7\n",
            "0.1   65\n",
            "8   7\n",
            "0.1   66\n",
            "8   7\n",
            "0.1   67\n",
            "8   7\n",
            "0.1   68\n",
            "9   7\n",
            "0.1   69\n",
            "9   7\n",
            "0.1   70\n",
            "9   7\n",
            "0.1   71\n",
            "9   7\n",
            "0.1   72\n",
            "9   7\n",
            "0.1   73\n",
            "9   7\n",
            "0.1   74\n",
            "9   7\n",
            "0.1   75\n",
            "9   7\n",
            "0.1   76\n",
            "9   7\n",
            "0.1   77\n",
            "9   7\n",
            "0.1   78\n",
            "10   8\n",
            "0.1   79\n",
            "10   8\n",
            "0.1   80\n",
            "10   8\n",
            "0.1   81\n",
            "10   8\n",
            "0.1   82\n",
            "10   8\n",
            "0.1   83\n",
            "10   8\n",
            "0.1   84\n",
            "11   8\n",
            "0.1   85\n",
            "11   8\n",
            "0.1   86\n",
            "12   9\n",
            "0.1   87\n",
            "13   10\n",
            "0.1   88\n",
            "13   10\n",
            "0.1   89\n",
            "13   10\n",
            "0.1   90\n",
            "13   10\n",
            "0.1   91\n",
            "13   10\n",
            "0.1   92\n",
            "13   10\n",
            "0.1   93\n",
            "13   10\n",
            "0.1   94\n",
            "13   10\n",
            "0.1   95\n",
            "13   10\n",
            "0.1   96\n",
            "13   10\n",
            "0.1   97\n",
            "14   11\n",
            "0.1   98\n",
            "14   11\n",
            "0.1   99\n",
            "14   11\n",
            "0.1   100\n",
            "14   11\n",
            "0.1   101\n",
            "14   11\n",
            "0.1   102\n",
            "14   11\n",
            "0.1   103\n",
            "14   11\n",
            "0.1   104\n",
            "14   11\n",
            "0.1   105\n",
            "14   11\n",
            "0.1   106\n",
            "14   11\n",
            "0.1   107\n",
            "14   11\n",
            "0.1   108\n",
            "14   11\n",
            "0.1   109\n",
            "14   11\n",
            "0.1   110\n",
            "14   11\n",
            "0.1   111\n",
            "14   11\n",
            "0.1   112\n",
            "15   12\n",
            "0.1   113\n",
            "16   13\n",
            "0.1   114\n",
            "16   13\n",
            "0.1   115\n",
            "16   13\n",
            "0.1   116\n",
            "16   13\n",
            "0.1   117\n",
            "16   13\n",
            "0.1   118\n",
            "17   13\n",
            "0.1   119\n",
            "17   13\n",
            "0.1   120\n",
            "17   13\n",
            "0.1   121\n",
            "18   13\n",
            "0.1   122\n",
            "18   13\n",
            "0.1   123\n",
            "18   13\n",
            "0.1   124\n",
            "18   13\n",
            "0.1   125\n",
            "19   14\n",
            "0.1   126\n",
            "19   14\n",
            "0.1   127\n",
            "19   14\n",
            "0.1   128\n",
            "20   15\n",
            "0.1   129\n",
            "20   15\n",
            "0.1   130\n",
            "20   15\n",
            "0.1   131\n",
            "20   15\n",
            "0.1   132\n",
            "20   15\n",
            "0.1   133\n",
            "20   15\n",
            "0.1   134\n",
            "20   15\n",
            "0.1   135\n",
            "20   15\n",
            "0.1   136\n",
            "20   15\n",
            "0.1   137\n",
            "20   15\n",
            "0.1   138\n",
            "20   15\n",
            "0.1   139\n",
            "21   16\n",
            "0.1   140\n",
            "21   16\n",
            "0.1   141\n",
            "21   16\n",
            "0.1   142\n",
            "21   16\n",
            "0.1   143\n",
            "21   16\n",
            "0.1   144\n",
            "21   16\n",
            "0.1   145\n",
            "21   16\n",
            "0.1   146\n",
            "21   16\n",
            "0.1   147\n",
            "22   17\n",
            "0.1   148\n",
            "23   18\n",
            "0.1   149\n",
            "23   18\n",
            "0.1   150\n",
            "23   18\n",
            "0.1   151\n",
            "23   18\n",
            "0.1   152\n",
            "23   18\n",
            "0.1   153\n",
            "23   18\n",
            "0.1   154\n",
            "23   18\n",
            "0.1   155\n",
            "23   18\n",
            "0.1   156\n",
            "23   18\n",
            "0.1   157\n",
            "23   18\n",
            "0.1   158\n",
            "23   18\n",
            "0.1   159\n",
            "23   18\n",
            "0.1   160\n",
            "24   19\n",
            "0.1   161\n",
            "24   19\n",
            "0.1   162\n",
            "24   19\n",
            "0.1   163\n",
            "24   19\n",
            "0.1   164\n",
            "25   20\n",
            "0.1   165\n",
            "26   21\n",
            "0.1   166\n",
            "26   21\n",
            "0.1   167\n",
            "26   21\n",
            "0.1   168\n",
            "26   21\n",
            "0.1   169\n",
            "27   21\n",
            "0.1   170\n",
            "27   21\n",
            "0.1   171\n",
            "28   22\n",
            "0.1   172\n",
            "28   22\n",
            "0.1   173\n",
            "28   22\n",
            "0.1   174\n",
            "28   22\n",
            "0.1   175\n",
            "28   22\n",
            "0.1   176\n",
            "28   22\n",
            "0.1   177\n",
            "28   22\n",
            "0.1   178\n",
            "28   22\n",
            "0.1   179\n",
            "28   22\n",
            "0.1   180\n",
            "28   22\n",
            "0.1   181\n",
            "28   22\n",
            "0.1   182\n",
            "28   22\n",
            "0.1   183\n",
            "29   23\n",
            "0.1   184\n",
            "29   23\n",
            "0.1   185\n",
            "29   23\n",
            "0.1   186\n",
            "29   23\n",
            "0.1   187\n",
            "29   23\n",
            "0.1   188\n",
            "29   23\n",
            "0.1   189\n",
            "29   23\n",
            "0.1   190\n",
            "29   23\n",
            "0.1   191\n",
            "29   23\n",
            "0.1   192\n",
            "30   24\n",
            "0.1   193\n",
            "30   24\n",
            "0.1   194\n",
            "30   24\n",
            "0.1   195\n",
            "30   24\n",
            "0.1   196\n",
            "30   24\n",
            "0.1   197\n",
            "30   24\n",
            "0.1   198\n",
            "30   24\n",
            "0.1   199\n",
            "30   24\n",
            "Epsilon value -  0.2\n",
            "\n",
            "0.2   0\n",
            "0   0\n",
            "0.2   1\n",
            "0   0\n",
            "0.2   2\n",
            "1   0\n",
            "0.2   3\n",
            "2   0\n",
            "0.2   4\n",
            "2   0\n",
            "0.2   5\n",
            "2   0\n",
            "0.2   6\n",
            "3   1\n",
            "0.2   7\n",
            "3   1\n",
            "0.2   8\n",
            "3   1\n",
            "0.2   9\n",
            "3   1\n",
            "0.2   10\n",
            "4   2\n",
            "0.2   11\n",
            "4   2\n",
            "0.2   12\n",
            "5   3\n",
            "0.2   13\n",
            "5   3\n",
            "0.2   14\n",
            "5   3\n",
            "0.2   15\n",
            "6   4\n",
            "0.2   16\n",
            "6   4\n",
            "0.2   17\n",
            "6   4\n",
            "0.2   18\n",
            "6   4\n",
            "0.2   19\n",
            "6   4\n",
            "0.2   20\n",
            "7   5\n",
            "0.2   21\n",
            "8   5\n",
            "0.2   22\n",
            "9   5\n",
            "0.2   23\n",
            "9   5\n",
            "0.2   24\n",
            "9   5\n",
            "0.2   25\n",
            "10   6\n",
            "0.2   26\n",
            "11   7\n",
            "0.2   27\n",
            "12   7\n",
            "0.2   28\n",
            "12   7\n",
            "0.2   29\n",
            "12   7\n",
            "0.2   30\n",
            "12   7\n",
            "0.2   31\n",
            "12   7\n",
            "0.2   32\n",
            "12   7\n",
            "0.2   33\n",
            "13   8\n",
            "0.2   34\n",
            "13   8\n",
            "0.2   35\n",
            "14   9\n",
            "0.2   36\n",
            "14   9\n",
            "0.2   37\n",
            "14   9\n",
            "0.2   38\n",
            "14   9\n",
            "0.2   39\n",
            "14   9\n",
            "0.2   40\n",
            "15   9\n",
            "0.2   41\n",
            "15   9\n",
            "0.2   42\n",
            "15   9\n",
            "0.2   43\n",
            "15   9\n",
            "0.2   44\n",
            "15   9\n",
            "0.2   45\n",
            "15   9\n",
            "0.2   46\n",
            "15   9\n",
            "0.2   47\n",
            "16   10\n",
            "0.2   48\n",
            "16   10\n",
            "0.2   49\n",
            "17   11\n",
            "0.2   50\n",
            "17   11\n",
            "0.2   51\n",
            "17   11\n",
            "0.2   52\n",
            "18   12\n",
            "0.2   53\n",
            "18   12\n",
            "0.2   54\n",
            "18   12\n",
            "0.2   55\n",
            "19   12\n",
            "0.2   56\n",
            "19   12\n",
            "0.2   57\n",
            "20   12\n",
            "0.2   58\n",
            "20   12\n",
            "0.2   59\n",
            "21   13\n",
            "0.2   60\n",
            "21   13\n",
            "0.2   61\n",
            "21   13\n",
            "0.2   62\n",
            "22   13\n",
            "0.2   63\n",
            "22   13\n",
            "0.2   64\n",
            "22   13\n",
            "0.2   65\n",
            "22   13\n",
            "0.2   66\n",
            "22   13\n",
            "0.2   67\n",
            "22   13\n",
            "0.2   68\n",
            "23   14\n",
            "0.2   69\n",
            "23   14\n",
            "0.2   70\n",
            "24   15\n",
            "0.2   71\n",
            "24   15\n",
            "0.2   72\n",
            "25   15\n",
            "0.2   73\n",
            "25   15\n",
            "0.2   74\n",
            "26   15\n",
            "0.2   75\n",
            "26   15\n",
            "0.2   76\n",
            "27   15\n",
            "0.2   77\n",
            "27   15\n",
            "0.2   78\n",
            "28   16\n",
            "0.2   79\n",
            "29   16\n",
            "0.2   80\n",
            "29   16\n",
            "0.2   81\n",
            "30   16\n",
            "0.2   82\n",
            "30   16\n",
            "0.2   83\n",
            "30   16\n",
            "0.2   84\n",
            "31   17\n",
            "0.2   85\n",
            "32   18\n",
            "0.2   86\n",
            "33   19\n",
            "0.2   87\n",
            "34   20\n",
            "0.2   88\n",
            "35   20\n",
            "0.2   89\n",
            "35   20\n",
            "0.2   90\n",
            "36   20\n",
            "0.2   91\n",
            "36   20\n",
            "0.2   92\n",
            "37   20\n",
            "0.2   93\n",
            "37   20\n",
            "0.2   94\n",
            "37   20\n",
            "0.2   95\n",
            "38   21\n",
            "0.2   96\n",
            "38   21\n",
            "0.2   97\n",
            "39   22\n",
            "0.2   98\n",
            "39   22\n",
            "0.2   99\n",
            "39   22\n",
            "0.2   100\n",
            "39   22\n",
            "0.2   101\n",
            "39   22\n",
            "0.2   102\n",
            "40   22\n",
            "0.2   103\n",
            "40   22\n",
            "0.2   104\n",
            "40   22\n",
            "0.2   105\n",
            "40   22\n",
            "0.2   106\n",
            "40   22\n",
            "0.2   107\n",
            "40   22\n",
            "0.2   108\n",
            "40   22\n",
            "0.2   109\n",
            "40   22\n",
            "0.2   110\n",
            "40   22\n",
            "0.2   111\n",
            "40   22\n",
            "0.2   112\n",
            "41   23\n",
            "0.2   113\n",
            "42   24\n",
            "0.2   114\n",
            "42   24\n",
            "0.2   115\n",
            "43   24\n",
            "0.2   116\n",
            "43   24\n",
            "0.2   117\n",
            "44   25\n",
            "0.2   118\n",
            "45   26\n",
            "0.2   119\n",
            "45   26\n",
            "0.2   120\n",
            "45   26\n",
            "0.2   121\n",
            "46   27\n",
            "0.2   122\n",
            "46   27\n",
            "0.2   123\n",
            "46   27\n",
            "0.2   124\n",
            "46   27\n",
            "0.2   125\n",
            "47   28\n",
            "0.2   126\n",
            "47   28\n",
            "0.2   127\n",
            "48   29\n",
            "0.2   128\n",
            "49   30\n",
            "0.2   129\n",
            "50   31\n",
            "0.2   130\n",
            "51   32\n",
            "0.2   131\n",
            "51   32\n",
            "0.2   132\n",
            "51   32\n",
            "0.2   133\n",
            "51   32\n",
            "0.2   134\n",
            "51   32\n",
            "0.2   135\n",
            "51   32\n",
            "0.2   136\n",
            "51   32\n",
            "0.2   137\n",
            "51   32\n",
            "0.2   138\n",
            "51   32\n",
            "0.2   139\n",
            "52   33\n",
            "0.2   140\n",
            "53   34\n",
            "0.2   141\n",
            "53   34\n",
            "0.2   142\n",
            "53   34\n",
            "0.2   143\n",
            "53   34\n",
            "0.2   144\n",
            "53   34\n",
            "0.2   145\n",
            "54   35\n",
            "0.2   146\n",
            "54   35\n",
            "0.2   147\n",
            "55   36\n",
            "0.2   148\n",
            "56   37\n",
            "0.2   149\n",
            "57   38\n",
            "0.2   150\n",
            "57   38\n",
            "0.2   151\n",
            "58   39\n",
            "0.2   152\n",
            "58   39\n",
            "0.2   153\n",
            "59   39\n",
            "0.2   154\n",
            "59   39\n",
            "0.2   155\n",
            "59   39\n",
            "0.2   156\n",
            "60   39\n",
            "0.2   157\n",
            "60   39\n",
            "0.2   158\n",
            "60   39\n",
            "0.2   159\n",
            "60   39\n",
            "0.2   160\n",
            "61   40\n",
            "0.2   161\n",
            "61   40\n",
            "0.2   162\n",
            "61   40\n",
            "0.2   163\n",
            "61   40\n",
            "0.2   164\n",
            "62   41\n",
            "0.2   165\n",
            "63   42\n",
            "0.2   166\n",
            "63   42\n",
            "0.2   167\n",
            "64   42\n",
            "0.2   168\n",
            "64   42\n",
            "0.2   169\n",
            "65   43\n",
            "0.2   170\n",
            "65   43\n",
            "0.2   171\n",
            "66   44\n",
            "0.2   172\n",
            "66   44\n",
            "0.2   173\n",
            "66   44\n",
            "0.2   174\n",
            "66   44\n",
            "0.2   175\n",
            "66   44\n",
            "0.2   176\n",
            "66   44\n",
            "0.2   177\n",
            "66   44\n",
            "0.2   178\n",
            "67   45\n",
            "0.2   179\n",
            "68   46\n",
            "0.2   180\n",
            "68   46\n",
            "0.2   181\n",
            "68   46\n",
            "0.2   182\n",
            "68   46\n",
            "0.2   183\n",
            "69   47\n",
            "0.2   184\n",
            "69   47\n",
            "0.2   185\n",
            "69   47\n",
            "0.2   186\n",
            "69   47\n",
            "0.2   187\n",
            "69   47\n",
            "0.2   188\n",
            "70   48\n",
            "0.2   189\n",
            "71   48\n",
            "0.2   190\n",
            "71   48\n",
            "0.2   191\n",
            "71   48\n",
            "0.2   192\n",
            "72   49\n",
            "0.2   193\n",
            "72   49\n",
            "0.2   194\n",
            "72   49\n",
            "0.2   195\n",
            "73   50\n",
            "0.2   196\n",
            "73   50\n",
            "0.2   197\n",
            "74   50\n",
            "0.2   198\n",
            "74   50\n",
            "0.2   199\n",
            "74   50\n",
            "Epsilon value -  0.30000000000000004\n",
            "\n",
            "0.30000000000000004   0\n",
            "0   0\n",
            "0.30000000000000004   1\n",
            "0   0\n",
            "0.30000000000000004   2\n",
            "1   1\n",
            "0.30000000000000004   3\n",
            "2   2\n",
            "0.30000000000000004   4\n",
            "2   2\n",
            "0.30000000000000004   5\n",
            "3   3\n",
            "0.30000000000000004   6\n",
            "4   4\n",
            "0.30000000000000004   7\n",
            "4   4\n",
            "0.30000000000000004   8\n",
            "4   4\n",
            "0.30000000000000004   9\n",
            "4   4\n",
            "0.30000000000000004   10\n",
            "5   5\n",
            "0.30000000000000004   11\n",
            "5   5\n",
            "0.30000000000000004   12\n",
            "6   6\n",
            "0.30000000000000004   13\n",
            "6   6\n",
            "0.30000000000000004   14\n",
            "6   6\n",
            "0.30000000000000004   15\n",
            "7   7\n",
            "0.30000000000000004   16\n",
            "7   7\n",
            "0.30000000000000004   17\n",
            "7   7\n",
            "0.30000000000000004   18\n",
            "7   7\n",
            "0.30000000000000004   19\n",
            "7   7\n",
            "0.30000000000000004   20\n",
            "8   8\n",
            "0.30000000000000004   21\n",
            "9   8\n",
            "0.30000000000000004   22\n",
            "10   8\n",
            "0.30000000000000004   23\n",
            "10   8\n",
            "0.30000000000000004   24\n",
            "10   8\n",
            "0.30000000000000004   25\n",
            "11   9\n",
            "0.30000000000000004   26\n",
            "12   10\n",
            "0.30000000000000004   27\n",
            "13   11\n",
            "0.30000000000000004   28\n",
            "13   11\n",
            "0.30000000000000004   29\n",
            "13   11\n",
            "0.30000000000000004   30\n",
            "13   11\n",
            "0.30000000000000004   31\n",
            "14   11\n",
            "0.30000000000000004   32\n",
            "15   12\n",
            "0.30000000000000004   33\n",
            "16   13\n",
            "0.30000000000000004   34\n",
            "16   13\n",
            "0.30000000000000004   35\n",
            "17   14\n",
            "0.30000000000000004   36\n",
            "17   14\n",
            "0.30000000000000004   37\n",
            "17   14\n",
            "0.30000000000000004   38\n",
            "17   14\n",
            "0.30000000000000004   39\n",
            "17   14\n",
            "0.30000000000000004   40\n",
            "18   15\n",
            "0.30000000000000004   41\n",
            "18   15\n",
            "0.30000000000000004   42\n",
            "19   15\n",
            "0.30000000000000004   43\n",
            "19   15\n",
            "0.30000000000000004   44\n",
            "19   15\n",
            "0.30000000000000004   45\n",
            "19   15\n",
            "0.30000000000000004   46\n",
            "19   15\n",
            "0.30000000000000004   47\n",
            "20   16\n",
            "0.30000000000000004   48\n",
            "20   16\n",
            "0.30000000000000004   49\n",
            "21   17\n",
            "0.30000000000000004   50\n",
            "21   17\n",
            "0.30000000000000004   51\n",
            "21   17\n",
            "0.30000000000000004   52\n",
            "22   18\n",
            "0.30000000000000004   53\n",
            "22   18\n",
            "0.30000000000000004   54\n",
            "22   18\n",
            "0.30000000000000004   55\n",
            "23   18\n",
            "0.30000000000000004   56\n",
            "23   18\n",
            "0.30000000000000004   57\n",
            "24   19\n",
            "0.30000000000000004   58\n",
            "24   19\n",
            "0.30000000000000004   59\n",
            "25   20\n",
            "0.30000000000000004   60\n",
            "25   20\n",
            "0.30000000000000004   61\n",
            "25   20\n",
            "0.30000000000000004   62\n",
            "26   21\n",
            "0.30000000000000004   63\n",
            "27   21\n",
            "0.30000000000000004   64\n",
            "27   21\n",
            "0.30000000000000004   65\n",
            "27   21\n",
            "0.30000000000000004   66\n",
            "27   21\n",
            "0.30000000000000004   67\n",
            "27   21\n",
            "0.30000000000000004   68\n",
            "28   22\n",
            "0.30000000000000004   69\n",
            "29   22\n",
            "0.30000000000000004   70\n",
            "30   23\n",
            "0.30000000000000004   71\n",
            "31   23\n",
            "0.30000000000000004   72\n",
            "32   24\n",
            "0.30000000000000004   73\n",
            "32   24\n",
            "0.30000000000000004   74\n",
            "33   25\n",
            "0.30000000000000004   75\n",
            "33   25\n",
            "0.30000000000000004   76\n",
            "34   26\n",
            "0.30000000000000004   77\n",
            "35   26\n",
            "0.30000000000000004   78\n",
            "36   27\n",
            "0.30000000000000004   79\n",
            "37   27\n",
            "0.30000000000000004   80\n",
            "37   27\n",
            "0.30000000000000004   81\n",
            "38   28\n",
            "0.30000000000000004   82\n",
            "38   28\n",
            "0.30000000000000004   83\n",
            "38   28\n",
            "0.30000000000000004   84\n",
            "39   29\n",
            "0.30000000000000004   85\n",
            "40   30\n",
            "0.30000000000000004   86\n",
            "41   31\n",
            "0.30000000000000004   87\n",
            "42   32\n",
            "0.30000000000000004   88\n",
            "43   33\n",
            "0.30000000000000004   89\n",
            "43   33\n",
            "0.30000000000000004   90\n",
            "44   33\n",
            "0.30000000000000004   91\n",
            "45   33\n",
            "0.30000000000000004   92\n",
            "46   33\n",
            "0.30000000000000004   93\n",
            "46   33\n",
            "0.30000000000000004   94\n",
            "47   33\n",
            "0.30000000000000004   95\n",
            "48   34\n",
            "0.30000000000000004   96\n",
            "48   34\n",
            "0.30000000000000004   97\n",
            "49   35\n",
            "0.30000000000000004   98\n",
            "49   35\n",
            "0.30000000000000004   99\n",
            "49   35\n",
            "0.30000000000000004   100\n",
            "49   35\n",
            "0.30000000000000004   101\n",
            "49   35\n",
            "0.30000000000000004   102\n",
            "50   36\n",
            "0.30000000000000004   103\n",
            "50   36\n",
            "0.30000000000000004   104\n",
            "50   36\n",
            "0.30000000000000004   105\n",
            "50   36\n",
            "0.30000000000000004   106\n",
            "50   36\n",
            "0.30000000000000004   107\n",
            "50   36\n",
            "0.30000000000000004   108\n",
            "50   36\n",
            "0.30000000000000004   109\n",
            "50   36\n",
            "0.30000000000000004   110\n",
            "50   36\n",
            "0.30000000000000004   111\n",
            "51   36\n",
            "0.30000000000000004   112\n",
            "52   37\n",
            "0.30000000000000004   113\n",
            "53   38\n",
            "0.30000000000000004   114\n",
            "53   38\n",
            "0.30000000000000004   115\n",
            "54   39\n",
            "0.30000000000000004   116\n",
            "54   39\n",
            "0.30000000000000004   117\n",
            "55   40\n",
            "0.30000000000000004   118\n",
            "56   41\n",
            "0.30000000000000004   119\n",
            "57   42\n",
            "0.30000000000000004   120\n",
            "57   42\n",
            "0.30000000000000004   121\n",
            "58   43\n",
            "0.30000000000000004   122\n",
            "58   43\n",
            "0.30000000000000004   123\n",
            "58   43\n",
            "0.30000000000000004   124\n",
            "59   43\n",
            "0.30000000000000004   125\n",
            "60   44\n",
            "0.30000000000000004   126\n",
            "60   44\n",
            "0.30000000000000004   127\n",
            "61   45\n",
            "0.30000000000000004   128\n",
            "62   46\n",
            "0.30000000000000004   129\n",
            "63   47\n",
            "0.30000000000000004   130\n",
            "64   48\n",
            "0.30000000000000004   131\n",
            "65   48\n",
            "0.30000000000000004   132\n",
            "65   48\n",
            "0.30000000000000004   133\n",
            "65   48\n",
            "0.30000000000000004   134\n",
            "66   48\n",
            "0.30000000000000004   135\n",
            "66   48\n",
            "0.30000000000000004   136\n",
            "66   48\n",
            "0.30000000000000004   137\n",
            "66   48\n",
            "0.30000000000000004   138\n",
            "66   48\n",
            "0.30000000000000004   139\n",
            "67   49\n",
            "0.30000000000000004   140\n",
            "68   50\n",
            "0.30000000000000004   141\n",
            "68   50\n",
            "0.30000000000000004   142\n",
            "69   50\n",
            "0.30000000000000004   143\n",
            "69   50\n",
            "0.30000000000000004   144\n",
            "69   50\n",
            "0.30000000000000004   145\n",
            "70   51\n",
            "0.30000000000000004   146\n",
            "70   51\n",
            "0.30000000000000004   147\n",
            "71   52\n",
            "0.30000000000000004   148\n",
            "72   53\n",
            "0.30000000000000004   149\n",
            "73   54\n",
            "0.30000000000000004   150\n",
            "74   55\n",
            "0.30000000000000004   151\n",
            "75   56\n",
            "0.30000000000000004   152\n",
            "75   56\n",
            "0.30000000000000004   153\n",
            "76   56\n",
            "0.30000000000000004   154\n",
            "76   56\n",
            "0.30000000000000004   155\n",
            "77   56\n",
            "0.30000000000000004   156\n",
            "78   56\n",
            "0.30000000000000004   157\n",
            "78   56\n",
            "0.30000000000000004   158\n",
            "78   56\n",
            "0.30000000000000004   159\n",
            "78   56\n",
            "0.30000000000000004   160\n",
            "79   57\n",
            "0.30000000000000004   161\n",
            "80   57\n",
            "0.30000000000000004   162\n",
            "80   57\n",
            "0.30000000000000004   163\n",
            "80   57\n",
            "0.30000000000000004   164\n",
            "81   58\n",
            "0.30000000000000004   165\n",
            "82   59\n",
            "0.30000000000000004   166\n",
            "83   59\n",
            "0.30000000000000004   167\n",
            "84   60\n",
            "0.30000000000000004   168\n",
            "84   60\n",
            "0.30000000000000004   169\n",
            "85   61\n",
            "0.30000000000000004   170\n",
            "85   61\n",
            "0.30000000000000004   171\n",
            "86   62\n",
            "0.30000000000000004   172\n",
            "87   62\n",
            "0.30000000000000004   173\n",
            "87   62\n",
            "0.30000000000000004   174\n",
            "88   62\n",
            "0.30000000000000004   175\n",
            "88   62\n",
            "0.30000000000000004   176\n",
            "88   62\n",
            "0.30000000000000004   177\n",
            "88   62\n",
            "0.30000000000000004   178\n",
            "89   63\n",
            "0.30000000000000004   179\n",
            "90   64\n",
            "0.30000000000000004   180\n",
            "90   64\n",
            "0.30000000000000004   181\n",
            "90   64\n",
            "0.30000000000000004   182\n",
            "90   64\n",
            "0.30000000000000004   183\n",
            "91   65\n",
            "0.30000000000000004   184\n",
            "92   65\n",
            "0.30000000000000004   185\n",
            "93   65\n",
            "0.30000000000000004   186\n",
            "93   65\n",
            "0.30000000000000004   187\n",
            "94   65\n",
            "0.30000000000000004   188\n",
            "95   66\n",
            "0.30000000000000004   189\n",
            "96   67\n",
            "0.30000000000000004   190\n",
            "96   67\n",
            "0.30000000000000004   191\n",
            "96   67\n",
            "0.30000000000000004   192\n",
            "97   68\n",
            "0.30000000000000004   193\n",
            "97   68\n",
            "0.30000000000000004   194\n",
            "97   68\n",
            "0.30000000000000004   195\n",
            "98   69\n",
            "0.30000000000000004   196\n",
            "98   69\n",
            "0.30000000000000004   197\n",
            "99   69\n",
            "0.30000000000000004   198\n",
            "99   69\n",
            "0.30000000000000004   199\n",
            "99   69\n",
            "Epsilon value -  0.4\n",
            "\n",
            "0.4   0\n",
            "0   0\n",
            "0.4   1\n",
            "0   0\n",
            "0.4   2\n",
            "1   1\n",
            "0.4   3\n",
            "2   2\n",
            "0.4   4\n",
            "2   2\n",
            "0.4   5\n",
            "3   3\n",
            "0.4   6\n",
            "4   4\n",
            "0.4   7\n",
            "4   4\n",
            "0.4   8\n",
            "4   4\n",
            "0.4   9\n",
            "4   4\n",
            "0.4   10\n",
            "5   5\n",
            "0.4   11\n",
            "6   5\n",
            "0.4   12\n",
            "7   6\n",
            "0.4   13\n",
            "7   6\n",
            "0.4   14\n",
            "7   6\n",
            "0.4   15\n",
            "8   7\n",
            "0.4   16\n",
            "8   7\n",
            "0.4   17\n",
            "8   7\n",
            "0.4   18\n",
            "8   7\n",
            "0.4   19\n",
            "8   7\n",
            "0.4   20\n",
            "9   8\n",
            "0.4   21\n",
            "10   8\n",
            "0.4   22\n",
            "11   8\n",
            "0.4   23\n",
            "11   8\n",
            "0.4   24\n",
            "11   8\n",
            "0.4   25\n",
            "12   9\n",
            "0.4   26\n",
            "13   10\n",
            "0.4   27\n",
            "14   11\n",
            "0.4   28\n",
            "14   11\n",
            "0.4   29\n",
            "14   11\n",
            "0.4   30\n",
            "15   11\n",
            "0.4   31\n",
            "16   11\n",
            "0.4   32\n",
            "17   12\n",
            "0.4   33\n",
            "18   13\n",
            "0.4   34\n",
            "18   13\n",
            "0.4   35\n",
            "19   14\n",
            "0.4   36\n",
            "20   14\n",
            "0.4   37\n",
            "20   14\n",
            "0.4   38\n",
            "20   14\n",
            "0.4   39\n",
            "20   14\n",
            "0.4   40\n",
            "21   15\n",
            "0.4   41\n",
            "21   15\n",
            "0.4   42\n",
            "22   15\n",
            "0.4   43\n",
            "22   15\n",
            "0.4   44\n",
            "22   15\n",
            "0.4   45\n",
            "22   15\n",
            "0.4   46\n",
            "22   15\n",
            "0.4   47\n",
            "23   16\n",
            "0.4   48\n",
            "23   16\n",
            "0.4   49\n",
            "24   17\n",
            "0.4   50\n",
            "25   17\n",
            "0.4   51\n",
            "25   17\n",
            "0.4   52\n",
            "26   18\n",
            "0.4   53\n",
            "26   18\n",
            "0.4   54\n",
            "26   18\n",
            "0.4   55\n",
            "27   18\n",
            "0.4   56\n",
            "27   18\n",
            "0.4   57\n",
            "28   19\n",
            "0.4   58\n",
            "28   19\n",
            "0.4   59\n",
            "29   20\n",
            "0.4   60\n",
            "29   20\n",
            "0.4   61\n",
            "29   20\n",
            "0.4   62\n",
            "30   21\n",
            "0.4   63\n",
            "31   22\n",
            "0.4   64\n",
            "31   22\n",
            "0.4   65\n",
            "31   22\n",
            "0.4   66\n",
            "32   22\n",
            "0.4   67\n",
            "32   22\n",
            "0.4   68\n",
            "33   23\n",
            "0.4   69\n",
            "34   24\n",
            "0.4   70\n",
            "35   25\n",
            "0.4   71\n",
            "36   25\n",
            "0.4   72\n",
            "37   26\n",
            "0.4   73\n",
            "38   26\n",
            "0.4   74\n",
            "39   27\n",
            "0.4   75\n",
            "39   27\n",
            "0.4   76\n",
            "40   28\n",
            "0.4   77\n",
            "41   29\n",
            "0.4   78\n",
            "42   30\n",
            "0.4   79\n",
            "43   30\n",
            "0.4   80\n",
            "43   30\n",
            "0.4   81\n",
            "44   31\n",
            "0.4   82\n",
            "44   31\n",
            "0.4   83\n",
            "45   31\n",
            "0.4   84\n",
            "46   32\n",
            "0.4   85\n",
            "47   33\n",
            "0.4   86\n",
            "48   34\n",
            "0.4   87\n",
            "49   35\n",
            "0.4   88\n",
            "50   36\n",
            "0.4   89\n",
            "50   36\n",
            "0.4   90\n",
            "51   36\n",
            "0.4   91\n",
            "52   37\n",
            "0.4   92\n",
            "53   38\n",
            "0.4   93\n",
            "53   38\n",
            "0.4   94\n",
            "54   38\n",
            "0.4   95\n",
            "55   39\n",
            "0.4   96\n",
            "55   39\n",
            "0.4   97\n",
            "56   40\n",
            "0.4   98\n",
            "56   40\n",
            "0.4   99\n",
            "56   40\n",
            "0.4   100\n",
            "57   40\n",
            "0.4   101\n",
            "57   40\n",
            "0.4   102\n",
            "58   41\n",
            "0.4   103\n",
            "59   41\n",
            "0.4   104\n",
            "59   41\n",
            "0.4   105\n",
            "59   41\n",
            "0.4   106\n",
            "59   41\n",
            "0.4   107\n",
            "59   41\n",
            "0.4   108\n",
            "60   41\n",
            "0.4   109\n",
            "60   41\n",
            "0.4   110\n",
            "60   41\n",
            "0.4   111\n",
            "61   42\n",
            "0.4   112\n",
            "62   43\n",
            "0.4   113\n",
            "63   44\n",
            "0.4   114\n",
            "63   44\n",
            "0.4   115\n",
            "64   45\n",
            "0.4   116\n",
            "64   45\n",
            "0.4   117\n",
            "65   46\n",
            "0.4   118\n",
            "66   47\n",
            "0.4   119\n",
            "67   48\n",
            "0.4   120\n",
            "68   48\n",
            "0.4   121\n",
            "69   49\n",
            "0.4   122\n",
            "69   49\n",
            "0.4   123\n",
            "69   49\n",
            "0.4   124\n",
            "70   49\n",
            "0.4   125\n",
            "71   50\n",
            "0.4   126\n",
            "71   50\n",
            "0.4   127\n",
            "72   51\n",
            "0.4   128\n",
            "73   52\n",
            "0.4   129\n",
            "74   53\n",
            "0.4   130\n",
            "75   54\n",
            "0.4   131\n",
            "76   55\n",
            "0.4   132\n",
            "76   55\n",
            "0.4   133\n",
            "76   55\n",
            "0.4   134\n",
            "77   56\n",
            "0.4   135\n",
            "77   56\n",
            "0.4   136\n",
            "77   56\n",
            "0.4   137\n",
            "77   56\n",
            "0.4   138\n",
            "77   56\n",
            "0.4   139\n",
            "78   57\n",
            "0.4   140\n",
            "79   58\n",
            "0.4   141\n",
            "79   58\n",
            "0.4   142\n",
            "80   58\n",
            "0.4   143\n",
            "81   58\n",
            "0.4   144\n",
            "81   58\n",
            "0.4   145\n",
            "82   59\n",
            "0.4   146\n",
            "83   59\n",
            "0.4   147\n",
            "84   60\n",
            "0.4   148\n",
            "85   61\n",
            "0.4   149\n",
            "86   62\n",
            "0.4   150\n",
            "87   63\n",
            "0.4   151\n",
            "88   64\n",
            "0.4   152\n",
            "88   64\n",
            "0.4   153\n",
            "89   65\n",
            "0.4   154\n",
            "89   65\n",
            "0.4   155\n",
            "90   65\n",
            "0.4   156\n",
            "91   66\n",
            "0.4   157\n",
            "91   66\n",
            "0.4   158\n",
            "91   66\n",
            "0.4   159\n",
            "91   66\n",
            "0.4   160\n",
            "92   67\n",
            "0.4   161\n",
            "93   67\n",
            "0.4   162\n",
            "93   67\n",
            "0.4   163\n",
            "93   67\n",
            "0.4   164\n",
            "94   68\n",
            "0.4   165\n",
            "95   69\n",
            "0.4   166\n",
            "96   69\n",
            "0.4   167\n",
            "97   70\n",
            "0.4   168\n",
            "97   70\n",
            "0.4   169\n",
            "98   71\n",
            "0.4   170\n",
            "98   71\n",
            "0.4   171\n",
            "99   72\n",
            "0.4   172\n",
            "100   73\n",
            "0.4   173\n",
            "100   73\n",
            "0.4   174\n",
            "101   74\n",
            "0.4   175\n",
            "101   74\n",
            "0.4   176\n",
            "102   74\n",
            "0.4   177\n",
            "102   74\n",
            "0.4   178\n",
            "103   75\n",
            "0.4   179\n",
            "104   76\n",
            "0.4   180\n",
            "105   76\n",
            "0.4   181\n",
            "105   76\n",
            "0.4   182\n",
            "105   76\n",
            "0.4   183\n",
            "106   77\n",
            "0.4   184\n",
            "107   77\n",
            "0.4   185\n",
            "108   77\n",
            "0.4   186\n",
            "108   77\n",
            "0.4   187\n",
            "109   77\n",
            "0.4   188\n",
            "110   78\n",
            "0.4   189\n",
            "111   79\n",
            "0.4   190\n",
            "111   79\n",
            "0.4   191\n",
            "111   79\n",
            "0.4   192\n",
            "112   80\n",
            "0.4   193\n",
            "112   80\n",
            "0.4   194\n",
            "112   80\n",
            "0.4   195\n",
            "113   81\n",
            "0.4   196\n",
            "113   81\n",
            "0.4   197\n",
            "114   81\n",
            "0.4   198\n",
            "114   81\n",
            "0.4   199\n",
            "115   81\n",
            "Epsilon value -  0.5\n",
            "\n",
            "0.5   0\n",
            "0   0\n",
            "0.5   1\n",
            "0   0\n",
            "0.5   2\n",
            "1   1\n",
            "0.5   3\n",
            "2   2\n",
            "0.5   4\n",
            "2   2\n",
            "0.5   5\n",
            "3   3\n",
            "0.5   6\n",
            "4   4\n",
            "0.5   7\n",
            "4   4\n",
            "0.5   8\n",
            "4   4\n",
            "0.5   9\n",
            "4   4\n",
            "0.5   10\n",
            "5   5\n",
            "0.5   11\n",
            "6   6\n",
            "0.5   12\n",
            "7   7\n",
            "0.5   13\n",
            "7   7\n",
            "0.5   14\n",
            "7   7\n",
            "0.5   15\n",
            "8   8\n",
            "0.5   16\n",
            "8   8\n",
            "0.5   17\n",
            "8   8\n",
            "0.5   18\n",
            "8   8\n",
            "0.5   19\n",
            "8   8\n",
            "0.5   20\n",
            "9   9\n",
            "0.5   21\n",
            "10   9\n",
            "0.5   22\n",
            "11   9\n",
            "0.5   23\n",
            "11   9\n",
            "0.5   24\n",
            "11   9\n",
            "0.5   25\n",
            "12   10\n",
            "0.5   26\n",
            "13   11\n",
            "0.5   27\n",
            "14   12\n",
            "0.5   28\n",
            "14   12\n",
            "0.5   29\n",
            "14   12\n",
            "0.5   30\n",
            "15   13\n",
            "0.5   31\n",
            "16   14\n",
            "0.5   32\n",
            "17   15\n",
            "0.5   33\n",
            "18   16\n",
            "0.5   34\n",
            "18   16\n",
            "0.5   35\n",
            "19   17\n",
            "0.5   36\n",
            "20   18\n",
            "0.5   37\n",
            "20   18\n",
            "0.5   38\n",
            "20   18\n",
            "0.5   39\n",
            "20   18\n",
            "0.5   40\n",
            "21   19\n",
            "0.5   41\n",
            "21   19\n",
            "0.5   42\n",
            "22   19\n",
            "0.5   43\n",
            "22   19\n",
            "0.5   44\n",
            "22   19\n",
            "0.5   45\n",
            "22   19\n",
            "0.5   46\n",
            "22   19\n",
            "0.5   47\n",
            "23   20\n",
            "0.5   48\n",
            "23   20\n",
            "0.5   49\n",
            "24   21\n",
            "0.5   50\n",
            "25   21\n",
            "0.5   51\n",
            "25   21\n",
            "0.5   52\n",
            "26   22\n",
            "0.5   53\n",
            "26   22\n",
            "0.5   54\n",
            "26   22\n",
            "0.5   55\n",
            "27   22\n",
            "0.5   56\n",
            "27   22\n",
            "0.5   57\n",
            "28   23\n",
            "0.5   58\n",
            "28   23\n",
            "0.5   59\n",
            "29   24\n",
            "0.5   60\n",
            "29   24\n",
            "0.5   61\n",
            "29   24\n",
            "0.5   62\n",
            "30   25\n",
            "0.5   63\n",
            "31   26\n",
            "0.5   64\n",
            "31   26\n",
            "0.5   65\n",
            "31   26\n",
            "0.5   66\n",
            "32   26\n",
            "0.5   67\n",
            "32   26\n",
            "0.5   68\n",
            "33   27\n",
            "0.5   69\n",
            "34   28\n",
            "0.5   70\n",
            "35   29\n",
            "0.5   71\n",
            "36   30\n",
            "0.5   72\n",
            "37   31\n",
            "0.5   73\n",
            "38   31\n",
            "0.5   74\n",
            "39   32\n",
            "0.5   75\n",
            "39   32\n",
            "0.5   76\n",
            "40   33\n",
            "0.5   77\n",
            "41   34\n",
            "0.5   78\n",
            "42   35\n",
            "0.5   79\n",
            "43   35\n",
            "0.5   80\n",
            "43   35\n",
            "0.5   81\n",
            "44   36\n",
            "0.5   82\n",
            "44   36\n",
            "0.5   83\n",
            "45   36\n",
            "0.5   84\n",
            "46   37\n",
            "0.5   85\n",
            "47   38\n",
            "0.5   86\n",
            "48   39\n",
            "0.5   87\n",
            "49   40\n",
            "0.5   88\n",
            "50   41\n",
            "0.5   89\n",
            "50   41\n",
            "0.5   90\n",
            "51   41\n",
            "0.5   91\n",
            "52   42\n",
            "0.5   92\n",
            "53   43\n",
            "0.5   93\n",
            "53   43\n",
            "0.5   94\n",
            "54   44\n",
            "0.5   95\n",
            "55   45\n",
            "0.5   96\n",
            "55   45\n",
            "0.5   97\n",
            "56   46\n",
            "0.5   98\n",
            "56   46\n",
            "0.5   99\n",
            "56   46\n",
            "0.5   100\n",
            "57   46\n",
            "0.5   101\n",
            "57   46\n",
            "0.5   102\n",
            "58   47\n",
            "0.5   103\n",
            "59   47\n",
            "0.5   104\n",
            "59   47\n",
            "0.5   105\n",
            "59   47\n",
            "0.5   106\n",
            "59   47\n",
            "0.5   107\n",
            "59   47\n",
            "0.5   108\n",
            "60   47\n",
            "0.5   109\n",
            "60   47\n",
            "0.5   110\n",
            "60   47\n",
            "0.5   111\n",
            "61   48\n",
            "0.5   112\n",
            "62   49\n",
            "0.5   113\n",
            "63   50\n",
            "0.5   114\n",
            "63   50\n",
            "0.5   115\n",
            "64   51\n",
            "0.5   116\n",
            "64   51\n",
            "0.5   117\n",
            "65   52\n",
            "0.5   118\n",
            "66   53\n",
            "0.5   119\n",
            "67   54\n",
            "0.5   120\n",
            "68   54\n",
            "0.5   121\n",
            "69   55\n",
            "0.5   122\n",
            "69   55\n",
            "0.5   123\n",
            "69   55\n",
            "0.5   124\n",
            "70   55\n",
            "0.5   125\n",
            "71   56\n",
            "0.5   126\n",
            "71   56\n",
            "0.5   127\n",
            "72   57\n",
            "0.5   128\n",
            "73   58\n",
            "0.5   129\n",
            "74   59\n",
            "0.5   130\n",
            "75   60\n",
            "0.5   131\n",
            "76   61\n",
            "0.5   132\n",
            "76   61\n",
            "0.5   133\n",
            "76   61\n",
            "0.5   134\n",
            "77   62\n",
            "0.5   135\n",
            "77   62\n",
            "0.5   136\n",
            "77   62\n",
            "0.5   137\n",
            "77   62\n",
            "0.5   138\n",
            "77   62\n",
            "0.5   139\n",
            "78   63\n",
            "0.5   140\n",
            "79   64\n",
            "0.5   141\n",
            "79   64\n",
            "0.5   142\n",
            "80   64\n",
            "0.5   143\n",
            "81   65\n",
            "0.5   144\n",
            "81   65\n",
            "0.5   145\n",
            "82   66\n",
            "0.5   146\n",
            "83   67\n",
            "0.5   147\n",
            "84   68\n",
            "0.5   148\n",
            "85   69\n",
            "0.5   149\n",
            "86   70\n",
            "0.5   150\n",
            "87   71\n",
            "0.5   151\n",
            "88   72\n",
            "0.5   152\n",
            "88   72\n",
            "0.5   153\n",
            "89   73\n",
            "0.5   154\n",
            "89   73\n",
            "0.5   155\n",
            "90   73\n",
            "0.5   156\n",
            "91   74\n",
            "0.5   157\n",
            "91   74\n",
            "0.5   158\n",
            "91   74\n",
            "0.5   159\n",
            "91   74\n",
            "0.5   160\n",
            "92   75\n",
            "0.5   161\n",
            "93   75\n",
            "0.5   162\n",
            "93   75\n",
            "0.5   163\n",
            "93   75\n",
            "0.5   164\n",
            "94   76\n",
            "0.5   165\n",
            "95   77\n",
            "0.5   166\n",
            "96   77\n",
            "0.5   167\n",
            "97   78\n",
            "0.5   168\n",
            "97   78\n",
            "0.5   169\n",
            "98   79\n",
            "0.5   170\n",
            "98   79\n",
            "0.5   171\n",
            "99   80\n",
            "0.5   172\n",
            "100   81\n",
            "0.5   173\n",
            "100   81\n",
            "0.5   174\n",
            "101   82\n",
            "0.5   175\n",
            "101   82\n",
            "0.5   176\n",
            "102   82\n",
            "0.5   177\n",
            "102   82\n",
            "0.5   178\n",
            "103   83\n",
            "0.5   179\n",
            "104   84\n",
            "0.5   180\n",
            "105   84\n",
            "0.5   181\n",
            "105   84\n",
            "0.5   182\n",
            "105   84\n",
            "0.5   183\n",
            "106   85\n",
            "0.5   184\n",
            "107   86\n",
            "0.5   185\n",
            "108   86\n",
            "0.5   186\n",
            "108   86\n",
            "0.5   187\n",
            "109   86\n",
            "0.5   188\n",
            "110   87\n",
            "0.5   189\n",
            "111   88\n",
            "0.5   190\n",
            "111   88\n",
            "0.5   191\n",
            "111   88\n",
            "0.5   192\n",
            "112   89\n",
            "0.5   193\n",
            "112   89\n",
            "0.5   194\n",
            "112   89\n",
            "0.5   195\n",
            "113   90\n",
            "0.5   196\n",
            "113   90\n",
            "0.5   197\n",
            "114   91\n",
            "0.5   198\n",
            "114   91\n",
            "0.5   199\n",
            "115   91\n",
            "Epsilon value -  0.6\n",
            "\n",
            "0.6   0\n",
            "0   0\n",
            "0.6   1\n",
            "0   0\n",
            "0.6   2\n",
            "1   1\n",
            "0.6   3\n",
            "2   2\n",
            "0.6   4\n",
            "2   2\n",
            "0.6   5\n",
            "3   3\n",
            "0.6   6\n",
            "4   4\n",
            "0.6   7\n",
            "4   4\n",
            "0.6   8\n",
            "4   4\n",
            "0.6   9\n",
            "4   4\n",
            "0.6   10\n",
            "5   5\n",
            "0.6   11\n",
            "6   6\n",
            "0.6   12\n",
            "7   7\n",
            "0.6   13\n",
            "7   7\n",
            "0.6   14\n",
            "7   7\n",
            "0.6   15\n",
            "8   8\n",
            "0.6   16\n",
            "8   8\n",
            "0.6   17\n",
            "8   8\n",
            "0.6   18\n",
            "8   8\n",
            "0.6   19\n",
            "8   8\n",
            "0.6   20\n",
            "9   9\n",
            "0.6   21\n",
            "10   9\n",
            "0.6   22\n",
            "11   9\n",
            "0.6   23\n",
            "11   9\n",
            "0.6   24\n",
            "11   9\n",
            "0.6   25\n",
            "12   10\n",
            "0.6   26\n",
            "13   11\n",
            "0.6   27\n",
            "14   12\n",
            "0.6   28\n",
            "14   12\n",
            "0.6   29\n",
            "14   12\n",
            "0.6   30\n",
            "15   13\n",
            "0.6   31\n",
            "16   14\n",
            "0.6   32\n",
            "17   15\n",
            "0.6   33\n",
            "18   16\n",
            "0.6   34\n",
            "18   16\n",
            "0.6   35\n",
            "19   17\n",
            "0.6   36\n",
            "20   18\n",
            "0.6   37\n",
            "20   18\n",
            "0.6   38\n",
            "20   18\n",
            "0.6   39\n",
            "20   18\n",
            "0.6   40\n",
            "21   19\n",
            "0.6   41\n",
            "21   19\n",
            "0.6   42\n",
            "22   19\n",
            "0.6   43\n",
            "22   19\n",
            "0.6   44\n",
            "22   19\n",
            "0.6   45\n",
            "22   19\n",
            "0.6   46\n",
            "22   19\n",
            "0.6   47\n",
            "23   20\n",
            "0.6   48\n",
            "23   20\n",
            "0.6   49\n",
            "24   21\n",
            "0.6   50\n",
            "25   21\n",
            "0.6   51\n",
            "25   21\n",
            "0.6   52\n",
            "26   22\n",
            "0.6   53\n",
            "26   22\n",
            "0.6   54\n",
            "26   22\n",
            "0.6   55\n",
            "27   22\n",
            "0.6   56\n",
            "27   22\n",
            "0.6   57\n",
            "28   23\n",
            "0.6   58\n",
            "28   23\n",
            "0.6   59\n",
            "29   24\n",
            "0.6   60\n",
            "29   24\n",
            "0.6   61\n",
            "29   24\n",
            "0.6   62\n",
            "30   25\n",
            "0.6   63\n",
            "31   26\n",
            "0.6   64\n",
            "31   26\n",
            "0.6   65\n",
            "31   26\n",
            "0.6   66\n",
            "32   27\n",
            "0.6   67\n",
            "32   27\n",
            "0.6   68\n",
            "33   28\n",
            "0.6   69\n",
            "34   29\n",
            "0.6   70\n",
            "35   30\n",
            "0.6   71\n",
            "36   31\n",
            "0.6   72\n",
            "37   32\n",
            "0.6   73\n",
            "38   32\n",
            "0.6   74\n",
            "39   33\n",
            "0.6   75\n",
            "39   33\n",
            "0.6   76\n",
            "40   34\n",
            "0.6   77\n",
            "41   35\n",
            "0.6   78\n",
            "42   36\n",
            "0.6   79\n",
            "43   36\n",
            "0.6   80\n",
            "43   36\n",
            "0.6   81\n",
            "44   37\n",
            "0.6   82\n",
            "44   37\n",
            "0.6   83\n",
            "45   37\n",
            "0.6   84\n",
            "46   38\n",
            "0.6   85\n",
            "47   39\n",
            "0.6   86\n",
            "48   40\n",
            "0.6   87\n",
            "49   41\n",
            "0.6   88\n",
            "50   42\n",
            "0.6   89\n",
            "50   42\n",
            "0.6   90\n",
            "51   42\n",
            "0.6   91\n",
            "52   43\n",
            "0.6   92\n",
            "53   44\n",
            "0.6   93\n",
            "53   44\n",
            "0.6   94\n",
            "54   45\n",
            "0.6   95\n",
            "55   46\n",
            "0.6   96\n",
            "55   46\n",
            "0.6   97\n",
            "56   47\n",
            "0.6   98\n",
            "56   47\n",
            "0.6   99\n",
            "56   47\n",
            "0.6   100\n",
            "57   47\n",
            "0.6   101\n",
            "57   47\n",
            "0.6   102\n",
            "58   48\n",
            "0.6   103\n",
            "59   48\n",
            "0.6   104\n",
            "59   48\n",
            "0.6   105\n",
            "59   48\n",
            "0.6   106\n",
            "59   48\n",
            "0.6   107\n",
            "59   48\n",
            "0.6   108\n",
            "60   49\n",
            "0.6   109\n",
            "60   49\n",
            "0.6   110\n",
            "60   49\n",
            "0.6   111\n",
            "61   50\n",
            "0.6   112\n",
            "62   51\n",
            "0.6   113\n",
            "63   52\n",
            "0.6   114\n",
            "63   52\n",
            "0.6   115\n",
            "64   53\n",
            "0.6   116\n",
            "64   53\n",
            "0.6   117\n",
            "65   54\n",
            "0.6   118\n",
            "66   55\n",
            "0.6   119\n",
            "67   56\n",
            "0.6   120\n",
            "68   56\n",
            "0.6   121\n",
            "69   57\n",
            "0.6   122\n",
            "69   57\n",
            "0.6   123\n",
            "69   57\n",
            "0.6   124\n",
            "70   57\n",
            "0.6   125\n",
            "71   58\n",
            "0.6   126\n",
            "71   58\n",
            "0.6   127\n",
            "72   59\n",
            "0.6   128\n",
            "73   60\n",
            "0.6   129\n",
            "74   61\n",
            "0.6   130\n",
            "75   62\n",
            "0.6   131\n",
            "76   63\n",
            "0.6   132\n",
            "76   63\n",
            "0.6   133\n",
            "76   63\n",
            "0.6   134\n",
            "77   64\n",
            "0.6   135\n",
            "77   64\n",
            "0.6   136\n",
            "77   64\n",
            "0.6   137\n",
            "77   64\n",
            "0.6   138\n",
            "77   64\n",
            "0.6   139\n",
            "78   65\n",
            "0.6   140\n",
            "79   66\n",
            "0.6   141\n",
            "79   66\n",
            "0.6   142\n",
            "80   66\n",
            "0.6   143\n",
            "81   67\n",
            "0.6   144\n",
            "81   67\n",
            "0.6   145\n",
            "82   68\n",
            "0.6   146\n",
            "83   69\n",
            "0.6   147\n",
            "84   70\n",
            "0.6   148\n",
            "85   71\n",
            "0.6   149\n",
            "86   72\n",
            "0.6   150\n",
            "87   73\n",
            "0.6   151\n",
            "88   74\n",
            "0.6   152\n",
            "88   74\n",
            "0.6   153\n",
            "89   75\n",
            "0.6   154\n",
            "89   75\n",
            "0.6   155\n",
            "90   76\n",
            "0.6   156\n",
            "91   77\n",
            "0.6   157\n",
            "91   77\n",
            "0.6   158\n",
            "91   77\n",
            "0.6   159\n",
            "91   77\n",
            "0.6   160\n",
            "92   78\n",
            "0.6   161\n",
            "93   79\n",
            "0.6   162\n",
            "93   79\n",
            "0.6   163\n",
            "93   79\n",
            "0.6   164\n",
            "94   80\n",
            "0.6   165\n",
            "95   81\n",
            "0.6   166\n",
            "96   81\n",
            "0.6   167\n",
            "97   82\n",
            "0.6   168\n",
            "97   82\n",
            "0.6   169\n",
            "98   83\n",
            "0.6   170\n",
            "98   83\n",
            "0.6   171\n",
            "99   84\n",
            "0.6   172\n",
            "100   85\n",
            "0.6   173\n",
            "100   85\n",
            "0.6   174\n",
            "101   86\n",
            "0.6   175\n",
            "101   86\n",
            "0.6   176\n",
            "102   86\n",
            "0.6   177\n",
            "102   86\n",
            "0.6   178\n",
            "103   87\n",
            "0.6   179\n",
            "104   88\n",
            "0.6   180\n",
            "105   88\n",
            "0.6   181\n",
            "105   88\n",
            "0.6   182\n",
            "105   88\n",
            "0.6   183\n",
            "106   89\n",
            "0.6   184\n",
            "107   90\n",
            "0.6   185\n",
            "108   90\n",
            "0.6   186\n",
            "108   90\n",
            "0.6   187\n",
            "109   91\n",
            "0.6   188\n",
            "110   92\n",
            "0.6   189\n",
            "111   93\n",
            "0.6   190\n",
            "111   93\n",
            "0.6   191\n",
            "111   93\n",
            "0.6   192\n",
            "112   94\n",
            "0.6   193\n",
            "112   94\n",
            "0.6   194\n",
            "112   94\n",
            "0.6   195\n",
            "113   95\n",
            "0.6   196\n",
            "113   95\n",
            "0.6   197\n",
            "114   96\n",
            "0.6   198\n",
            "114   96\n",
            "0.6   199\n",
            "115   96\n",
            "Epsilon value -  0.7\n",
            "\n",
            "0.7   0\n",
            "0   0\n",
            "0.7   1\n",
            "0   0\n",
            "0.7   2\n",
            "1   1\n",
            "0.7   3\n",
            "2   2\n",
            "0.7   4\n",
            "2   2\n",
            "0.7   5\n",
            "3   3\n",
            "0.7   6\n",
            "4   4\n",
            "0.7   7\n",
            "4   4\n",
            "0.7   8\n",
            "4   4\n",
            "0.7   9\n",
            "4   4\n",
            "0.7   10\n",
            "5   5\n",
            "0.7   11\n",
            "6   6\n",
            "0.7   12\n",
            "7   7\n",
            "0.7   13\n",
            "7   7\n",
            "0.7   14\n",
            "7   7\n",
            "0.7   15\n",
            "8   8\n",
            "0.7   16\n",
            "8   8\n",
            "0.7   17\n",
            "8   8\n",
            "0.7   18\n",
            "8   8\n",
            "0.7   19\n",
            "8   8\n",
            "0.7   20\n",
            "9   9\n",
            "0.7   21\n",
            "10   9\n",
            "0.7   22\n",
            "11   9\n",
            "0.7   23\n",
            "11   9\n",
            "0.7   24\n",
            "11   9\n",
            "0.7   25\n",
            "12   10\n",
            "0.7   26\n",
            "13   11\n",
            "0.7   27\n",
            "14   12\n",
            "0.7   28\n",
            "14   12\n",
            "0.7   29\n",
            "14   12\n",
            "0.7   30\n",
            "15   13\n",
            "0.7   31\n",
            "16   14\n",
            "0.7   32\n",
            "17   15\n",
            "0.7   33\n",
            "18   16\n",
            "0.7   34\n",
            "18   16\n",
            "0.7   35\n",
            "19   17\n",
            "0.7   36\n",
            "20   18\n",
            "0.7   37\n",
            "20   18\n",
            "0.7   38\n",
            "20   18\n",
            "0.7   39\n",
            "20   18\n",
            "0.7   40\n",
            "21   19\n",
            "0.7   41\n",
            "21   19\n",
            "0.7   42\n",
            "22   19\n",
            "0.7   43\n",
            "22   19\n",
            "0.7   44\n",
            "22   19\n",
            "0.7   45\n",
            "22   19\n",
            "0.7   46\n",
            "22   19\n",
            "0.7   47\n",
            "23   20\n",
            "0.7   48\n",
            "23   21\n",
            "0.7   49\n",
            "24   22\n",
            "0.7   50\n",
            "25   23\n",
            "0.7   51\n",
            "25   23\n",
            "0.7   52\n",
            "26   24\n",
            "0.7   53\n",
            "26   24\n",
            "0.7   54\n",
            "26   24\n",
            "0.7   55\n",
            "27   24\n",
            "0.7   56\n",
            "27   24\n",
            "0.7   57\n",
            "28   25\n",
            "0.7   58\n",
            "28   25\n",
            "0.7   59\n",
            "29   26\n",
            "0.7   60\n",
            "29   26\n",
            "0.7   61\n",
            "29   26\n",
            "0.7   62\n",
            "30   27\n",
            "0.7   63\n",
            "31   28\n",
            "0.7   64\n",
            "31   28\n",
            "0.7   65\n",
            "31   28\n",
            "0.7   66\n",
            "32   29\n",
            "0.7   67\n",
            "32   29\n",
            "0.7   68\n",
            "33   30\n",
            "0.7   69\n",
            "34   31\n",
            "0.7   70\n",
            "35   32\n",
            "0.7   71\n",
            "36   33\n",
            "0.7   72\n",
            "37   34\n",
            "0.7   73\n",
            "38   34\n",
            "0.7   74\n",
            "39   35\n",
            "0.7   75\n",
            "39   35\n",
            "0.7   76\n",
            "40   36\n",
            "0.7   77\n",
            "41   37\n",
            "0.7   78\n",
            "42   38\n",
            "0.7   79\n",
            "43   38\n",
            "0.7   80\n",
            "43   38\n",
            "0.7   81\n",
            "44   39\n",
            "0.7   82\n",
            "44   39\n",
            "0.7   83\n",
            "45   39\n",
            "0.7   84\n",
            "46   40\n",
            "0.7   85\n",
            "47   41\n",
            "0.7   86\n",
            "48   42\n",
            "0.7   87\n",
            "49   43\n",
            "0.7   88\n",
            "50   44\n",
            "0.7   89\n",
            "50   44\n",
            "0.7   90\n",
            "51   44\n",
            "0.7   91\n",
            "52   45\n",
            "0.7   92\n",
            "53   46\n",
            "0.7   93\n",
            "53   46\n",
            "0.7   94\n",
            "54   47\n",
            "0.7   95\n",
            "55   48\n",
            "0.7   96\n",
            "55   48\n",
            "0.7   97\n",
            "56   49\n",
            "0.7   98\n",
            "56   49\n",
            "0.7   99\n",
            "56   49\n",
            "0.7   100\n",
            "57   50\n",
            "0.7   101\n",
            "57   50\n",
            "0.7   102\n",
            "58   51\n",
            "0.7   103\n",
            "59   51\n",
            "0.7   104\n",
            "59   51\n",
            "0.7   105\n",
            "59   51\n",
            "0.7   106\n",
            "59   51\n",
            "0.7   107\n",
            "59   51\n",
            "0.7   108\n",
            "60   52\n",
            "0.7   109\n",
            "60   52\n",
            "0.7   110\n",
            "60   52\n",
            "0.7   111\n",
            "61   53\n",
            "0.7   112\n",
            "62   54\n",
            "0.7   113\n",
            "63   55\n",
            "0.7   114\n",
            "63   55\n",
            "0.7   115\n",
            "64   56\n",
            "0.7   116\n",
            "64   56\n",
            "0.7   117\n",
            "65   57\n",
            "0.7   118\n",
            "66   58\n",
            "0.7   119\n",
            "67   59\n",
            "0.7   120\n",
            "68   59\n",
            "0.7   121\n",
            "69   60\n",
            "0.7   122\n",
            "69   60\n",
            "0.7   123\n",
            "69   60\n",
            "0.7   124\n",
            "70   60\n",
            "0.7   125\n",
            "71   61\n",
            "0.7   126\n",
            "71   61\n",
            "0.7   127\n",
            "72   62\n",
            "0.7   128\n",
            "73   63\n",
            "0.7   129\n",
            "74   64\n",
            "0.7   130\n",
            "75   65\n",
            "0.7   131\n",
            "76   66\n",
            "0.7   132\n",
            "76   66\n",
            "0.7   133\n",
            "76   66\n",
            "0.7   134\n",
            "77   67\n",
            "0.7   135\n",
            "77   67\n",
            "0.7   136\n",
            "77   67\n",
            "0.7   137\n",
            "77   67\n",
            "0.7   138\n",
            "77   67\n",
            "0.7   139\n",
            "78   68\n",
            "0.7   140\n",
            "79   69\n",
            "0.7   141\n",
            "79   69\n",
            "0.7   142\n",
            "80   70\n",
            "0.7   143\n",
            "81   71\n",
            "0.7   144\n",
            "81   71\n",
            "0.7   145\n",
            "82   72\n",
            "0.7   146\n",
            "83   73\n",
            "0.7   147\n",
            "84   74\n",
            "0.7   148\n",
            "85   75\n",
            "0.7   149\n",
            "86   76\n",
            "0.7   150\n",
            "87   77\n",
            "0.7   151\n",
            "88   78\n",
            "0.7   152\n",
            "88   78\n",
            "0.7   153\n",
            "89   79\n",
            "0.7   154\n",
            "89   79\n",
            "0.7   155\n",
            "90   80\n",
            "0.7   156\n",
            "91   81\n",
            "0.7   157\n",
            "91   81\n",
            "0.7   158\n",
            "91   81\n",
            "0.7   159\n",
            "91   81\n",
            "0.7   160\n",
            "92   82\n",
            "0.7   161\n",
            "93   83\n",
            "0.7   162\n",
            "93   83\n",
            "0.7   163\n",
            "93   83\n",
            "0.7   164\n",
            "94   84\n",
            "0.7   165\n",
            "95   85\n",
            "0.7   166\n",
            "96   85\n",
            "0.7   167\n",
            "97   86\n",
            "0.7   168\n",
            "97   87\n",
            "0.7   169\n",
            "98   88\n",
            "0.7   170\n",
            "98   88\n",
            "0.7   171\n",
            "99   89\n",
            "0.7   172\n",
            "100   90\n",
            "0.7   173\n",
            "100   90\n",
            "0.7   174\n",
            "101   91\n",
            "0.7   175\n",
            "101   91\n",
            "0.7   176\n",
            "102   91\n",
            "0.7   177\n",
            "102   92\n",
            "0.7   178\n",
            "103   93\n",
            "0.7   179\n",
            "104   94\n",
            "0.7   180\n",
            "105   94\n",
            "0.7   181\n",
            "105   94\n",
            "0.7   182\n",
            "105   94\n",
            "0.7   183\n",
            "106   95\n",
            "0.7   184\n",
            "107   96\n",
            "0.7   185\n",
            "108   96\n",
            "0.7   186\n",
            "108   96\n",
            "0.7   187\n",
            "109   97\n",
            "0.7   188\n",
            "110   98\n",
            "0.7   189\n",
            "111   99\n",
            "0.7   190\n",
            "111   99\n",
            "0.7   191\n",
            "111   99\n",
            "0.7   192\n",
            "112   100\n",
            "0.7   193\n",
            "112   100\n",
            "0.7   194\n",
            "112   100\n",
            "0.7   195\n",
            "113   101\n",
            "0.7   196\n",
            "113   101\n",
            "0.7   197\n",
            "114   102\n",
            "0.7   198\n",
            "114   102\n",
            "0.7   199\n",
            "115   102\n",
            "Epsilon value -  0.7999999999999999\n",
            "\n",
            "0.7999999999999999   0\n",
            "0   0\n",
            "0.7999999999999999   1\n",
            "0   0\n",
            "0.7999999999999999   2\n",
            "1   1\n",
            "0.7999999999999999   3\n",
            "2   2\n",
            "0.7999999999999999   4\n",
            "2   2\n",
            "0.7999999999999999   5\n",
            "3   3\n",
            "0.7999999999999999   6\n",
            "4   4\n",
            "0.7999999999999999   7\n",
            "4   4\n",
            "0.7999999999999999   8\n",
            "4   5\n",
            "0.7999999999999999   9\n",
            "4   6\n",
            "0.7999999999999999   10\n",
            "5   7\n",
            "0.7999999999999999   11\n",
            "6   8\n",
            "0.7999999999999999   12\n",
            "7   9\n",
            "0.7999999999999999   13\n",
            "7   9\n",
            "0.7999999999999999   14\n",
            "7   9\n",
            "0.7999999999999999   15\n",
            "8   10\n",
            "0.7999999999999999   16\n",
            "8   10\n",
            "0.7999999999999999   17\n",
            "8   10\n",
            "0.7999999999999999   18\n",
            "8   10\n",
            "0.7999999999999999   19\n",
            "8   10\n",
            "0.7999999999999999   20\n",
            "9   11\n",
            "0.7999999999999999   21\n",
            "10   11\n",
            "0.7999999999999999   22\n",
            "11   11\n",
            "0.7999999999999999   23\n",
            "11   11\n",
            "0.7999999999999999   24\n",
            "11   11\n",
            "0.7999999999999999   25\n",
            "12   12\n",
            "0.7999999999999999   26\n",
            "13   13\n",
            "0.7999999999999999   27\n",
            "14   14\n",
            "0.7999999999999999   28\n",
            "14   14\n",
            "0.7999999999999999   29\n",
            "14   14\n",
            "0.7999999999999999   30\n",
            "15   15\n",
            "0.7999999999999999   31\n",
            "16   16\n",
            "0.7999999999999999   32\n",
            "17   17\n",
            "0.7999999999999999   33\n",
            "18   18\n",
            "0.7999999999999999   34\n",
            "18   18\n",
            "0.7999999999999999   35\n",
            "19   19\n",
            "0.7999999999999999   36\n",
            "20   20\n",
            "0.7999999999999999   37\n",
            "20   20\n",
            "0.7999999999999999   38\n",
            "20   20\n",
            "0.7999999999999999   39\n",
            "20   20\n",
            "0.7999999999999999   40\n",
            "21   21\n",
            "0.7999999999999999   41\n",
            "21   21\n",
            "0.7999999999999999   42\n",
            "22   21\n",
            "0.7999999999999999   43\n",
            "22   21\n",
            "0.7999999999999999   44\n",
            "22   21\n",
            "0.7999999999999999   45\n",
            "22   22\n",
            "0.7999999999999999   46\n",
            "22   22\n",
            "0.7999999999999999   47\n",
            "23   23\n",
            "0.7999999999999999   48\n",
            "23   24\n",
            "0.7999999999999999   49\n",
            "24   25\n",
            "0.7999999999999999   50\n",
            "25   26\n",
            "0.7999999999999999   51\n",
            "25   26\n",
            "0.7999999999999999   52\n",
            "26   27\n",
            "0.7999999999999999   53\n",
            "26   27\n",
            "0.7999999999999999   54\n",
            "26   27\n",
            "0.7999999999999999   55\n",
            "27   27\n",
            "0.7999999999999999   56\n",
            "27   27\n",
            "0.7999999999999999   57\n",
            "28   28\n",
            "0.7999999999999999   58\n",
            "28   28\n",
            "0.7999999999999999   59\n",
            "29   29\n",
            "0.7999999999999999   60\n",
            "29   30\n",
            "0.7999999999999999   61\n",
            "29   30\n",
            "0.7999999999999999   62\n",
            "30   31\n",
            "0.7999999999999999   63\n",
            "31   32\n",
            "0.7999999999999999   64\n",
            "31   32\n",
            "0.7999999999999999   65\n",
            "31   33\n",
            "0.7999999999999999   66\n",
            "32   34\n",
            "0.7999999999999999   67\n",
            "32   34\n",
            "0.7999999999999999   68\n",
            "33   35\n",
            "0.7999999999999999   69\n",
            "34   36\n",
            "0.7999999999999999   70\n",
            "35   37\n",
            "0.7999999999999999   71\n",
            "36   38\n",
            "0.7999999999999999   72\n",
            "37   39\n",
            "0.7999999999999999   73\n",
            "38   39\n",
            "0.7999999999999999   74\n",
            "39   40\n",
            "0.7999999999999999   75\n",
            "39   40\n",
            "0.7999999999999999   76\n",
            "40   41\n",
            "0.7999999999999999   77\n",
            "41   42\n",
            "0.7999999999999999   78\n",
            "42   43\n",
            "0.7999999999999999   79\n",
            "43   44\n",
            "0.7999999999999999   80\n",
            "43   44\n",
            "0.7999999999999999   81\n",
            "44   45\n",
            "0.7999999999999999   82\n",
            "44   45\n",
            "0.7999999999999999   83\n",
            "45   46\n",
            "0.7999999999999999   84\n",
            "46   47\n",
            "0.7999999999999999   85\n",
            "47   48\n",
            "0.7999999999999999   86\n",
            "48   49\n",
            "0.7999999999999999   87\n",
            "49   50\n",
            "0.7999999999999999   88\n",
            "50   51\n",
            "0.7999999999999999   89\n",
            "50   51\n",
            "0.7999999999999999   90\n",
            "51   51\n",
            "0.7999999999999999   91\n",
            "52   52\n",
            "0.7999999999999999   92\n",
            "53   53\n",
            "0.7999999999999999   93\n",
            "53   53\n",
            "0.7999999999999999   94\n",
            "54   54\n",
            "0.7999999999999999   95\n",
            "55   55\n",
            "0.7999999999999999   96\n",
            "55   55\n",
            "0.7999999999999999   97\n",
            "56   56\n",
            "0.7999999999999999   98\n",
            "56   56\n",
            "0.7999999999999999   99\n",
            "56   56\n",
            "0.7999999999999999   100\n",
            "57   57\n",
            "0.7999999999999999   101\n",
            "57   58\n",
            "0.7999999999999999   102\n",
            "58   59\n",
            "0.7999999999999999   103\n",
            "59   60\n",
            "0.7999999999999999   104\n",
            "59   60\n",
            "0.7999999999999999   105\n",
            "59   60\n",
            "0.7999999999999999   106\n",
            "59   60\n",
            "0.7999999999999999   107\n",
            "59   60\n",
            "0.7999999999999999   108\n",
            "60   61\n",
            "0.7999999999999999   109\n",
            "60   61\n",
            "0.7999999999999999   110\n",
            "60   61\n",
            "0.7999999999999999   111\n",
            "61   62\n",
            "0.7999999999999999   112\n",
            "62   63\n",
            "0.7999999999999999   113\n",
            "63   64\n",
            "0.7999999999999999   114\n",
            "63   64\n",
            "0.7999999999999999   115\n",
            "64   65\n",
            "0.7999999999999999   116\n",
            "64   65\n",
            "0.7999999999999999   117\n",
            "65   66\n",
            "0.7999999999999999   118\n",
            "66   67\n",
            "0.7999999999999999   119\n",
            "67   68\n",
            "0.7999999999999999   120\n",
            "68   68\n",
            "0.7999999999999999   121\n",
            "69   69\n",
            "0.7999999999999999   122\n",
            "69   69\n",
            "0.7999999999999999   123\n",
            "69   69\n",
            "0.7999999999999999   124\n",
            "70   69\n",
            "0.7999999999999999   125\n",
            "71   70\n",
            "0.7999999999999999   126\n",
            "71   70\n",
            "0.7999999999999999   127\n",
            "72   71\n",
            "0.7999999999999999   128\n",
            "73   72\n",
            "0.7999999999999999   129\n",
            "74   73\n",
            "0.7999999999999999   130\n",
            "75   74\n",
            "0.7999999999999999   131\n",
            "76   75\n",
            "0.7999999999999999   132\n",
            "76   75\n",
            "0.7999999999999999   133\n",
            "76   75\n",
            "0.7999999999999999   134\n",
            "77   76\n",
            "0.7999999999999999   135\n",
            "77   76\n",
            "0.7999999999999999   136\n",
            "77   76\n",
            "0.7999999999999999   137\n",
            "77   76\n",
            "0.7999999999999999   138\n",
            "77   76\n",
            "0.7999999999999999   139\n",
            "78   77\n",
            "0.7999999999999999   140\n",
            "79   78\n",
            "0.7999999999999999   141\n",
            "79   78\n",
            "0.7999999999999999   142\n",
            "80   79\n",
            "0.7999999999999999   143\n",
            "81   80\n",
            "0.7999999999999999   144\n",
            "81   80\n",
            "0.7999999999999999   145\n",
            "82   81\n",
            "0.7999999999999999   146\n",
            "83   82\n",
            "0.7999999999999999   147\n",
            "84   83\n",
            "0.7999999999999999   148\n",
            "85   84\n",
            "0.7999999999999999   149\n",
            "86   85\n",
            "0.7999999999999999   150\n",
            "87   86\n",
            "0.7999999999999999   151\n",
            "88   87\n",
            "0.7999999999999999   152\n",
            "88   87\n",
            "0.7999999999999999   153\n",
            "89   88\n",
            "0.7999999999999999   154\n",
            "89   88\n",
            "0.7999999999999999   155\n",
            "90   89\n",
            "0.7999999999999999   156\n",
            "91   90\n",
            "0.7999999999999999   157\n",
            "91   90\n",
            "0.7999999999999999   158\n",
            "91   90\n",
            "0.7999999999999999   159\n",
            "91   90\n",
            "0.7999999999999999   160\n",
            "92   91\n",
            "0.7999999999999999   161\n",
            "93   92\n",
            "0.7999999999999999   162\n",
            "93   92\n",
            "0.7999999999999999   163\n",
            "93   93\n",
            "0.7999999999999999   164\n",
            "94   94\n",
            "0.7999999999999999   165\n",
            "95   95\n",
            "0.7999999999999999   166\n",
            "96   95\n",
            "0.7999999999999999   167\n",
            "97   96\n",
            "0.7999999999999999   168\n",
            "97   97\n",
            "0.7999999999999999   169\n",
            "98   98\n",
            "0.7999999999999999   170\n",
            "98   98\n",
            "0.7999999999999999   171\n",
            "99   99\n",
            "0.7999999999999999   172\n",
            "100   100\n",
            "0.7999999999999999   173\n",
            "100   100\n",
            "0.7999999999999999   174\n",
            "101   101\n",
            "0.7999999999999999   175\n",
            "101   101\n",
            "0.7999999999999999   176\n",
            "102   102\n",
            "0.7999999999999999   177\n",
            "102   103\n",
            "0.7999999999999999   178\n",
            "103   104\n",
            "0.7999999999999999   179\n",
            "104   105\n",
            "0.7999999999999999   180\n",
            "105   105\n",
            "0.7999999999999999   181\n",
            "105   105\n",
            "0.7999999999999999   182\n",
            "105   105\n",
            "0.7999999999999999   183\n",
            "106   106\n",
            "0.7999999999999999   184\n",
            "107   107\n",
            "0.7999999999999999   185\n",
            "108   107\n",
            "0.7999999999999999   186\n",
            "108   107\n",
            "0.7999999999999999   187\n",
            "109   108\n",
            "0.7999999999999999   188\n",
            "110   109\n",
            "0.7999999999999999   189\n",
            "111   110\n",
            "0.7999999999999999   190\n",
            "111   110\n",
            "0.7999999999999999   191\n",
            "111   110\n",
            "0.7999999999999999   192\n",
            "112   111\n",
            "0.7999999999999999   193\n",
            "112   111\n",
            "0.7999999999999999   194\n",
            "112   111\n",
            "0.7999999999999999   195\n",
            "113   112\n",
            "0.7999999999999999   196\n",
            "113   112\n",
            "0.7999999999999999   197\n",
            "114   113\n",
            "0.7999999999999999   198\n",
            "114   113\n",
            "0.7999999999999999   199\n",
            "115   113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in result.keys():\n",
        "  print(key,' ',result[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL0_6uCGCcXj",
        "outputId": "f95a6e86-288f-4ac6-8e30-dbea3d3eee22"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1   (24, 30)\n",
            "0.2   (50, 74)\n",
            "0.30000000000000004   (69, 99)\n",
            "0.4   (81, 115)\n",
            "0.5   (91, 115)\n",
            "0.6   (96, 115)\n",
            "0.7   (102, 115)\n",
            "0.7999999999999999   (113, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(model_path)\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "epsilon_end = 0.8\n",
        "#logits_model = tf.keras.Model(model.input,model.layers[-1].output)\n",
        "total_images = 200\n",
        "\n",
        "result={}\n",
        "epsilon = 0.1\n",
        "while(epsilon <= epsilon_end):\n",
        "\n",
        "  fgsm_counter = 0\n",
        "  pgd_counter = 0\n",
        "  print(\"Epsilon value - \",epsilon)\n",
        "  print()\n",
        "  for image_index in range(total_images):\n",
        "  \n",
        "  \n",
        "    image = x_test[image_index]\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape(1, 32, 32, 3)\n",
        "    true_value = y_test[image_index]\n",
        "    original_prediction = make_prediction(model,image,true_value)\n",
        "    fgsm_sample = fast_gradient_method(model, image, epsilon, np.inf, targeted=False)\n",
        "    pgd_sample = projected_gradient_descent(model, image, epsilon, 0.01, 40, np.inf)\n",
        "    print(epsilon,' ',image_index)\n",
        "    fgsm_prediction = make_prediction(model , fgsm_sample , true_value)\n",
        "    pgd_prediction = make_prediction(model , pgd_sample , true_value)\n",
        "    pgd_counter+=pgd_prediction\n",
        "    fgsm_counter+=fgsm_prediction\n",
        "    print(pgd_counter,' ',fgsm_counter)\n",
        "  result[epsilon] = (fgsm_counter , pgd_counter)\n",
        "  epsilon+=0.1\n"
      ],
      "metadata": {
        "id": "5InTZ_6PCdZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in result.keys():\n",
        "  print(key,' ',result[key])"
      ],
      "metadata": {
        "id": "HPFdHqRHCjIj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}