{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Test_bench.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOt66vJvLVh718ZPX7Q4JHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirath2205/Final-Year-Project/blob/main/Test_bench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcyH2uCmqDOG"
      },
      "source": [
        "import keras,os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D , Dropout\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50 , preprocess_input\n",
        "from keras import regularizers\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlBqJ6SIkZ0u",
        "outputId": "27758bbb-a776-4e4d-eeb3-8c67288dd4f9"
      },
      "source": [
        "!pip install Keras-applications\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: Keras-applications in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras-applications) (1.19.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras-applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras-applications) (1.15.0)\n",
            "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVVahuJ1t7HD"
      },
      "source": [
        "def select_dataset(index):\n",
        "\n",
        "  if(index==1):\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist\n",
        "\n",
        "  elif(index==2):\n",
        "    cifar_10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar_10\n",
        "  \n",
        "  elif(index==3):\n",
        "    cifar_100 = tf.keras.datasets.cifar100.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar_100\n",
        "    print(len(X_train))\n",
        "\n",
        "    \n",
        "  return X_train,y_train,X_test,y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQV52_6GvrRS"
      },
      "source": [
        "def normalize(X_train,X_test):\n",
        "    #this function normalize inputs for zero mean and unit variance\n",
        "    # it is used when training a model.\n",
        "    # Input: training set and test set\n",
        "    # Output: normalized training set and test set according to the trianing set statistics.\n",
        "    mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "    print(mean)\n",
        "    print(std)\n",
        "    X_train = (X_train-mean)/(std+1e-7)\n",
        "    X_test = (X_test-mean)/(std+1e-7)\n",
        "    return X_train, X_test\n",
        "\n",
        "def pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,image_channel):\n",
        "  img_width = X_train.shape[1]\n",
        "  img_height = X_train.shape[2]\n",
        "  input_shape = (img_width, img_height, image_channel)\n",
        "  \n",
        "  # normalize data\n",
        "  X_train, X_test = X_train / 255, X_test / 255\n",
        "\n",
        "  # reshape input \n",
        "  X_train = X_train.reshape(X_train.shape[0], *input_shape)\n",
        "  X_test = X_test.reshape(X_test.shape[0], *input_shape)\n",
        "\n",
        "  # one-hot\n",
        "  y_train = tf.keras.utils.to_categorical(y_train)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  return X_train,y_train,X_test,y_test,input_shape\n",
        "\n",
        "def pre_processing_cifar10(X_train,y_train,X_test,y_test,image_channel):\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "  X_train = preprocess_input(X_train)\n",
        "  X_test = preprocess_input(X_test)\n",
        "\n",
        "  img_width = X_train[0].shape[0]\n",
        "  img_height = X_train[0].shape[1]\n",
        "  image_channel = image_channel\n",
        "\n",
        "  input_shape=(img_width,img_height,image_channel) \n",
        "  print(input_shape)\n",
        "  X_train , X_test = normalize(X_train , X_test)\n",
        "  return X_train,y_train,X_test,y_test,input_shape\n",
        "  \n",
        "def pre_processing_cifar100(X_train,y_train,X_test,y_test,image_channel):\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_train = preprocess_input(X_train)\n",
        "  X_test = preprocess_input(X_test)\n",
        "\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "  img_width = X_train[0].shape[0]\n",
        "  img_height = X_train[0].shape[1]\n",
        "  image_channel = image_channel\n",
        "\n",
        "  input_shape=(img_width,img_height,image_channel) \n",
        "  print(input_shape)\n",
        "  return X_train,y_train,X_test,y_test,input_shape"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDvpMVLzu3if"
      },
      "source": [
        "def define_model_vgg16(image_shape,total_classes):\n",
        "  print(image_shape[2])\n",
        "\n",
        "  model = Sequential()\n",
        "  weight_decay = 0.0005\n",
        "  learning_rate = 0.1\n",
        "  lr_decay = 1e-6\n",
        "  lr_drop = 20\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=image_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(total_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  sgd = keras.optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def define_model_standard_cnn(image_shape,total_classes):\n",
        "  initializer = tf.keras.initializers.he_uniform()\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32,(3,3), activation = 'relu',  padding = 'same', input_shape = image_shape))\n",
        "  model.add(Conv2D(32,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))  \n",
        "  model.add(Conv2D(64,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(Conv2D(64,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(128,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(Conv2D(128,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation = 'relu'))\n",
        "  model.add(Dense(total_classes, activation = 'softmax'))\n",
        "  opt = keras.optimizers.SGD(learning_rate=0.1 , momentum=0.9)\n",
        "  model.compile(optimizer=opt,loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MAaxp2hqAR"
      },
      "source": [
        "\n",
        "def identity_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])     \n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def convolutional_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Processing Residue with conv(1,1)\n",
        "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])     \n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet34(shape, classes):\n",
        "    learning_rate = 0.1\n",
        "    lr_decay = 1e-6\n",
        "    # Step 1 (Setup Input Layer)\n",
        "    x_input = tf.keras.layers.Input(shape)\n",
        "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
        "    # Step 2 (Initial Conv layer along with maxPool)\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "    # Define size of sub-blocks and initial filter size\n",
        "    block_layers = [3, 4, 6, 3]\n",
        "    filter_size = 64\n",
        "    # Step 3 Add the Resnet Blocks\n",
        "    for i in range(4):\n",
        "        if i == 0:\n",
        "            # For sub-block 1 Residual/Convolutional block not needed\n",
        "            for j in range(block_layers[i]):\n",
        "                x = identity_block(x, filter_size)\n",
        "        else:\n",
        "            # One Residual/Convolutional Block followed by Identity blocks\n",
        "            # The filter size will go on increasing by a factor of 2\n",
        "            filter_size = filter_size*2\n",
        "            x = convolutional_block(x, filter_size)\n",
        "            for j in range(block_layers[i] - 1):\n",
        "                x = identity_block(x, filter_size)\n",
        "    # Step 4 End Dense Network\n",
        "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
        "    sgd = keras.optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaRAX4NsO-qR"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgsl1X29yf2k"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "def train_model_vgg16(X_train,y_train,X_test,y_test,epochs=10,batch_size=128):\n",
        "  \n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_vgg16', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.9, patience = 7, min_lr = 0.000001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 100)\n",
        "  ]\n",
        "  history=model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size,callbacks = callbacks, verbose = 1,validation_data=(X_test,y_test))\n",
        "  return history\n",
        "\n",
        "def train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=10,batch_size=64):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_standard_cnn', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.9, patience = 3, min_lr = 0.000001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 15)\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size=batch_size , callbacks = callbacks)\n",
        "  return history\n",
        "\n",
        "\n",
        "def train_model_resnet34(X_train,y_train,X_test,y_test,epochs=10,batch_size=64):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_resnet50', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.9, patience = 7, min_lr = 0.000001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 50)\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size= 128 , callbacks = callbacks)\n",
        "  return history"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeJvjs7VO9-u"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6AWutrFy4V8"
      },
      "source": [
        "def make_prediction(model,X_test,index):\n",
        "\n",
        "  return model.predict(X_test(index))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UiQLmEn1vuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10485af4-be03-4f3a-ece9-282ce660758c"
      },
      "source": [
        "\n",
        "'''\n",
        "\n",
        "X_train,y_train,X_test,y_test=select_dataset(2)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar10(X_train,y_train,X_test,y_test,3)\n",
        "model=define_model_standard_cnn(image_shape,10)\n",
        "history_cnn_model = train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=100)\n",
        "model.save('Desktop/cnn_model_cifar10.h5')\n",
        "\n",
        "X_train,y_train,X_test,y_test=select_dataset(2)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar10(X_train,y_train,X_test,y_test,3)\n",
        "model=ResNet34(image_shape,10)\n",
        "history_resnet=train_model_resnet34(X_train,y_train,X_test,y_test,epochs=100)\n",
        "model.save('Desktop/resnet_cifar10.h5') '''\n",
        "\n",
        "X_train,y_train,X_test,y_test=select_dataset(3)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar100(X_train,y_train,X_test,y_test,3)\n",
        "model=define_model_vgg16(image_shape,100)\n",
        "history_vgg16=train_model_vgg16(X_train,y_train,X_test,y_test,epochs=400)\n",
        "model.save('Desktop/vgg16_cifar100.h5')\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "(32, 32, 3)\n",
            "3\n",
            "Epoch 1/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 18.9348 - accuracy: 0.0261\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.01380, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 18.9348 - accuracy: 0.0261 - val_loss: 14.6029 - val_accuracy: 0.0138 - lr: 0.1000\n",
            "Epoch 2/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 10.9565 - accuracy: 0.0465\n",
            "Epoch 00002: val_accuracy improved from 0.01380 to 0.01990, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 10.9467 - accuracy: 0.0465 - val_loss: 9.9447 - val_accuracy: 0.0199 - lr: 0.1000\n",
            "Epoch 3/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 7.1923 - accuracy: 0.0648\n",
            "Epoch 00003: val_accuracy improved from 0.01990 to 0.05000, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 7.1879 - accuracy: 0.0647 - val_loss: 6.4825 - val_accuracy: 0.0500 - lr: 0.1000\n",
            "Epoch 4/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 5.4692 - accuracy: 0.0822\n",
            "Epoch 00004: val_accuracy improved from 0.05000 to 0.06100, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 5.4671 - accuracy: 0.0823 - val_loss: 5.2761 - val_accuracy: 0.0610 - lr: 0.1000\n",
            "Epoch 5/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 4.6857 - accuracy: 0.0986\n",
            "Epoch 00005: val_accuracy improved from 0.06100 to 0.07130, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 4.6842 - accuracy: 0.0988 - val_loss: 5.6938 - val_accuracy: 0.0713 - lr: 0.1000\n",
            "Epoch 6/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 4.3153 - accuracy: 0.1216\n",
            "Epoch 00006: val_accuracy improved from 0.07130 to 0.11920, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 4.3148 - accuracy: 0.1217 - val_loss: 4.3048 - val_accuracy: 0.1192 - lr: 0.1000\n",
            "Epoch 7/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.0546 - accuracy: 0.1424\n",
            "Epoch 00007: val_accuracy improved from 0.11920 to 0.16580, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 4.0546 - accuracy: 0.1424 - val_loss: 3.9662 - val_accuracy: 0.1658 - lr: 0.1000\n",
            "Epoch 8/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.8700 - accuracy: 0.1832\n",
            "Epoch 00008: val_accuracy did not improve from 0.16580\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.8707 - accuracy: 0.1831 - val_loss: 4.3711 - val_accuracy: 0.1425 - lr: 0.1000\n",
            "Epoch 9/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.7343 - accuracy: 0.2245\n",
            "Epoch 00009: val_accuracy improved from 0.16580 to 0.24130, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 3.7343 - accuracy: 0.2247 - val_loss: 3.7219 - val_accuracy: 0.2413 - lr: 0.1000\n",
            "Epoch 10/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6491 - accuracy: 0.2593\n",
            "Epoch 00010: val_accuracy improved from 0.24130 to 0.29030, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.6489 - accuracy: 0.2594 - val_loss: 3.5166 - val_accuracy: 0.2903 - lr: 0.1000\n",
            "Epoch 11/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6182 - accuracy: 0.2841\n",
            "Epoch 00011: val_accuracy did not improve from 0.29030\n",
            "391/391 [==============================] - 12s 29ms/step - loss: 3.6182 - accuracy: 0.2841 - val_loss: 3.7156 - val_accuracy: 0.2832 - lr: 0.1000\n",
            "Epoch 12/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6093 - accuracy: 0.3040\n",
            "Epoch 00012: val_accuracy did not improve from 0.29030\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 3.6098 - accuracy: 0.3039 - val_loss: 3.9287 - val_accuracy: 0.2777 - lr: 0.1000\n",
            "Epoch 13/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6103 - accuracy: 0.3188\n",
            "Epoch 00013: val_accuracy improved from 0.29030 to 0.33160, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 3.6104 - accuracy: 0.3188 - val_loss: 3.7080 - val_accuracy: 0.3316 - lr: 0.1000\n",
            "Epoch 14/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6184 - accuracy: 0.3360\n",
            "Epoch 00014: val_accuracy did not improve from 0.33160\n",
            "391/391 [==============================] - 12s 29ms/step - loss: 3.6193 - accuracy: 0.3360 - val_loss: 3.8110 - val_accuracy: 0.3016 - lr: 0.1000\n",
            "Epoch 15/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6381 - accuracy: 0.3489\n",
            "Epoch 00015: val_accuracy improved from 0.33160 to 0.36120, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 3.6382 - accuracy: 0.3489 - val_loss: 3.6391 - val_accuracy: 0.3612 - lr: 0.1000\n",
            "Epoch 16/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6607 - accuracy: 0.3605\n",
            "Epoch 00016: val_accuracy did not improve from 0.36120\n",
            "391/391 [==============================] - 12s 29ms/step - loss: 3.6613 - accuracy: 0.3604 - val_loss: 3.8387 - val_accuracy: 0.3410 - lr: 0.1000\n",
            "Epoch 17/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6816 - accuracy: 0.3698\n",
            "Epoch 00017: val_accuracy improved from 0.36120 to 0.38090, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.09000000134110452.\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.6813 - accuracy: 0.3699 - val_loss: 3.6780 - val_accuracy: 0.3809 - lr: 0.1000\n",
            "Epoch 18/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6290 - accuracy: 0.3862\n",
            "Epoch 00018: val_accuracy improved from 0.38090 to 0.40930, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.6286 - accuracy: 0.3861 - val_loss: 3.5924 - val_accuracy: 0.4093 - lr: 0.0900\n",
            "Epoch 19/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6150 - accuracy: 0.3983\n",
            "Epoch 00019: val_accuracy did not improve from 0.40930\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6150 - accuracy: 0.3983 - val_loss: 3.6891 - val_accuracy: 0.3919 - lr: 0.0900\n",
            "Epoch 20/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6450 - accuracy: 0.4037\n",
            "Epoch 00020: val_accuracy improved from 0.40930 to 0.41100, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.6450 - accuracy: 0.4037 - val_loss: 3.6950 - val_accuracy: 0.4110 - lr: 0.0900\n",
            "Epoch 21/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6687 - accuracy: 0.4089\n",
            "Epoch 00021: val_accuracy did not improve from 0.41100\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6687 - accuracy: 0.4089 - val_loss: 3.7824 - val_accuracy: 0.4012 - lr: 0.0900\n",
            "Epoch 22/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6851 - accuracy: 0.4174\n",
            "Epoch 00022: val_accuracy did not improve from 0.41100\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6851 - accuracy: 0.4174 - val_loss: 3.9175 - val_accuracy: 0.3897 - lr: 0.0900\n",
            "Epoch 23/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.7217 - accuracy: 0.4164\n",
            "Epoch 00023: val_accuracy improved from 0.41100 to 0.42340, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.7217 - accuracy: 0.4164 - val_loss: 3.6949 - val_accuracy: 0.4234 - lr: 0.0900\n",
            "Epoch 24/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.7257 - accuracy: 0.4267\n",
            "Epoch 00024: val_accuracy did not improve from 0.42340\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.08100000321865082.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.7257 - accuracy: 0.4267 - val_loss: 3.8658 - val_accuracy: 0.4067 - lr: 0.0900\n",
            "Epoch 25/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6707 - accuracy: 0.4393\n",
            "Epoch 00025: val_accuracy did not improve from 0.42340\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6707 - accuracy: 0.4393 - val_loss: 3.8546 - val_accuracy: 0.4129 - lr: 0.0810\n",
            "Epoch 26/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6596 - accuracy: 0.4448\n",
            "Epoch 00026: val_accuracy did not improve from 0.42340\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6596 - accuracy: 0.4448 - val_loss: 3.9072 - val_accuracy: 0.4078 - lr: 0.0810\n",
            "Epoch 27/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6609 - accuracy: 0.4500\n",
            "Epoch 00027: val_accuracy improved from 0.42340 to 0.44220, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.6609 - accuracy: 0.4500 - val_loss: 3.7372 - val_accuracy: 0.4422 - lr: 0.0810\n",
            "Epoch 28/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6780 - accuracy: 0.4503\n",
            "Epoch 00028: val_accuracy did not improve from 0.44220\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6780 - accuracy: 0.4503 - val_loss: 3.9812 - val_accuracy: 0.4024 - lr: 0.0810\n",
            "Epoch 29/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.7008 - accuracy: 0.4514\n",
            "Epoch 00029: val_accuracy improved from 0.44220 to 0.45960, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.7008 - accuracy: 0.4514 - val_loss: 3.7155 - val_accuracy: 0.4596 - lr: 0.0810\n",
            "Epoch 30/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.7118 - accuracy: 0.4564\n",
            "Epoch 00030: val_accuracy improved from 0.45960 to 0.46290, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.7118 - accuracy: 0.4564 - val_loss: 3.7268 - val_accuracy: 0.4629 - lr: 0.0810\n",
            "Epoch 31/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.7300 - accuracy: 0.4595\n",
            "Epoch 00031: val_accuracy did not improve from 0.46290\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.07290000021457672.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.7300 - accuracy: 0.4595 - val_loss: 3.8511 - val_accuracy: 0.4384 - lr: 0.0810\n",
            "Epoch 32/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6513 - accuracy: 0.4745\n",
            "Epoch 00032: val_accuracy did not improve from 0.46290\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6520 - accuracy: 0.4744 - val_loss: 3.7611 - val_accuracy: 0.4569 - lr: 0.0729\n",
            "Epoch 33/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6327 - accuracy: 0.4784\n",
            "Epoch 00033: val_accuracy did not improve from 0.46290\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6327 - accuracy: 0.4784 - val_loss: 3.8106 - val_accuracy: 0.4438 - lr: 0.0729\n",
            "Epoch 34/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6571 - accuracy: 0.4784\n",
            "Epoch 00034: val_accuracy did not improve from 0.46290\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6571 - accuracy: 0.4784 - val_loss: 3.7904 - val_accuracy: 0.4628 - lr: 0.0729\n",
            "Epoch 35/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6713 - accuracy: 0.4812\n",
            "Epoch 00035: val_accuracy did not improve from 0.46290\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6713 - accuracy: 0.4812 - val_loss: 3.8553 - val_accuracy: 0.4479 - lr: 0.0729\n",
            "Epoch 36/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6764 - accuracy: 0.4852\n",
            "Epoch 00036: val_accuracy did not improve from 0.46290\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6764 - accuracy: 0.4852 - val_loss: 4.0319 - val_accuracy: 0.4180 - lr: 0.0729\n",
            "Epoch 37/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6758 - accuracy: 0.4869\n",
            "Epoch 00037: val_accuracy improved from 0.46290 to 0.46620, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.6758 - accuracy: 0.4869 - val_loss: 3.7782 - val_accuracy: 0.4662 - lr: 0.0729\n",
            "Epoch 38/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.7011 - accuracy: 0.4860\n",
            "Epoch 00038: val_accuracy did not improve from 0.46620\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.06560999751091004.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.7011 - accuracy: 0.4860 - val_loss: 3.9017 - val_accuracy: 0.4549 - lr: 0.0729\n",
            "Epoch 39/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6218 - accuracy: 0.5015\n",
            "Epoch 00039: val_accuracy improved from 0.46620 to 0.48320, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 3.6218 - accuracy: 0.5015 - val_loss: 3.6938 - val_accuracy: 0.4832 - lr: 0.0656\n",
            "Epoch 40/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6025 - accuracy: 0.5061\n",
            "Epoch 00040: val_accuracy did not improve from 0.48320\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6025 - accuracy: 0.5061 - val_loss: 3.8253 - val_accuracy: 0.4671 - lr: 0.0656\n",
            "Epoch 41/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6173 - accuracy: 0.5045\n",
            "Epoch 00041: val_accuracy improved from 0.48320 to 0.48400, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.6184 - accuracy: 0.5042 - val_loss: 3.7520 - val_accuracy: 0.4840 - lr: 0.0656\n",
            "Epoch 42/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6308 - accuracy: 0.5071\n",
            "Epoch 00042: val_accuracy did not improve from 0.48400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6308 - accuracy: 0.5071 - val_loss: 3.9347 - val_accuracy: 0.4494 - lr: 0.0656\n",
            "Epoch 43/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6359 - accuracy: 0.5093\n",
            "Epoch 00043: val_accuracy did not improve from 0.48400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6359 - accuracy: 0.5093 - val_loss: 3.9214 - val_accuracy: 0.4590 - lr: 0.0656\n",
            "Epoch 44/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6468 - accuracy: 0.5106\n",
            "Epoch 00044: val_accuracy did not improve from 0.48400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6468 - accuracy: 0.5106 - val_loss: 3.8338 - val_accuracy: 0.4764 - lr: 0.0656\n",
            "Epoch 45/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6552 - accuracy: 0.5131\n",
            "Epoch 00045: val_accuracy did not improve from 0.48400\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.05904899910092354.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6552 - accuracy: 0.5131 - val_loss: 3.8979 - val_accuracy: 0.4783 - lr: 0.0656\n",
            "Epoch 46/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5824 - accuracy: 0.5267\n",
            "Epoch 00046: val_accuracy improved from 0.48400 to 0.50420, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.5824 - accuracy: 0.5267 - val_loss: 3.6612 - val_accuracy: 0.5042 - lr: 0.0590\n",
            "Epoch 47/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5581 - accuracy: 0.5313\n",
            "Epoch 00047: val_accuracy did not improve from 0.50420\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5581 - accuracy: 0.5313 - val_loss: 3.7753 - val_accuracy: 0.4873 - lr: 0.0590\n",
            "Epoch 48/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5628 - accuracy: 0.5300\n",
            "Epoch 00048: val_accuracy did not improve from 0.50420\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5628 - accuracy: 0.5300 - val_loss: 3.7352 - val_accuracy: 0.5022 - lr: 0.0590\n",
            "Epoch 49/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5791 - accuracy: 0.5319\n",
            "Epoch 00049: val_accuracy did not improve from 0.50420\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5791 - accuracy: 0.5319 - val_loss: 3.8045 - val_accuracy: 0.4926 - lr: 0.0590\n",
            "Epoch 50/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5892 - accuracy: 0.5351\n",
            "Epoch 00050: val_accuracy did not improve from 0.50420\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5892 - accuracy: 0.5351 - val_loss: 3.7518 - val_accuracy: 0.5033 - lr: 0.0590\n",
            "Epoch 51/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.5763 - accuracy: 0.5384\n",
            "Epoch 00051: val_accuracy did not improve from 0.50420\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5777 - accuracy: 0.5381 - val_loss: 3.9375 - val_accuracy: 0.4785 - lr: 0.0590\n",
            "Epoch 52/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6224 - accuracy: 0.5360\n",
            "Epoch 00052: val_accuracy did not improve from 0.50420\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.053144099190831184.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.6224 - accuracy: 0.5360 - val_loss: 3.8983 - val_accuracy: 0.4786 - lr: 0.0590\n",
            "Epoch 53/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5211 - accuracy: 0.5536\n",
            "Epoch 00053: val_accuracy improved from 0.50420 to 0.51040, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.5211 - accuracy: 0.5536 - val_loss: 3.7740 - val_accuracy: 0.5104 - lr: 0.0531\n",
            "Epoch 54/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5007 - accuracy: 0.5546\n",
            "Epoch 00054: val_accuracy improved from 0.51040 to 0.53400, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.5007 - accuracy: 0.5546 - val_loss: 3.6282 - val_accuracy: 0.5340 - lr: 0.0531\n",
            "Epoch 55/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.5088 - accuracy: 0.5564\n",
            "Epoch 00055: val_accuracy did not improve from 0.53400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5089 - accuracy: 0.5565 - val_loss: 3.7352 - val_accuracy: 0.5142 - lr: 0.0531\n",
            "Epoch 56/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5284 - accuracy: 0.5535\n",
            "Epoch 00056: val_accuracy did not improve from 0.53400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5284 - accuracy: 0.5535 - val_loss: 3.7269 - val_accuracy: 0.5180 - lr: 0.0531\n",
            "Epoch 57/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5180 - accuracy: 0.5556\n",
            "Epoch 00057: val_accuracy did not improve from 0.53400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5180 - accuracy: 0.5556 - val_loss: 3.7956 - val_accuracy: 0.5145 - lr: 0.0531\n",
            "Epoch 58/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5517 - accuracy: 0.5569\n",
            "Epoch 00058: val_accuracy did not improve from 0.53400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5517 - accuracy: 0.5569 - val_loss: 3.7443 - val_accuracy: 0.5219 - lr: 0.0531\n",
            "Epoch 59/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5642 - accuracy: 0.5599\n",
            "Epoch 00059: val_accuracy did not improve from 0.53400\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.04782968759536743.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5642 - accuracy: 0.5599 - val_loss: 3.8017 - val_accuracy: 0.5130 - lr: 0.0531\n",
            "Epoch 60/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4820 - accuracy: 0.5754\n",
            "Epoch 00060: val_accuracy did not improve from 0.53400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.4820 - accuracy: 0.5754 - val_loss: 3.7443 - val_accuracy: 0.5238 - lr: 0.0478\n",
            "Epoch 61/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4687 - accuracy: 0.5756\n",
            "Epoch 00061: val_accuracy did not improve from 0.53400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.4687 - accuracy: 0.5756 - val_loss: 3.7260 - val_accuracy: 0.5304 - lr: 0.0478\n",
            "Epoch 62/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4753 - accuracy: 0.5739\n",
            "Epoch 00062: val_accuracy improved from 0.53400 to 0.53660, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.4753 - accuracy: 0.5739 - val_loss: 3.6769 - val_accuracy: 0.5366 - lr: 0.0478\n",
            "Epoch 63/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4888 - accuracy: 0.5758\n",
            "Epoch 00063: val_accuracy did not improve from 0.53660\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.4888 - accuracy: 0.5758 - val_loss: 3.6995 - val_accuracy: 0.5358 - lr: 0.0478\n",
            "Epoch 64/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4848 - accuracy: 0.5788\n",
            "Epoch 00064: val_accuracy did not improve from 0.53660\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.4848 - accuracy: 0.5788 - val_loss: 3.7086 - val_accuracy: 0.5363 - lr: 0.0478\n",
            "Epoch 65/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5005 - accuracy: 0.5794\n",
            "Epoch 00065: val_accuracy improved from 0.53660 to 0.54180, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.5005 - accuracy: 0.5794 - val_loss: 3.6900 - val_accuracy: 0.5418 - lr: 0.0478\n",
            "Epoch 66/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.5063 - accuracy: 0.5797\n",
            "Epoch 00066: val_accuracy did not improve from 0.54180\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.04304671883583069.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.5063 - accuracy: 0.5797 - val_loss: 3.7338 - val_accuracy: 0.5415 - lr: 0.0478\n",
            "Epoch 67/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4188 - accuracy: 0.5946\n",
            "Epoch 00067: val_accuracy improved from 0.54180 to 0.54800, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.4188 - accuracy: 0.5946 - val_loss: 3.6591 - val_accuracy: 0.5480 - lr: 0.0430\n",
            "Epoch 68/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4179 - accuracy: 0.5951\n",
            "Epoch 00068: val_accuracy did not improve from 0.54800\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.4179 - accuracy: 0.5951 - val_loss: 3.7116 - val_accuracy: 0.5395 - lr: 0.0430\n",
            "Epoch 69/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4167 - accuracy: 0.5996\n",
            "Epoch 00069: val_accuracy improved from 0.54800 to 0.55520, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.4167 - accuracy: 0.5996 - val_loss: 3.6827 - val_accuracy: 0.5552 - lr: 0.0430\n",
            "Epoch 70/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4287 - accuracy: 0.5992\n",
            "Epoch 00070: val_accuracy improved from 0.55520 to 0.55530, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 3.4287 - accuracy: 0.5992 - val_loss: 3.6688 - val_accuracy: 0.5553 - lr: 0.0430\n",
            "Epoch 71/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4382 - accuracy: 0.6007\n",
            "Epoch 00071: val_accuracy did not improve from 0.55530\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.4382 - accuracy: 0.6007 - val_loss: 3.7234 - val_accuracy: 0.5447 - lr: 0.0430\n",
            "Epoch 72/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4483 - accuracy: 0.6029\n",
            "Epoch 00072: val_accuracy did not improve from 0.55530\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.4483 - accuracy: 0.6029 - val_loss: 3.7454 - val_accuracy: 0.5435 - lr: 0.0430\n",
            "Epoch 73/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4707 - accuracy: 0.6013\n",
            "Epoch 00073: val_accuracy improved from 0.55530 to 0.56030, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.03874204829335213.\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.4707 - accuracy: 0.6013 - val_loss: 3.6811 - val_accuracy: 0.5603 - lr: 0.0430\n",
            "Epoch 74/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4004 - accuracy: 0.6164\n",
            "Epoch 00074: val_accuracy did not improve from 0.56030\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.4004 - accuracy: 0.6164 - val_loss: 3.6878 - val_accuracy: 0.5575 - lr: 0.0387\n",
            "Epoch 75/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.3568 - accuracy: 0.6193\n",
            "Epoch 00075: val_accuracy did not improve from 0.56030\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.3568 - accuracy: 0.6193 - val_loss: 3.8260 - val_accuracy: 0.5281 - lr: 0.0387\n",
            "Epoch 76/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.3634 - accuracy: 0.6170\n",
            "Epoch 00076: val_accuracy improved from 0.56030 to 0.56620, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.3634 - accuracy: 0.6170 - val_loss: 3.6478 - val_accuracy: 0.5662 - lr: 0.0387\n",
            "Epoch 77/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.3665 - accuracy: 0.6181\n",
            "Epoch 00077: val_accuracy did not improve from 0.56620\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.3665 - accuracy: 0.6181 - val_loss: 3.8043 - val_accuracy: 0.5383 - lr: 0.0387\n",
            "Epoch 78/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.3820 - accuracy: 0.6190\n",
            "Epoch 00078: val_accuracy did not improve from 0.56620\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.3826 - accuracy: 0.6190 - val_loss: 3.8164 - val_accuracy: 0.5433 - lr: 0.0387\n",
            "Epoch 79/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.3946 - accuracy: 0.6227\n",
            "Epoch 00079: val_accuracy improved from 0.56620 to 0.56750, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.3946 - accuracy: 0.6227 - val_loss: 3.6886 - val_accuracy: 0.5675 - lr: 0.0387\n",
            "Epoch 80/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4186 - accuracy: 0.6188\n",
            "Epoch 00080: val_accuracy improved from 0.56750 to 0.57300, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.034867842122912406.\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.4186 - accuracy: 0.6188 - val_loss: 3.6881 - val_accuracy: 0.5730 - lr: 0.0387\n",
            "Epoch 81/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.3213 - accuracy: 0.6370\n",
            "Epoch 00081: val_accuracy improved from 0.57300 to 0.57600, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.3213 - accuracy: 0.6370 - val_loss: 3.6071 - val_accuracy: 0.5760 - lr: 0.0349\n",
            "Epoch 82/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2733 - accuracy: 0.6437\n",
            "Epoch 00082: val_accuracy did not improve from 0.57600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.2733 - accuracy: 0.6437 - val_loss: 3.6085 - val_accuracy: 0.5735 - lr: 0.0349\n",
            "Epoch 83/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2782 - accuracy: 0.6417\n",
            "Epoch 00083: val_accuracy did not improve from 0.57600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.2782 - accuracy: 0.6417 - val_loss: 3.6670 - val_accuracy: 0.5714 - lr: 0.0349\n",
            "Epoch 84/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2963 - accuracy: 0.6381\n",
            "Epoch 00084: val_accuracy did not improve from 0.57600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.2963 - accuracy: 0.6381 - val_loss: 3.7074 - val_accuracy: 0.5657 - lr: 0.0349\n",
            "Epoch 85/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.3034 - accuracy: 0.6408\n",
            "Epoch 00085: val_accuracy improved from 0.57600 to 0.57790, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.3034 - accuracy: 0.6408 - val_loss: 3.6457 - val_accuracy: 0.5779 - lr: 0.0349\n",
            "Epoch 86/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.3141 - accuracy: 0.6402\n",
            "Epoch 00086: val_accuracy did not improve from 0.57790\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.3141 - accuracy: 0.6402 - val_loss: 3.7371 - val_accuracy: 0.5614 - lr: 0.0349\n",
            "Epoch 87/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.3111 - accuracy: 0.6431\n",
            "Epoch 00087: val_accuracy did not improve from 0.57790\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.03138105757534504.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.3117 - accuracy: 0.6430 - val_loss: 3.7414 - val_accuracy: 0.5616 - lr: 0.0349\n",
            "Epoch 88/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2572 - accuracy: 0.6562\n",
            "Epoch 00088: val_accuracy improved from 0.57790 to 0.58440, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 3.2572 - accuracy: 0.6562 - val_loss: 3.6445 - val_accuracy: 0.5844 - lr: 0.0314\n",
            "Epoch 89/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2346 - accuracy: 0.6561\n",
            "Epoch 00089: val_accuracy improved from 0.58440 to 0.58820, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.2346 - accuracy: 0.6561 - val_loss: 3.6004 - val_accuracy: 0.5882 - lr: 0.0314\n",
            "Epoch 90/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2257 - accuracy: 0.6601\n",
            "Epoch 00090: val_accuracy did not improve from 0.58820\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.2257 - accuracy: 0.6601 - val_loss: 3.6031 - val_accuracy: 0.5877 - lr: 0.0314\n",
            "Epoch 91/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2061 - accuracy: 0.6632\n",
            "Epoch 00091: val_accuracy did not improve from 0.58820\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.2061 - accuracy: 0.6632 - val_loss: 3.6069 - val_accuracy: 0.5825 - lr: 0.0314\n",
            "Epoch 92/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2390 - accuracy: 0.6579\n",
            "Epoch 00092: val_accuracy did not improve from 0.58820\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.2390 - accuracy: 0.6579 - val_loss: 3.6496 - val_accuracy: 0.5830 - lr: 0.0314\n",
            "Epoch 93/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2341 - accuracy: 0.6642\n",
            "Epoch 00093: val_accuracy did not improve from 0.58820\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.2341 - accuracy: 0.6642 - val_loss: 3.6840 - val_accuracy: 0.5782 - lr: 0.0314\n",
            "Epoch 94/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2638 - accuracy: 0.6574\n",
            "Epoch 00094: val_accuracy did not improve from 0.58820\n",
            "\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.028242950141429902.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.2638 - accuracy: 0.6574 - val_loss: 3.7648 - val_accuracy: 0.5715 - lr: 0.0314\n",
            "Epoch 95/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1964 - accuracy: 0.6742\n",
            "Epoch 00095: val_accuracy did not improve from 0.58820\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.1964 - accuracy: 0.6742 - val_loss: 3.7328 - val_accuracy: 0.5772 - lr: 0.0282\n",
            "Epoch 96/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1542 - accuracy: 0.6779\n",
            "Epoch 00096: val_accuracy did not improve from 0.58820\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.1542 - accuracy: 0.6779 - val_loss: 3.6418 - val_accuracy: 0.5868 - lr: 0.0282\n",
            "Epoch 97/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1727 - accuracy: 0.6740\n",
            "Epoch 00097: val_accuracy did not improve from 0.58820\n",
            "391/391 [==============================] - 12s 31ms/step - loss: 3.1727 - accuracy: 0.6740 - val_loss: 3.6512 - val_accuracy: 0.5865 - lr: 0.0282\n",
            "Epoch 98/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1536 - accuracy: 0.6810\n",
            "Epoch 00098: val_accuracy improved from 0.58820 to 0.59120, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.1536 - accuracy: 0.6810 - val_loss: 3.6575 - val_accuracy: 0.5912 - lr: 0.0282\n",
            "Epoch 99/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1606 - accuracy: 0.6779\n",
            "Epoch 00099: val_accuracy improved from 0.59120 to 0.59480, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.1606 - accuracy: 0.6779 - val_loss: 3.6069 - val_accuracy: 0.5948 - lr: 0.0282\n",
            "Epoch 100/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1655 - accuracy: 0.6788\n",
            "Epoch 00100: val_accuracy improved from 0.59480 to 0.59680, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.1655 - accuracy: 0.6788 - val_loss: 3.6268 - val_accuracy: 0.5968 - lr: 0.0282\n",
            "Epoch 101/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1665 - accuracy: 0.6832\n",
            "Epoch 00101: val_accuracy did not improve from 0.59680\n",
            "\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.02541865445673466.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.1665 - accuracy: 0.6832 - val_loss: 3.6540 - val_accuracy: 0.5854 - lr: 0.0282\n",
            "Epoch 102/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0837 - accuracy: 0.6980\n",
            "Epoch 00102: val_accuracy improved from 0.59680 to 0.61600, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 3.0837 - accuracy: 0.6980 - val_loss: 3.5010 - val_accuracy: 0.6160 - lr: 0.0254\n",
            "Epoch 103/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0819 - accuracy: 0.6946\n",
            "Epoch 00103: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.0819 - accuracy: 0.6946 - val_loss: 3.6471 - val_accuracy: 0.5853 - lr: 0.0254\n",
            "Epoch 104/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0704 - accuracy: 0.6965\n",
            "Epoch 00104: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.0704 - accuracy: 0.6965 - val_loss: 3.5722 - val_accuracy: 0.6050 - lr: 0.0254\n",
            "Epoch 105/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0750 - accuracy: 0.6960\n",
            "Epoch 00105: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.0750 - accuracy: 0.6960 - val_loss: 3.7311 - val_accuracy: 0.5825 - lr: 0.0254\n",
            "Epoch 106/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0747 - accuracy: 0.6989\n",
            "Epoch 00106: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.0747 - accuracy: 0.6989 - val_loss: 3.6311 - val_accuracy: 0.5917 - lr: 0.0254\n",
            "Epoch 107/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0748 - accuracy: 0.6993\n",
            "Epoch 00107: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.0748 - accuracy: 0.6993 - val_loss: 3.7177 - val_accuracy: 0.5825 - lr: 0.0254\n",
            "Epoch 108/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0872 - accuracy: 0.6994\n",
            "Epoch 00108: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.0872 - accuracy: 0.6994 - val_loss: 3.5911 - val_accuracy: 0.6011 - lr: 0.0254\n",
            "Epoch 109/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0804 - accuracy: 0.7002\n",
            "Epoch 00109: val_accuracy did not improve from 0.61600\n",
            "\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.022876788675785065.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.0804 - accuracy: 0.7002 - val_loss: 3.6616 - val_accuracy: 0.5892 - lr: 0.0254\n",
            "Epoch 110/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0098 - accuracy: 0.7160\n",
            "Epoch 00110: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 3.0098 - accuracy: 0.7160 - val_loss: 3.6009 - val_accuracy: 0.6041 - lr: 0.0229\n",
            "Epoch 111/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9745 - accuracy: 0.7192\n",
            "Epoch 00111: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9745 - accuracy: 0.7192 - val_loss: 3.5688 - val_accuracy: 0.6128 - lr: 0.0229\n",
            "Epoch 112/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9829 - accuracy: 0.7147\n",
            "Epoch 00112: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9829 - accuracy: 0.7147 - val_loss: 3.6692 - val_accuracy: 0.5885 - lr: 0.0229\n",
            "Epoch 113/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9801 - accuracy: 0.7153\n",
            "Epoch 00113: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9801 - accuracy: 0.7153 - val_loss: 3.6491 - val_accuracy: 0.5907 - lr: 0.0229\n",
            "Epoch 114/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9878 - accuracy: 0.7153\n",
            "Epoch 00114: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9878 - accuracy: 0.7153 - val_loss: 3.6230 - val_accuracy: 0.5989 - lr: 0.0229\n",
            "Epoch 115/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9860 - accuracy: 0.7183\n",
            "Epoch 00115: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9860 - accuracy: 0.7183 - val_loss: 3.6142 - val_accuracy: 0.6046 - lr: 0.0229\n",
            "Epoch 116/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9941 - accuracy: 0.7173\n",
            "Epoch 00116: val_accuracy did not improve from 0.61600\n",
            "\n",
            "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.020589109137654306.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9941 - accuracy: 0.7173 - val_loss: 3.6265 - val_accuracy: 0.5966 - lr: 0.0229\n",
            "Epoch 117/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9316 - accuracy: 0.7323\n",
            "Epoch 00117: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9316 - accuracy: 0.7323 - val_loss: 3.5184 - val_accuracy: 0.6159 - lr: 0.0206\n",
            "Epoch 118/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8986 - accuracy: 0.7347\n",
            "Epoch 00118: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.8986 - accuracy: 0.7347 - val_loss: 3.6322 - val_accuracy: 0.5995 - lr: 0.0206\n",
            "Epoch 119/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8873 - accuracy: 0.7358\n",
            "Epoch 00119: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.8873 - accuracy: 0.7358 - val_loss: 3.5737 - val_accuracy: 0.6068 - lr: 0.0206\n",
            "Epoch 120/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8972 - accuracy: 0.7333\n",
            "Epoch 00120: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.8972 - accuracy: 0.7333 - val_loss: 3.6134 - val_accuracy: 0.6007 - lr: 0.0206\n",
            "Epoch 121/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8899 - accuracy: 0.7360\n",
            "Epoch 00121: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 31ms/step - loss: 2.8899 - accuracy: 0.7360 - val_loss: 3.5369 - val_accuracy: 0.6155 - lr: 0.0206\n",
            "Epoch 122/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9001 - accuracy: 0.7341\n",
            "Epoch 00122: val_accuracy did not improve from 0.61600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9001 - accuracy: 0.7341 - val_loss: 3.5994 - val_accuracy: 0.6036 - lr: 0.0206\n",
            "Epoch 123/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9037 - accuracy: 0.7382\n",
            "Epoch 00123: val_accuracy did not improve from 0.61600\n",
            "\n",
            "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.018530198559165.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.9037 - accuracy: 0.7382 - val_loss: 3.6114 - val_accuracy: 0.6036 - lr: 0.0206\n",
            "Epoch 124/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8395 - accuracy: 0.7489\n",
            "Epoch 00124: val_accuracy improved from 0.61600 to 0.61910, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.8395 - accuracy: 0.7489 - val_loss: 3.5209 - val_accuracy: 0.6191 - lr: 0.0185\n",
            "Epoch 125/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8073 - accuracy: 0.7523\n",
            "Epoch 00125: val_accuracy did not improve from 0.61910\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.8073 - accuracy: 0.7523 - val_loss: 3.5612 - val_accuracy: 0.6142 - lr: 0.0185\n",
            "Epoch 126/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7932 - accuracy: 0.7561\n",
            "Epoch 00126: val_accuracy did not improve from 0.61910\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7932 - accuracy: 0.7561 - val_loss: 3.5799 - val_accuracy: 0.6087 - lr: 0.0185\n",
            "Epoch 127/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8074 - accuracy: 0.7525\n",
            "Epoch 00127: val_accuracy improved from 0.61910 to 0.62490, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.8074 - accuracy: 0.7525 - val_loss: 3.4950 - val_accuracy: 0.6249 - lr: 0.0185\n",
            "Epoch 128/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7871 - accuracy: 0.7539\n",
            "Epoch 00128: val_accuracy did not improve from 0.62490\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7871 - accuracy: 0.7539 - val_loss: 3.5611 - val_accuracy: 0.6080 - lr: 0.0185\n",
            "Epoch 129/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7964 - accuracy: 0.7542\n",
            "Epoch 00129: val_accuracy did not improve from 0.62490\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7964 - accuracy: 0.7542 - val_loss: 3.6286 - val_accuracy: 0.5953 - lr: 0.0185\n",
            "Epoch 130/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7967 - accuracy: 0.7540\n",
            "Epoch 00130: val_accuracy did not improve from 0.62490\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7967 - accuracy: 0.7540 - val_loss: 3.5673 - val_accuracy: 0.6100 - lr: 0.0185\n",
            "Epoch 131/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8010 - accuracy: 0.7529\n",
            "Epoch 00131: val_accuracy did not improve from 0.62490\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.8010 - accuracy: 0.7529 - val_loss: 3.5623 - val_accuracy: 0.6150 - lr: 0.0185\n",
            "Epoch 132/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8071 - accuracy: 0.7533\n",
            "Epoch 00132: val_accuracy did not improve from 0.62490\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.8071 - accuracy: 0.7533 - val_loss: 3.5737 - val_accuracy: 0.6126 - lr: 0.0185\n",
            "Epoch 133/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8175 - accuracy: 0.7532\n",
            "Epoch 00133: val_accuracy did not improve from 0.62490\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.8175 - accuracy: 0.7532 - val_loss: 3.6516 - val_accuracy: 0.6042 - lr: 0.0185\n",
            "Epoch 134/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8347 - accuracy: 0.7518\n",
            "Epoch 00134: val_accuracy improved from 0.62490 to 0.62510, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.016677179373800755.\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.8347 - accuracy: 0.7518 - val_loss: 3.5391 - val_accuracy: 0.6251 - lr: 0.0185\n",
            "Epoch 135/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7594 - accuracy: 0.7703\n",
            "Epoch 00135: val_accuracy did not improve from 0.62510\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7594 - accuracy: 0.7703 - val_loss: 3.5781 - val_accuracy: 0.6173 - lr: 0.0167\n",
            "Epoch 136/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7250 - accuracy: 0.7764\n",
            "Epoch 00136: val_accuracy did not improve from 0.62510\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7250 - accuracy: 0.7764 - val_loss: 3.5742 - val_accuracy: 0.6150 - lr: 0.0167\n",
            "Epoch 137/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.7240 - accuracy: 0.7725\n",
            "Epoch 00137: val_accuracy did not improve from 0.62510\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7245 - accuracy: 0.7724 - val_loss: 3.5359 - val_accuracy: 0.6217 - lr: 0.0167\n",
            "Epoch 138/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7094 - accuracy: 0.7732\n",
            "Epoch 00138: val_accuracy did not improve from 0.62510\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7094 - accuracy: 0.7732 - val_loss: 3.5637 - val_accuracy: 0.6163 - lr: 0.0167\n",
            "Epoch 139/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7183 - accuracy: 0.7754\n",
            "Epoch 00139: val_accuracy did not improve from 0.62510\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7183 - accuracy: 0.7754 - val_loss: 3.5291 - val_accuracy: 0.6205 - lr: 0.0167\n",
            "Epoch 140/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7031 - accuracy: 0.7767\n",
            "Epoch 00140: val_accuracy did not improve from 0.62510\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.7031 - accuracy: 0.7767 - val_loss: 3.5853 - val_accuracy: 0.6125 - lr: 0.0167\n",
            "Epoch 141/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7145 - accuracy: 0.7750\n",
            "Epoch 00141: val_accuracy improved from 0.62510 to 0.62570, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "\n",
            "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.015009460598230362.\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.7145 - accuracy: 0.7750 - val_loss: 3.5120 - val_accuracy: 0.6257 - lr: 0.0167\n",
            "Epoch 142/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6647 - accuracy: 0.7867\n",
            "Epoch 00142: val_accuracy improved from 0.62570 to 0.63160, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.6647 - accuracy: 0.7867 - val_loss: 3.4783 - val_accuracy: 0.6316 - lr: 0.0150\n",
            "Epoch 143/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6255 - accuracy: 0.7921\n",
            "Epoch 00143: val_accuracy did not improve from 0.63160\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.6255 - accuracy: 0.7921 - val_loss: 3.4986 - val_accuracy: 0.6305 - lr: 0.0150\n",
            "Epoch 144/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6059 - accuracy: 0.7949\n",
            "Epoch 00144: val_accuracy did not improve from 0.63160\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.6059 - accuracy: 0.7949 - val_loss: 3.5520 - val_accuracy: 0.6223 - lr: 0.0150\n",
            "Epoch 145/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6128 - accuracy: 0.7904\n",
            "Epoch 00145: val_accuracy did not improve from 0.63160\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.6128 - accuracy: 0.7904 - val_loss: 3.5117 - val_accuracy: 0.6256 - lr: 0.0150\n",
            "Epoch 146/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.6148 - accuracy: 0.7906\n",
            "Epoch 00146: val_accuracy did not improve from 0.63160\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.6154 - accuracy: 0.7904 - val_loss: 3.5781 - val_accuracy: 0.6157 - lr: 0.0150\n",
            "Epoch 147/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6159 - accuracy: 0.7897\n",
            "Epoch 00147: val_accuracy did not improve from 0.63160\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.6159 - accuracy: 0.7897 - val_loss: 3.5747 - val_accuracy: 0.6144 - lr: 0.0150\n",
            "Epoch 148/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6193 - accuracy: 0.7909\n",
            "Epoch 00148: val_accuracy did not improve from 0.63160\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.6193 - accuracy: 0.7909 - val_loss: 3.4967 - val_accuracy: 0.6300 - lr: 0.0150\n",
            "Epoch 149/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6108 - accuracy: 0.7913\n",
            "Epoch 00149: val_accuracy did not improve from 0.63160\n",
            "\n",
            "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.013508514873683453.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.6108 - accuracy: 0.7913 - val_loss: 3.5736 - val_accuracy: 0.6161 - lr: 0.0150\n",
            "Epoch 150/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5680 - accuracy: 0.8045\n",
            "Epoch 00150: val_accuracy improved from 0.63160 to 0.63400, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 2.5680 - accuracy: 0.8045 - val_loss: 3.5008 - val_accuracy: 0.6340 - lr: 0.0135\n",
            "Epoch 151/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5270 - accuracy: 0.8071\n",
            "Epoch 00151: val_accuracy did not improve from 0.63400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.5270 - accuracy: 0.8071 - val_loss: 3.5585 - val_accuracy: 0.6205 - lr: 0.0135\n",
            "Epoch 152/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.5139 - accuracy: 0.8102\n",
            "Epoch 00152: val_accuracy improved from 0.63400 to 0.63600, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.5147 - accuracy: 0.8101 - val_loss: 3.4821 - val_accuracy: 0.6360 - lr: 0.0135\n",
            "Epoch 153/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4990 - accuracy: 0.8108\n",
            "Epoch 00153: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.4990 - accuracy: 0.8108 - val_loss: 3.5266 - val_accuracy: 0.6277 - lr: 0.0135\n",
            "Epoch 154/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5114 - accuracy: 0.8077\n",
            "Epoch 00154: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.5114 - accuracy: 0.8077 - val_loss: 3.5837 - val_accuracy: 0.6155 - lr: 0.0135\n",
            "Epoch 155/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5127 - accuracy: 0.8071\n",
            "Epoch 00155: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.5127 - accuracy: 0.8071 - val_loss: 3.5073 - val_accuracy: 0.6255 - lr: 0.0135\n",
            "Epoch 156/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4977 - accuracy: 0.8111\n",
            "Epoch 00156: val_accuracy did not improve from 0.63600\n",
            "\n",
            "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.012157663051038981.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.4977 - accuracy: 0.8111 - val_loss: 3.5801 - val_accuracy: 0.6134 - lr: 0.0135\n",
            "Epoch 157/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4446 - accuracy: 0.8206\n",
            "Epoch 00157: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.4446 - accuracy: 0.8206 - val_loss: 3.4734 - val_accuracy: 0.6353 - lr: 0.0122\n",
            "Epoch 158/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4100 - accuracy: 0.8261\n",
            "Epoch 00158: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.4100 - accuracy: 0.8261 - val_loss: 3.5045 - val_accuracy: 0.6246 - lr: 0.0122\n",
            "Epoch 159/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4143 - accuracy: 0.8240\n",
            "Epoch 00159: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.4143 - accuracy: 0.8240 - val_loss: 3.4953 - val_accuracy: 0.6295 - lr: 0.0122\n",
            "Epoch 160/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4002 - accuracy: 0.8250\n",
            "Epoch 00160: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.4002 - accuracy: 0.8250 - val_loss: 3.5204 - val_accuracy: 0.6251 - lr: 0.0122\n",
            "Epoch 161/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4102 - accuracy: 0.8213\n",
            "Epoch 00161: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.4102 - accuracy: 0.8213 - val_loss: 3.4844 - val_accuracy: 0.6282 - lr: 0.0122\n",
            "Epoch 162/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3919 - accuracy: 0.8261\n",
            "Epoch 00162: val_accuracy did not improve from 0.63600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3919 - accuracy: 0.8261 - val_loss: 3.4727 - val_accuracy: 0.6279 - lr: 0.0122\n",
            "Epoch 163/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4037 - accuracy: 0.8208\n",
            "Epoch 00163: val_accuracy improved from 0.63600 to 0.63680, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.4037 - accuracy: 0.8208 - val_loss: 3.4284 - val_accuracy: 0.6368 - lr: 0.0122\n",
            "Epoch 164/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.3778 - accuracy: 0.8288\n",
            "Epoch 00164: val_accuracy did not improve from 0.63680\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3781 - accuracy: 0.8286 - val_loss: 3.4661 - val_accuracy: 0.6368 - lr: 0.0122\n",
            "Epoch 165/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3949 - accuracy: 0.8227\n",
            "Epoch 00165: val_accuracy did not improve from 0.63680\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3949 - accuracy: 0.8227 - val_loss: 3.4715 - val_accuracy: 0.6344 - lr: 0.0122\n",
            "Epoch 166/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3970 - accuracy: 0.8234\n",
            "Epoch 00166: val_accuracy did not improve from 0.63680\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3970 - accuracy: 0.8234 - val_loss: 3.4399 - val_accuracy: 0.6352 - lr: 0.0122\n",
            "Epoch 167/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3850 - accuracy: 0.8273\n",
            "Epoch 00167: val_accuracy did not improve from 0.63680\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3850 - accuracy: 0.8273 - val_loss: 3.5207 - val_accuracy: 0.6246 - lr: 0.0122\n",
            "Epoch 168/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3889 - accuracy: 0.8245\n",
            "Epoch 00168: val_accuracy did not improve from 0.63680\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3889 - accuracy: 0.8245 - val_loss: 3.5216 - val_accuracy: 0.6222 - lr: 0.0122\n",
            "Epoch 169/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3985 - accuracy: 0.8226\n",
            "Epoch 00169: val_accuracy did not improve from 0.63680\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3985 - accuracy: 0.8226 - val_loss: 3.5124 - val_accuracy: 0.6255 - lr: 0.0122\n",
            "Epoch 170/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3952 - accuracy: 0.8247\n",
            "Epoch 00170: val_accuracy did not improve from 0.63680\n",
            "\n",
            "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.010941896494477988.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3952 - accuracy: 0.8247 - val_loss: 3.4937 - val_accuracy: 0.6319 - lr: 0.0122\n",
            "Epoch 171/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3393 - accuracy: 0.8386\n",
            "Epoch 00171: val_accuracy improved from 0.63680 to 0.64520, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.3393 - accuracy: 0.8386 - val_loss: 3.4054 - val_accuracy: 0.6452 - lr: 0.0109\n",
            "Epoch 172/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.3034 - accuracy: 0.8453\n",
            "Epoch 00172: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.3033 - accuracy: 0.8454 - val_loss: 3.4830 - val_accuracy: 0.6279 - lr: 0.0109\n",
            "Epoch 173/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2903 - accuracy: 0.8431\n",
            "Epoch 00173: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2903 - accuracy: 0.8431 - val_loss: 3.4384 - val_accuracy: 0.6414 - lr: 0.0109\n",
            "Epoch 174/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2898 - accuracy: 0.8417\n",
            "Epoch 00174: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2898 - accuracy: 0.8417 - val_loss: 3.4645 - val_accuracy: 0.6348 - lr: 0.0109\n",
            "Epoch 175/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.2921 - accuracy: 0.8390\n",
            "Epoch 00175: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2926 - accuracy: 0.8388 - val_loss: 3.4325 - val_accuracy: 0.6338 - lr: 0.0109\n",
            "Epoch 176/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2857 - accuracy: 0.8419\n",
            "Epoch 00176: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2857 - accuracy: 0.8419 - val_loss: 3.4245 - val_accuracy: 0.6389 - lr: 0.0109\n",
            "Epoch 177/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2694 - accuracy: 0.8459\n",
            "Epoch 00177: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2694 - accuracy: 0.8459 - val_loss: 3.4040 - val_accuracy: 0.6394 - lr: 0.0109\n",
            "Epoch 178/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2747 - accuracy: 0.8414\n",
            "Epoch 00178: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2747 - accuracy: 0.8414 - val_loss: 3.4369 - val_accuracy: 0.6362 - lr: 0.0109\n",
            "Epoch 179/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2901 - accuracy: 0.8379\n",
            "Epoch 00179: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2901 - accuracy: 0.8379 - val_loss: 3.4667 - val_accuracy: 0.6343 - lr: 0.0109\n",
            "Epoch 180/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2811 - accuracy: 0.8404\n",
            "Epoch 00180: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2811 - accuracy: 0.8404 - val_loss: 3.4887 - val_accuracy: 0.6252 - lr: 0.0109\n",
            "Epoch 181/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2617 - accuracy: 0.8466\n",
            "Epoch 00181: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2617 - accuracy: 0.8466 - val_loss: 3.4367 - val_accuracy: 0.6366 - lr: 0.0109\n",
            "Epoch 182/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2780 - accuracy: 0.8408\n",
            "Epoch 00182: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2780 - accuracy: 0.8408 - val_loss: 3.4230 - val_accuracy: 0.6398 - lr: 0.0109\n",
            "Epoch 183/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2793 - accuracy: 0.8411\n",
            "Epoch 00183: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2793 - accuracy: 0.8411 - val_loss: 3.4605 - val_accuracy: 0.6292 - lr: 0.0109\n",
            "Epoch 184/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2665 - accuracy: 0.8465\n",
            "Epoch 00184: val_accuracy did not improve from 0.64520\n",
            "\n",
            "Epoch 00184: ReduceLROnPlateau reducing learning rate to 0.009847706928849221.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2665 - accuracy: 0.8465 - val_loss: 3.4527 - val_accuracy: 0.6406 - lr: 0.0109\n",
            "Epoch 185/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2248 - accuracy: 0.8564\n",
            "Epoch 00185: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.2248 - accuracy: 0.8564 - val_loss: 3.4444 - val_accuracy: 0.6416 - lr: 0.0098\n",
            "Epoch 186/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1791 - accuracy: 0.8641\n",
            "Epoch 00186: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1791 - accuracy: 0.8641 - val_loss: 3.3965 - val_accuracy: 0.6420 - lr: 0.0098\n",
            "Epoch 187/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1723 - accuracy: 0.8610\n",
            "Epoch 00187: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1723 - accuracy: 0.8610 - val_loss: 3.4264 - val_accuracy: 0.6432 - lr: 0.0098\n",
            "Epoch 188/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1834 - accuracy: 0.8572\n",
            "Epoch 00188: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1834 - accuracy: 0.8572 - val_loss: 3.3925 - val_accuracy: 0.6432 - lr: 0.0098\n",
            "Epoch 189/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1608 - accuracy: 0.8621\n",
            "Epoch 00189: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1608 - accuracy: 0.8621 - val_loss: 3.4419 - val_accuracy: 0.6346 - lr: 0.0098\n",
            "Epoch 190/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1551 - accuracy: 0.8599\n",
            "Epoch 00190: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1551 - accuracy: 0.8599 - val_loss: 3.4470 - val_accuracy: 0.6326 - lr: 0.0098\n",
            "Epoch 191/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1571 - accuracy: 0.8583\n",
            "Epoch 00191: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1571 - accuracy: 0.8583 - val_loss: 3.3661 - val_accuracy: 0.6402 - lr: 0.0098\n",
            "Epoch 192/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1307 - accuracy: 0.8638\n",
            "Epoch 00192: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1307 - accuracy: 0.8638 - val_loss: 3.4760 - val_accuracy: 0.6270 - lr: 0.0098\n",
            "Epoch 193/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1437 - accuracy: 0.8605\n",
            "Epoch 00193: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1437 - accuracy: 0.8605 - val_loss: 3.3781 - val_accuracy: 0.6435 - lr: 0.0098\n",
            "Epoch 194/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1415 - accuracy: 0.8604\n",
            "Epoch 00194: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1415 - accuracy: 0.8604 - val_loss: 3.4369 - val_accuracy: 0.6345 - lr: 0.0098\n",
            "Epoch 195/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1452 - accuracy: 0.8600\n",
            "Epoch 00195: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1452 - accuracy: 0.8600 - val_loss: 3.3902 - val_accuracy: 0.6410 - lr: 0.0098\n",
            "Epoch 196/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1479 - accuracy: 0.8583\n",
            "Epoch 00196: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1479 - accuracy: 0.8583 - val_loss: 3.4421 - val_accuracy: 0.6382 - lr: 0.0098\n",
            "Epoch 197/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1500 - accuracy: 0.8574\n",
            "Epoch 00197: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1500 - accuracy: 0.8574 - val_loss: 3.3992 - val_accuracy: 0.6373 - lr: 0.0098\n",
            "Epoch 198/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1373 - accuracy: 0.8622\n",
            "Epoch 00198: val_accuracy did not improve from 0.64520\n",
            "\n",
            "Epoch 00198: ReduceLROnPlateau reducing learning rate to 0.008862936403602362.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.1373 - accuracy: 0.8622 - val_loss: 3.4008 - val_accuracy: 0.6401 - lr: 0.0098\n",
            "Epoch 199/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0900 - accuracy: 0.8738\n",
            "Epoch 00199: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0900 - accuracy: 0.8738 - val_loss: 3.3833 - val_accuracy: 0.6401 - lr: 0.0089\n",
            "Epoch 200/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0741 - accuracy: 0.8741\n",
            "Epoch 00200: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0741 - accuracy: 0.8741 - val_loss: 3.4219 - val_accuracy: 0.6377 - lr: 0.0089\n",
            "Epoch 201/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0714 - accuracy: 0.8719\n",
            "Epoch 00201: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0714 - accuracy: 0.8719 - val_loss: 3.4080 - val_accuracy: 0.6406 - lr: 0.0089\n",
            "Epoch 202/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.0566 - accuracy: 0.8728\n",
            "Epoch 00202: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0572 - accuracy: 0.8726 - val_loss: 3.3679 - val_accuracy: 0.6423 - lr: 0.0089\n",
            "Epoch 203/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0465 - accuracy: 0.8738\n",
            "Epoch 00203: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0465 - accuracy: 0.8738 - val_loss: 3.3637 - val_accuracy: 0.6433 - lr: 0.0089\n",
            "Epoch 204/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0390 - accuracy: 0.8738\n",
            "Epoch 00204: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0390 - accuracy: 0.8738 - val_loss: 3.3813 - val_accuracy: 0.6371 - lr: 0.0089\n",
            "Epoch 205/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0254 - accuracy: 0.8753\n",
            "Epoch 00205: val_accuracy did not improve from 0.64520\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0254 - accuracy: 0.8753 - val_loss: 3.3884 - val_accuracy: 0.6448 - lr: 0.0089\n",
            "Epoch 206/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0384 - accuracy: 0.8736\n",
            "Epoch 00206: val_accuracy improved from 0.64520 to 0.64990, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.0384 - accuracy: 0.8736 - val_loss: 3.3268 - val_accuracy: 0.6499 - lr: 0.0089\n",
            "Epoch 207/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0388 - accuracy: 0.8738\n",
            "Epoch 00207: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0388 - accuracy: 0.8738 - val_loss: 3.3777 - val_accuracy: 0.6398 - lr: 0.0089\n",
            "Epoch 208/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0257 - accuracy: 0.8751\n",
            "Epoch 00208: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0257 - accuracy: 0.8751 - val_loss: 3.4036 - val_accuracy: 0.6339 - lr: 0.0089\n",
            "Epoch 209/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0260 - accuracy: 0.8751\n",
            "Epoch 00209: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0260 - accuracy: 0.8751 - val_loss: 3.3540 - val_accuracy: 0.6366 - lr: 0.0089\n",
            "Epoch 210/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0223 - accuracy: 0.8743\n",
            "Epoch 00210: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0223 - accuracy: 0.8743 - val_loss: 3.3563 - val_accuracy: 0.6390 - lr: 0.0089\n",
            "Epoch 211/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0291 - accuracy: 0.8709\n",
            "Epoch 00211: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0291 - accuracy: 0.8709 - val_loss: 3.3953 - val_accuracy: 0.6360 - lr: 0.0089\n",
            "Epoch 212/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0205 - accuracy: 0.8756\n",
            "Epoch 00212: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0205 - accuracy: 0.8756 - val_loss: 3.3654 - val_accuracy: 0.6408 - lr: 0.0089\n",
            "Epoch 213/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0268 - accuracy: 0.8730\n",
            "Epoch 00213: val_accuracy did not improve from 0.64990\n",
            "\n",
            "Epoch 00213: ReduceLROnPlateau reducing learning rate to 0.007976643182337284.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 2.0268 - accuracy: 0.8730 - val_loss: 3.3906 - val_accuracy: 0.6361 - lr: 0.0089\n",
            "Epoch 214/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9822 - accuracy: 0.8832\n",
            "Epoch 00214: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9822 - accuracy: 0.8832 - val_loss: 3.3359 - val_accuracy: 0.6408 - lr: 0.0080\n",
            "Epoch 215/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9449 - accuracy: 0.8910\n",
            "Epoch 00215: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9449 - accuracy: 0.8910 - val_loss: 3.3251 - val_accuracy: 0.6481 - lr: 0.0080\n",
            "Epoch 216/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9433 - accuracy: 0.8875\n",
            "Epoch 00216: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9433 - accuracy: 0.8875 - val_loss: 3.3100 - val_accuracy: 0.6445 - lr: 0.0080\n",
            "Epoch 217/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9324 - accuracy: 0.8893\n",
            "Epoch 00217: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9324 - accuracy: 0.8893 - val_loss: 3.3363 - val_accuracy: 0.6432 - lr: 0.0080\n",
            "Epoch 218/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9440 - accuracy: 0.8846\n",
            "Epoch 00218: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9440 - accuracy: 0.8846 - val_loss: 3.3543 - val_accuracy: 0.6386 - lr: 0.0080\n",
            "Epoch 219/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9126 - accuracy: 0.8908\n",
            "Epoch 00219: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9126 - accuracy: 0.8908 - val_loss: 3.3150 - val_accuracy: 0.6474 - lr: 0.0080\n",
            "Epoch 220/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9128 - accuracy: 0.8880\n",
            "Epoch 00220: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9128 - accuracy: 0.8880 - val_loss: 3.3547 - val_accuracy: 0.6402 - lr: 0.0080\n",
            "Epoch 221/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9159 - accuracy: 0.8864\n",
            "Epoch 00221: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9159 - accuracy: 0.8864 - val_loss: 3.2943 - val_accuracy: 0.6475 - lr: 0.0080\n",
            "Epoch 222/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9056 - accuracy: 0.8887\n",
            "Epoch 00222: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9056 - accuracy: 0.8887 - val_loss: 3.3168 - val_accuracy: 0.6439 - lr: 0.0080\n",
            "Epoch 223/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9038 - accuracy: 0.8883\n",
            "Epoch 00223: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9038 - accuracy: 0.8883 - val_loss: 3.3518 - val_accuracy: 0.6407 - lr: 0.0080\n",
            "Epoch 224/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9056 - accuracy: 0.8859\n",
            "Epoch 00224: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9056 - accuracy: 0.8859 - val_loss: 3.2647 - val_accuracy: 0.6484 - lr: 0.0080\n",
            "Epoch 225/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9062 - accuracy: 0.8853\n",
            "Epoch 00225: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9062 - accuracy: 0.8853 - val_loss: 3.3316 - val_accuracy: 0.6377 - lr: 0.0080\n",
            "Epoch 226/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9078 - accuracy: 0.8845\n",
            "Epoch 00226: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9078 - accuracy: 0.8845 - val_loss: 3.3177 - val_accuracy: 0.6438 - lr: 0.0080\n",
            "Epoch 227/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9033 - accuracy: 0.8870\n",
            "Epoch 00227: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9033 - accuracy: 0.8870 - val_loss: 3.3015 - val_accuracy: 0.6437 - lr: 0.0080\n",
            "Epoch 228/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9028 - accuracy: 0.8867\n",
            "Epoch 00228: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9028 - accuracy: 0.8867 - val_loss: 3.2840 - val_accuracy: 0.6442 - lr: 0.0080\n",
            "Epoch 229/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8985 - accuracy: 0.8863\n",
            "Epoch 00229: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.8985 - accuracy: 0.8863 - val_loss: 3.3089 - val_accuracy: 0.6460 - lr: 0.0080\n",
            "Epoch 230/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8888 - accuracy: 0.8894\n",
            "Epoch 00230: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.8888 - accuracy: 0.8894 - val_loss: 3.3057 - val_accuracy: 0.6428 - lr: 0.0080\n",
            "Epoch 231/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9084 - accuracy: 0.8829\n",
            "Epoch 00231: val_accuracy did not improve from 0.64990\n",
            "\n",
            "Epoch 00231: ReduceLROnPlateau reducing learning rate to 0.007178978528827429.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.9084 - accuracy: 0.8829 - val_loss: 3.3237 - val_accuracy: 0.6389 - lr: 0.0080\n",
            "Epoch 232/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8669 - accuracy: 0.8924\n",
            "Epoch 00232: val_accuracy did not improve from 0.64990\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.8669 - accuracy: 0.8924 - val_loss: 3.2590 - val_accuracy: 0.6488 - lr: 0.0072\n",
            "Epoch 233/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8278 - accuracy: 0.9019\n",
            "Epoch 00233: val_accuracy improved from 0.64990 to 0.65400, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 1.8278 - accuracy: 0.9019 - val_loss: 3.2764 - val_accuracy: 0.6540 - lr: 0.0072\n",
            "Epoch 234/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8148 - accuracy: 0.9015\n",
            "Epoch 00234: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.8148 - accuracy: 0.9015 - val_loss: 3.3046 - val_accuracy: 0.6433 - lr: 0.0072\n",
            "Epoch 235/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8049 - accuracy: 0.9021\n",
            "Epoch 00235: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.8049 - accuracy: 0.9021 - val_loss: 3.3109 - val_accuracy: 0.6432 - lr: 0.0072\n",
            "Epoch 236/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7992 - accuracy: 0.9026\n",
            "Epoch 00236: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7992 - accuracy: 0.9026 - val_loss: 3.2582 - val_accuracy: 0.6482 - lr: 0.0072\n",
            "Epoch 237/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8058 - accuracy: 0.8979\n",
            "Epoch 00237: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.8058 - accuracy: 0.8979 - val_loss: 3.3053 - val_accuracy: 0.6392 - lr: 0.0072\n",
            "Epoch 238/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7973 - accuracy: 0.8992\n",
            "Epoch 00238: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7973 - accuracy: 0.8992 - val_loss: 3.3300 - val_accuracy: 0.6370 - lr: 0.0072\n",
            "Epoch 239/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7814 - accuracy: 0.9029\n",
            "Epoch 00239: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7814 - accuracy: 0.9029 - val_loss: 3.2875 - val_accuracy: 0.6442 - lr: 0.0072\n",
            "Epoch 240/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7837 - accuracy: 0.9005\n",
            "Epoch 00240: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7837 - accuracy: 0.9005 - val_loss: 3.2534 - val_accuracy: 0.6519 - lr: 0.0072\n",
            "Epoch 241/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7744 - accuracy: 0.9025\n",
            "Epoch 00241: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7744 - accuracy: 0.9025 - val_loss: 3.2321 - val_accuracy: 0.6487 - lr: 0.0072\n",
            "Epoch 242/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7801 - accuracy: 0.8973\n",
            "Epoch 00242: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7801 - accuracy: 0.8973 - val_loss: 3.2711 - val_accuracy: 0.6463 - lr: 0.0072\n",
            "Epoch 243/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7849 - accuracy: 0.8974\n",
            "Epoch 00243: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7849 - accuracy: 0.8974 - val_loss: 3.2502 - val_accuracy: 0.6472 - lr: 0.0072\n",
            "Epoch 244/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7818 - accuracy: 0.8971\n",
            "Epoch 00244: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7818 - accuracy: 0.8971 - val_loss: 3.2467 - val_accuracy: 0.6499 - lr: 0.0072\n",
            "Epoch 245/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7717 - accuracy: 0.9000\n",
            "Epoch 00245: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7717 - accuracy: 0.9000 - val_loss: 3.2107 - val_accuracy: 0.6482 - lr: 0.0072\n",
            "Epoch 246/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7643 - accuracy: 0.9012\n",
            "Epoch 00246: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7643 - accuracy: 0.9012 - val_loss: 3.2632 - val_accuracy: 0.6421 - lr: 0.0072\n",
            "Epoch 247/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7730 - accuracy: 0.8986\n",
            "Epoch 00247: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7730 - accuracy: 0.8986 - val_loss: 3.2601 - val_accuracy: 0.6439 - lr: 0.0072\n",
            "Epoch 248/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7774 - accuracy: 0.8969\n",
            "Epoch 00248: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7774 - accuracy: 0.8969 - val_loss: 3.3371 - val_accuracy: 0.6318 - lr: 0.0072\n",
            "Epoch 249/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7751 - accuracy: 0.8978\n",
            "Epoch 00249: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7751 - accuracy: 0.8978 - val_loss: 3.2359 - val_accuracy: 0.6501 - lr: 0.0072\n",
            "Epoch 250/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7678 - accuracy: 0.9017\n",
            "Epoch 00250: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7678 - accuracy: 0.9017 - val_loss: 3.2499 - val_accuracy: 0.6434 - lr: 0.0072\n",
            "Epoch 251/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7697 - accuracy: 0.8983\n",
            "Epoch 00251: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7697 - accuracy: 0.8983 - val_loss: 3.2952 - val_accuracy: 0.6345 - lr: 0.0072\n",
            "Epoch 252/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7652 - accuracy: 0.9006\n",
            "Epoch 00252: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7652 - accuracy: 0.9006 - val_loss: 3.1962 - val_accuracy: 0.6504 - lr: 0.0072\n",
            "Epoch 253/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7694 - accuracy: 0.8969\n",
            "Epoch 00253: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7694 - accuracy: 0.8969 - val_loss: 3.2398 - val_accuracy: 0.6467 - lr: 0.0072\n",
            "Epoch 254/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7614 - accuracy: 0.8994\n",
            "Epoch 00254: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7614 - accuracy: 0.8994 - val_loss: 3.2538 - val_accuracy: 0.6447 - lr: 0.0072\n",
            "Epoch 255/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7699 - accuracy: 0.8984\n",
            "Epoch 00255: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7699 - accuracy: 0.8984 - val_loss: 3.2814 - val_accuracy: 0.6435 - lr: 0.0072\n",
            "Epoch 256/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7668 - accuracy: 0.8982\n",
            "Epoch 00256: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7668 - accuracy: 0.8982 - val_loss: 3.2340 - val_accuracy: 0.6462 - lr: 0.0072\n",
            "Epoch 257/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7764 - accuracy: 0.8943\n",
            "Epoch 00257: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7764 - accuracy: 0.8943 - val_loss: 3.2523 - val_accuracy: 0.6458 - lr: 0.0072\n",
            "Epoch 258/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7576 - accuracy: 0.9007\n",
            "Epoch 00258: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7576 - accuracy: 0.9007 - val_loss: 3.2544 - val_accuracy: 0.6488 - lr: 0.0072\n",
            "Epoch 259/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7543 - accuracy: 0.9015\n",
            "Epoch 00259: val_accuracy did not improve from 0.65400\n",
            "\n",
            "Epoch 00259: ReduceLROnPlateau reducing learning rate to 0.006461080675944686.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7543 - accuracy: 0.9015 - val_loss: 3.2596 - val_accuracy: 0.6405 - lr: 0.0072\n",
            "Epoch 260/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7077 - accuracy: 0.9130\n",
            "Epoch 00260: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.7077 - accuracy: 0.9130 - val_loss: 3.2446 - val_accuracy: 0.6504 - lr: 0.0065\n",
            "Epoch 261/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6834 - accuracy: 0.9160\n",
            "Epoch 00261: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.6834 - accuracy: 0.9160 - val_loss: 3.2222 - val_accuracy: 0.6474 - lr: 0.0065\n",
            "Epoch 262/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6914 - accuracy: 0.9112\n",
            "Epoch 00262: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.6914 - accuracy: 0.9112 - val_loss: 3.2242 - val_accuracy: 0.6526 - lr: 0.0065\n",
            "Epoch 263/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6767 - accuracy: 0.9135\n",
            "Epoch 00263: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.6767 - accuracy: 0.9135 - val_loss: 3.3103 - val_accuracy: 0.6362 - lr: 0.0065\n",
            "Epoch 264/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6724 - accuracy: 0.9139\n",
            "Epoch 00264: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.6724 - accuracy: 0.9139 - val_loss: 3.2713 - val_accuracy: 0.6451 - lr: 0.0065\n",
            "Epoch 265/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6530 - accuracy: 0.9164\n",
            "Epoch 00265: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.6530 - accuracy: 0.9164 - val_loss: 3.2315 - val_accuracy: 0.6486 - lr: 0.0065\n",
            "Epoch 266/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6655 - accuracy: 0.9118\n",
            "Epoch 00266: val_accuracy did not improve from 0.65400\n",
            "\n",
            "Epoch 00266: ReduceLROnPlateau reducing learning rate to 0.0058149725664407015.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.6655 - accuracy: 0.9118 - val_loss: 3.2265 - val_accuracy: 0.6428 - lr: 0.0065\n",
            "Epoch 267/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6409 - accuracy: 0.9165\n",
            "Epoch 00267: val_accuracy did not improve from 0.65400\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.6409 - accuracy: 0.9165 - val_loss: 3.1815 - val_accuracy: 0.6525 - lr: 0.0058\n",
            "Epoch 268/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6004 - accuracy: 0.9242\n",
            "Epoch 00268: val_accuracy improved from 0.65400 to 0.65610, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.6004 - accuracy: 0.9242 - val_loss: 3.1952 - val_accuracy: 0.6561 - lr: 0.0058\n",
            "Epoch 269/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5877 - accuracy: 0.9246\n",
            "Epoch 00269: val_accuracy did not improve from 0.65610\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5877 - accuracy: 0.9246 - val_loss: 3.1824 - val_accuracy: 0.6520 - lr: 0.0058\n",
            "Epoch 270/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5905 - accuracy: 0.9206\n",
            "Epoch 00270: val_accuracy did not improve from 0.65610\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5905 - accuracy: 0.9206 - val_loss: 3.2355 - val_accuracy: 0.6452 - lr: 0.0058\n",
            "Epoch 271/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5748 - accuracy: 0.9229\n",
            "Epoch 00271: val_accuracy improved from 0.65610 to 0.65950, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.5748 - accuracy: 0.9229 - val_loss: 3.1266 - val_accuracy: 0.6595 - lr: 0.0058\n",
            "Epoch 272/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5678 - accuracy: 0.9227\n",
            "Epoch 00272: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5678 - accuracy: 0.9227 - val_loss: 3.2060 - val_accuracy: 0.6494 - lr: 0.0058\n",
            "Epoch 273/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5560 - accuracy: 0.9244\n",
            "Epoch 00273: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5560 - accuracy: 0.9244 - val_loss: 3.1567 - val_accuracy: 0.6537 - lr: 0.0058\n",
            "Epoch 274/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5471 - accuracy: 0.9247\n",
            "Epoch 00274: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5471 - accuracy: 0.9247 - val_loss: 3.1934 - val_accuracy: 0.6525 - lr: 0.0058\n",
            "Epoch 275/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5421 - accuracy: 0.9241\n",
            "Epoch 00275: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5421 - accuracy: 0.9241 - val_loss: 3.1318 - val_accuracy: 0.6548 - lr: 0.0058\n",
            "Epoch 276/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5477 - accuracy: 0.9207\n",
            "Epoch 00276: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5477 - accuracy: 0.9207 - val_loss: 3.1636 - val_accuracy: 0.6528 - lr: 0.0058\n",
            "Epoch 277/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5426 - accuracy: 0.9213\n",
            "Epoch 00277: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5426 - accuracy: 0.9213 - val_loss: 3.1839 - val_accuracy: 0.6519 - lr: 0.0058\n",
            "Epoch 278/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5379 - accuracy: 0.9216\n",
            "Epoch 00278: val_accuracy did not improve from 0.65950\n",
            "\n",
            "Epoch 00278: ReduceLROnPlateau reducing learning rate to 0.005233475100249053.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5379 - accuracy: 0.9216 - val_loss: 3.1791 - val_accuracy: 0.6429 - lr: 0.0058\n",
            "Epoch 279/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5204 - accuracy: 0.9250\n",
            "Epoch 00279: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.5204 - accuracy: 0.9250 - val_loss: 3.1245 - val_accuracy: 0.6530 - lr: 0.0052\n",
            "Epoch 280/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4938 - accuracy: 0.9305\n",
            "Epoch 00280: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4938 - accuracy: 0.9305 - val_loss: 3.1071 - val_accuracy: 0.6593 - lr: 0.0052\n",
            "Epoch 281/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4715 - accuracy: 0.9334\n",
            "Epoch 00281: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4715 - accuracy: 0.9334 - val_loss: 3.1692 - val_accuracy: 0.6504 - lr: 0.0052\n",
            "Epoch 282/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4509 - accuracy: 0.9356\n",
            "Epoch 00282: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4509 - accuracy: 0.9356 - val_loss: 3.1864 - val_accuracy: 0.6478 - lr: 0.0052\n",
            "Epoch 283/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4547 - accuracy: 0.9323\n",
            "Epoch 00283: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4547 - accuracy: 0.9323 - val_loss: 3.1986 - val_accuracy: 0.6492 - lr: 0.0052\n",
            "Epoch 284/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4517 - accuracy: 0.9309\n",
            "Epoch 00284: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4517 - accuracy: 0.9309 - val_loss: 3.1224 - val_accuracy: 0.6538 - lr: 0.0052\n",
            "Epoch 285/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4397 - accuracy: 0.9327\n",
            "Epoch 00285: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4397 - accuracy: 0.9327 - val_loss: 3.1022 - val_accuracy: 0.6558 - lr: 0.0052\n",
            "Epoch 286/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4444 - accuracy: 0.9296\n",
            "Epoch 00286: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4444 - accuracy: 0.9296 - val_loss: 3.1350 - val_accuracy: 0.6485 - lr: 0.0052\n",
            "Epoch 287/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4329 - accuracy: 0.9316\n",
            "Epoch 00287: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4329 - accuracy: 0.9316 - val_loss: 3.1424 - val_accuracy: 0.6456 - lr: 0.0052\n",
            "Epoch 288/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4359 - accuracy: 0.9281\n",
            "Epoch 00288: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4359 - accuracy: 0.9281 - val_loss: 3.1340 - val_accuracy: 0.6472 - lr: 0.0052\n",
            "Epoch 289/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4369 - accuracy: 0.9273\n",
            "Epoch 00289: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4369 - accuracy: 0.9273 - val_loss: 3.1522 - val_accuracy: 0.6421 - lr: 0.0052\n",
            "Epoch 290/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4325 - accuracy: 0.9269\n",
            "Epoch 00290: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4325 - accuracy: 0.9269 - val_loss: 3.1213 - val_accuracy: 0.6498 - lr: 0.0052\n",
            "Epoch 291/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4232 - accuracy: 0.9293\n",
            "Epoch 00291: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4232 - accuracy: 0.9293 - val_loss: 3.0727 - val_accuracy: 0.6529 - lr: 0.0052\n",
            "Epoch 292/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4137 - accuracy: 0.9309\n",
            "Epoch 00292: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4137 - accuracy: 0.9309 - val_loss: 3.0789 - val_accuracy: 0.6492 - lr: 0.0052\n",
            "Epoch 293/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4230 - accuracy: 0.9273\n",
            "Epoch 00293: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4230 - accuracy: 0.9273 - val_loss: 3.0823 - val_accuracy: 0.6518 - lr: 0.0052\n",
            "Epoch 294/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4277 - accuracy: 0.9267\n",
            "Epoch 00294: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4277 - accuracy: 0.9267 - val_loss: 3.0881 - val_accuracy: 0.6498 - lr: 0.0052\n",
            "Epoch 295/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4269 - accuracy: 0.9264\n",
            "Epoch 00295: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4269 - accuracy: 0.9264 - val_loss: 3.0607 - val_accuracy: 0.6442 - lr: 0.0052\n",
            "Epoch 296/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4196 - accuracy: 0.9273\n",
            "Epoch 00296: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4196 - accuracy: 0.9273 - val_loss: 3.1091 - val_accuracy: 0.6450 - lr: 0.0052\n",
            "Epoch 297/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4137 - accuracy: 0.9279\n",
            "Epoch 00297: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4137 - accuracy: 0.9279 - val_loss: 3.0560 - val_accuracy: 0.6515 - lr: 0.0052\n",
            "Epoch 298/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4166 - accuracy: 0.9257\n",
            "Epoch 00298: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4166 - accuracy: 0.9257 - val_loss: 3.1009 - val_accuracy: 0.6461 - lr: 0.0052\n",
            "Epoch 299/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4172 - accuracy: 0.9256\n",
            "Epoch 00299: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4172 - accuracy: 0.9256 - val_loss: 3.0652 - val_accuracy: 0.6527 - lr: 0.0052\n",
            "Epoch 300/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4019 - accuracy: 0.9302\n",
            "Epoch 00300: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4019 - accuracy: 0.9302 - val_loss: 3.0132 - val_accuracy: 0.6549 - lr: 0.0052\n",
            "Epoch 301/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4205 - accuracy: 0.9239\n",
            "Epoch 00301: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4205 - accuracy: 0.9239 - val_loss: 3.0296 - val_accuracy: 0.6501 - lr: 0.0052\n",
            "Epoch 302/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4098 - accuracy: 0.9263\n",
            "Epoch 00302: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4098 - accuracy: 0.9263 - val_loss: 3.0454 - val_accuracy: 0.6539 - lr: 0.0052\n",
            "Epoch 303/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4053 - accuracy: 0.9287\n",
            "Epoch 00303: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4053 - accuracy: 0.9287 - val_loss: 3.0010 - val_accuracy: 0.6570 - lr: 0.0052\n",
            "Epoch 304/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3984 - accuracy: 0.9289\n",
            "Epoch 00304: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.3984 - accuracy: 0.9289 - val_loss: 3.0367 - val_accuracy: 0.6525 - lr: 0.0052\n",
            "Epoch 305/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4181 - accuracy: 0.9225\n",
            "Epoch 00305: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4181 - accuracy: 0.9225 - val_loss: 3.0429 - val_accuracy: 0.6515 - lr: 0.0052\n",
            "Epoch 306/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4093 - accuracy: 0.9266\n",
            "Epoch 00306: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4093 - accuracy: 0.9266 - val_loss: 3.0472 - val_accuracy: 0.6527 - lr: 0.0052\n",
            "Epoch 307/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.4173 - accuracy: 0.9240\n",
            "Epoch 00307: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4176 - accuracy: 0.9239 - val_loss: 3.0477 - val_accuracy: 0.6505 - lr: 0.0052\n",
            "Epoch 308/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4188 - accuracy: 0.9244\n",
            "Epoch 00308: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4188 - accuracy: 0.9244 - val_loss: 3.0347 - val_accuracy: 0.6536 - lr: 0.0052\n",
            "Epoch 309/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4139 - accuracy: 0.9249\n",
            "Epoch 00309: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4139 - accuracy: 0.9249 - val_loss: 3.1013 - val_accuracy: 0.6483 - lr: 0.0052\n",
            "Epoch 310/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4177 - accuracy: 0.9245\n",
            "Epoch 00310: val_accuracy did not improve from 0.65950\n",
            "\n",
            "Epoch 00310: ReduceLROnPlateau reducing learning rate to 0.0047101275064051155.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4177 - accuracy: 0.9245 - val_loss: 3.0698 - val_accuracy: 0.6472 - lr: 0.0052\n",
            "Epoch 311/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4039 - accuracy: 0.9290\n",
            "Epoch 00311: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.4039 - accuracy: 0.9290 - val_loss: 3.0533 - val_accuracy: 0.6544 - lr: 0.0047\n",
            "Epoch 312/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3704 - accuracy: 0.9360\n",
            "Epoch 00312: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.3704 - accuracy: 0.9360 - val_loss: 3.0685 - val_accuracy: 0.6516 - lr: 0.0047\n",
            "Epoch 313/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3505 - accuracy: 0.9394\n",
            "Epoch 00313: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.3505 - accuracy: 0.9395 - val_loss: 3.0793 - val_accuracy: 0.6503 - lr: 0.0047\n",
            "Epoch 314/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3353 - accuracy: 0.9408\n",
            "Epoch 00314: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.3353 - accuracy: 0.9408 - val_loss: 3.0951 - val_accuracy: 0.6461 - lr: 0.0047\n",
            "Epoch 315/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3428 - accuracy: 0.9372\n",
            "Epoch 00315: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.3428 - accuracy: 0.9372 - val_loss: 3.0296 - val_accuracy: 0.6565 - lr: 0.0047\n",
            "Epoch 316/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3319 - accuracy: 0.9395\n",
            "Epoch 00316: val_accuracy did not improve from 0.65950\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.3319 - accuracy: 0.9395 - val_loss: 3.0181 - val_accuracy: 0.6550 - lr: 0.0047\n",
            "Epoch 317/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3330 - accuracy: 0.9369\n",
            "Epoch 00317: val_accuracy did not improve from 0.65950\n",
            "\n",
            "Epoch 00317: ReduceLROnPlateau reducing learning rate to 0.004239114839583636.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.3330 - accuracy: 0.9369 - val_loss: 3.0336 - val_accuracy: 0.6549 - lr: 0.0047\n",
            "Epoch 318/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3101 - accuracy: 0.9418\n",
            "Epoch 00318: val_accuracy improved from 0.65950 to 0.65980, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.3101 - accuracy: 0.9418 - val_loss: 3.0218 - val_accuracy: 0.6598 - lr: 0.0042\n",
            "Epoch 319/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2851 - accuracy: 0.9463\n",
            "Epoch 00319: val_accuracy did not improve from 0.65980\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.2854 - accuracy: 0.9462 - val_loss: 3.0065 - val_accuracy: 0.6580 - lr: 0.0042\n",
            "Epoch 320/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2699 - accuracy: 0.9489\n",
            "Epoch 00320: val_accuracy did not improve from 0.65980\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.2699 - accuracy: 0.9489 - val_loss: 2.9950 - val_accuracy: 0.6579 - lr: 0.0042\n",
            "Epoch 321/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2541 - accuracy: 0.9501\n",
            "Epoch 00321: val_accuracy did not improve from 0.65980\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.2541 - accuracy: 0.9501 - val_loss: 3.0827 - val_accuracy: 0.6550 - lr: 0.0042\n",
            "Epoch 322/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2522 - accuracy: 0.9486\n",
            "Epoch 00322: val_accuracy improved from 0.65980 to 0.66140, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.2522 - accuracy: 0.9486 - val_loss: 3.0080 - val_accuracy: 0.6614 - lr: 0.0042\n",
            "Epoch 323/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2514 - accuracy: 0.9465\n",
            "Epoch 00323: val_accuracy did not improve from 0.66140\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.2518 - accuracy: 0.9464 - val_loss: 3.0119 - val_accuracy: 0.6566 - lr: 0.0042\n",
            "Epoch 324/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2514 - accuracy: 0.9440\n",
            "Epoch 00324: val_accuracy did not improve from 0.66140\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.2514 - accuracy: 0.9440 - val_loss: 2.9983 - val_accuracy: 0.6563 - lr: 0.0042\n",
            "Epoch 325/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2480 - accuracy: 0.9444\n",
            "Epoch 00325: val_accuracy did not improve from 0.66140\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.2480 - accuracy: 0.9444 - val_loss: 3.0050 - val_accuracy: 0.6591 - lr: 0.0042\n",
            "Epoch 326/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2409 - accuracy: 0.9448\n",
            "Epoch 00326: val_accuracy did not improve from 0.66140\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.2409 - accuracy: 0.9448 - val_loss: 3.0582 - val_accuracy: 0.6507 - lr: 0.0042\n",
            "Epoch 327/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2348 - accuracy: 0.9452\n",
            "Epoch 00327: val_accuracy did not improve from 0.66140\n",
            "\n",
            "Epoch 00327: ReduceLROnPlateau reducing learning rate to 0.0038152034394443035.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.2348 - accuracy: 0.9452 - val_loss: 3.0352 - val_accuracy: 0.6526 - lr: 0.0042\n",
            "Epoch 328/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2173 - accuracy: 0.9491\n",
            "Epoch 00328: val_accuracy improved from 0.66140 to 0.66190, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 44ms/step - loss: 1.2173 - accuracy: 0.9491 - val_loss: 2.9623 - val_accuracy: 0.6619 - lr: 0.0038\n",
            "Epoch 329/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1969 - accuracy: 0.9530\n",
            "Epoch 00329: val_accuracy did not improve from 0.66190\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1969 - accuracy: 0.9530 - val_loss: 2.9990 - val_accuracy: 0.6559 - lr: 0.0038\n",
            "Epoch 330/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1816 - accuracy: 0.9547\n",
            "Epoch 00330: val_accuracy did not improve from 0.66190\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1816 - accuracy: 0.9547 - val_loss: 2.9809 - val_accuracy: 0.6616 - lr: 0.0038\n",
            "Epoch 331/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1787 - accuracy: 0.9523\n",
            "Epoch 00331: val_accuracy did not improve from 0.66190\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1787 - accuracy: 0.9523 - val_loss: 3.0277 - val_accuracy: 0.6552 - lr: 0.0038\n",
            "Epoch 332/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1742 - accuracy: 0.9524\n",
            "Epoch 00332: val_accuracy did not improve from 0.66190\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1742 - accuracy: 0.9524 - val_loss: 3.0015 - val_accuracy: 0.6599 - lr: 0.0038\n",
            "Epoch 333/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1618 - accuracy: 0.9549\n",
            "Epoch 00333: val_accuracy did not improve from 0.66190\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1618 - accuracy: 0.9549 - val_loss: 2.9778 - val_accuracy: 0.6591 - lr: 0.0038\n",
            "Epoch 334/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1584 - accuracy: 0.9535\n",
            "Epoch 00334: val_accuracy did not improve from 0.66190\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1584 - accuracy: 0.9535 - val_loss: 3.0065 - val_accuracy: 0.6556 - lr: 0.0038\n",
            "Epoch 335/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1486 - accuracy: 0.9541\n",
            "Epoch 00335: val_accuracy did not improve from 0.66190\n",
            "\n",
            "Epoch 00335: ReduceLROnPlateau reducing learning rate to 0.003433683095499873.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1486 - accuracy: 0.9541 - val_loss: 2.9901 - val_accuracy: 0.6564 - lr: 0.0038\n",
            "Epoch 336/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1348 - accuracy: 0.9551\n",
            "Epoch 00336: val_accuracy improved from 0.66190 to 0.66500, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.1348 - accuracy: 0.9551 - val_loss: 2.9181 - val_accuracy: 0.6650 - lr: 0.0034\n",
            "Epoch 337/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1185 - accuracy: 0.9579\n",
            "Epoch 00337: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1185 - accuracy: 0.9579 - val_loss: 2.9706 - val_accuracy: 0.6622 - lr: 0.0034\n",
            "Epoch 338/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1121 - accuracy: 0.9581\n",
            "Epoch 00338: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1121 - accuracy: 0.9581 - val_loss: 2.9820 - val_accuracy: 0.6585 - lr: 0.0034\n",
            "Epoch 339/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1016 - accuracy: 0.9597\n",
            "Epoch 00339: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.1016 - accuracy: 0.9597 - val_loss: 2.9286 - val_accuracy: 0.6638 - lr: 0.0034\n",
            "Epoch 340/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0903 - accuracy: 0.9606\n",
            "Epoch 00340: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0903 - accuracy: 0.9606 - val_loss: 2.9637 - val_accuracy: 0.6567 - lr: 0.0034\n",
            "Epoch 341/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0892 - accuracy: 0.9581\n",
            "Epoch 00341: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0892 - accuracy: 0.9581 - val_loss: 2.9359 - val_accuracy: 0.6587 - lr: 0.0034\n",
            "Epoch 342/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0737 - accuracy: 0.9609\n",
            "Epoch 00342: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0737 - accuracy: 0.9609 - val_loss: 2.9344 - val_accuracy: 0.6631 - lr: 0.0034\n",
            "Epoch 343/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0689 - accuracy: 0.9592\n",
            "Epoch 00343: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0689 - accuracy: 0.9592 - val_loss: 2.9109 - val_accuracy: 0.6609 - lr: 0.0034\n",
            "Epoch 344/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0617 - accuracy: 0.9597\n",
            "Epoch 00344: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0617 - accuracy: 0.9597 - val_loss: 2.9392 - val_accuracy: 0.6612 - lr: 0.0034\n",
            "Epoch 345/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0615 - accuracy: 0.9579\n",
            "Epoch 00345: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0615 - accuracy: 0.9579 - val_loss: 2.9292 - val_accuracy: 0.6560 - lr: 0.0034\n",
            "Epoch 346/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0541 - accuracy: 0.9592\n",
            "Epoch 00346: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0541 - accuracy: 0.9592 - val_loss: 2.9339 - val_accuracy: 0.6569 - lr: 0.0034\n",
            "Epoch 347/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0560 - accuracy: 0.9578\n",
            "Epoch 00347: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0560 - accuracy: 0.9578 - val_loss: 3.0047 - val_accuracy: 0.6489 - lr: 0.0034\n",
            "Epoch 348/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0567 - accuracy: 0.9550\n",
            "Epoch 00348: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0567 - accuracy: 0.9550 - val_loss: 2.9351 - val_accuracy: 0.6582 - lr: 0.0034\n",
            "Epoch 349/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0499 - accuracy: 0.9564\n",
            "Epoch 00349: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0499 - accuracy: 0.9564 - val_loss: 2.9037 - val_accuracy: 0.6593 - lr: 0.0034\n",
            "Epoch 350/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0494 - accuracy: 0.9556\n",
            "Epoch 00350: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0494 - accuracy: 0.9556 - val_loss: 2.9249 - val_accuracy: 0.6585 - lr: 0.0034\n",
            "Epoch 351/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0420 - accuracy: 0.9561\n",
            "Epoch 00351: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0420 - accuracy: 0.9561 - val_loss: 2.9583 - val_accuracy: 0.6533 - lr: 0.0034\n",
            "Epoch 352/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0464 - accuracy: 0.9532\n",
            "Epoch 00352: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0464 - accuracy: 0.9532 - val_loss: 2.9168 - val_accuracy: 0.6590 - lr: 0.0034\n",
            "Epoch 353/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0480 - accuracy: 0.9534\n",
            "Epoch 00353: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0480 - accuracy: 0.9534 - val_loss: 2.8676 - val_accuracy: 0.6596 - lr: 0.0034\n",
            "Epoch 354/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.9531\n",
            "Epoch 00354: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0440 - accuracy: 0.9531 - val_loss: 2.8823 - val_accuracy: 0.6615 - lr: 0.0034\n",
            "Epoch 355/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0459 - accuracy: 0.9527\n",
            "Epoch 00355: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0459 - accuracy: 0.9527 - val_loss: 2.8802 - val_accuracy: 0.6600 - lr: 0.0034\n",
            "Epoch 356/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0404 - accuracy: 0.9536\n",
            "Epoch 00356: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0404 - accuracy: 0.9536 - val_loss: 2.8892 - val_accuracy: 0.6598 - lr: 0.0034\n",
            "Epoch 357/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0385 - accuracy: 0.9536\n",
            "Epoch 00357: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0385 - accuracy: 0.9536 - val_loss: 2.8648 - val_accuracy: 0.6621 - lr: 0.0034\n",
            "Epoch 358/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0430 - accuracy: 0.9520\n",
            "Epoch 00358: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0430 - accuracy: 0.9520 - val_loss: 2.9184 - val_accuracy: 0.6546 - lr: 0.0034\n",
            "Epoch 359/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0395 - accuracy: 0.9524\n",
            "Epoch 00359: val_accuracy did not improve from 0.66500\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0395 - accuracy: 0.9524 - val_loss: 2.8952 - val_accuracy: 0.6580 - lr: 0.0034\n",
            "Epoch 360/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0459 - accuracy: 0.9502\n",
            "Epoch 00360: val_accuracy improved from 0.66500 to 0.66600, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.0459 - accuracy: 0.9502 - val_loss: 2.8337 - val_accuracy: 0.6660 - lr: 0.0034\n",
            "Epoch 361/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0394 - accuracy: 0.9511\n",
            "Epoch 00361: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0394 - accuracy: 0.9511 - val_loss: 2.8732 - val_accuracy: 0.6584 - lr: 0.0034\n",
            "Epoch 362/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0321 - accuracy: 0.9532\n",
            "Epoch 00362: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0321 - accuracy: 0.9532 - val_loss: 2.8718 - val_accuracy: 0.6573 - lr: 0.0034\n",
            "Epoch 363/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0393 - accuracy: 0.9508\n",
            "Epoch 00363: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0393 - accuracy: 0.9508 - val_loss: 2.8780 - val_accuracy: 0.6623 - lr: 0.0034\n",
            "Epoch 364/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0333 - accuracy: 0.9523\n",
            "Epoch 00364: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0333 - accuracy: 0.9523 - val_loss: 2.8707 - val_accuracy: 0.6605 - lr: 0.0034\n",
            "Epoch 365/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0312 - accuracy: 0.9525\n",
            "Epoch 00365: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0312 - accuracy: 0.9525 - val_loss: 2.8483 - val_accuracy: 0.6587 - lr: 0.0034\n",
            "Epoch 366/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0257 - accuracy: 0.9544\n",
            "Epoch 00366: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0257 - accuracy: 0.9544 - val_loss: 2.9051 - val_accuracy: 0.6524 - lr: 0.0034\n",
            "Epoch 367/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0295 - accuracy: 0.9523\n",
            "Epoch 00367: val_accuracy did not improve from 0.66600\n",
            "\n",
            "Epoch 00367: ReduceLROnPlateau reducing learning rate to 0.0030903148697689177.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0295 - accuracy: 0.9523 - val_loss: 2.9066 - val_accuracy: 0.6542 - lr: 0.0034\n",
            "Epoch 368/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0214 - accuracy: 0.9552\n",
            "Epoch 00368: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 1.0214 - accuracy: 0.9552 - val_loss: 2.8321 - val_accuracy: 0.6588 - lr: 0.0031\n",
            "Epoch 369/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9955 - accuracy: 0.9606\n",
            "Epoch 00369: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9955 - accuracy: 0.9606 - val_loss: 2.8315 - val_accuracy: 0.6596 - lr: 0.0031\n",
            "Epoch 370/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9894 - accuracy: 0.9607\n",
            "Epoch 00370: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9894 - accuracy: 0.9607 - val_loss: 2.8494 - val_accuracy: 0.6627 - lr: 0.0031\n",
            "Epoch 371/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.9621\n",
            "Epoch 00371: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9802 - accuracy: 0.9621 - val_loss: 2.8366 - val_accuracy: 0.6631 - lr: 0.0031\n",
            "Epoch 372/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9803 - accuracy: 0.9606\n",
            "Epoch 00372: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9803 - accuracy: 0.9606 - val_loss: 2.8850 - val_accuracy: 0.6574 - lr: 0.0031\n",
            "Epoch 373/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9742 - accuracy: 0.9616\n",
            "Epoch 00373: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9742 - accuracy: 0.9616 - val_loss: 2.8497 - val_accuracy: 0.6605 - lr: 0.0031\n",
            "Epoch 374/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9695 - accuracy: 0.9611\n",
            "Epoch 00374: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9695 - accuracy: 0.9611 - val_loss: 2.8967 - val_accuracy: 0.6565 - lr: 0.0031\n",
            "Epoch 375/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9620 - accuracy: 0.9620\n",
            "Epoch 00375: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9620 - accuracy: 0.9620 - val_loss: 2.8398 - val_accuracy: 0.6622 - lr: 0.0031\n",
            "Epoch 376/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9608 - accuracy: 0.9616\n",
            "Epoch 00376: val_accuracy did not improve from 0.66600\n",
            "\n",
            "Epoch 00376: ReduceLROnPlateau reducing learning rate to 0.002781283319927752.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9608 - accuracy: 0.9616 - val_loss: 2.8679 - val_accuracy: 0.6597 - lr: 0.0031\n",
            "Epoch 377/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9541 - accuracy: 0.9619\n",
            "Epoch 00377: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9541 - accuracy: 0.9619 - val_loss: 2.8208 - val_accuracy: 0.6654 - lr: 0.0028\n",
            "Epoch 378/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9359 - accuracy: 0.9667\n",
            "Epoch 00378: val_accuracy did not improve from 0.66600\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9359 - accuracy: 0.9667 - val_loss: 2.8367 - val_accuracy: 0.6639 - lr: 0.0028\n",
            "Epoch 379/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9321 - accuracy: 0.9659\n",
            "Epoch 00379: val_accuracy improved from 0.66600 to 0.66720, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.9321 - accuracy: 0.9659 - val_loss: 2.8317 - val_accuracy: 0.6672 - lr: 0.0028\n",
            "Epoch 380/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9302 - accuracy: 0.9653\n",
            "Epoch 00380: val_accuracy did not improve from 0.66720\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9302 - accuracy: 0.9653 - val_loss: 2.8709 - val_accuracy: 0.6615 - lr: 0.0028\n",
            "Epoch 381/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9262 - accuracy: 0.9653\n",
            "Epoch 00381: val_accuracy did not improve from 0.66720\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9262 - accuracy: 0.9653 - val_loss: 2.8281 - val_accuracy: 0.6643 - lr: 0.0028\n",
            "Epoch 382/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9150 - accuracy: 0.9668\n",
            "Epoch 00382: val_accuracy did not improve from 0.66720\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9150 - accuracy: 0.9668 - val_loss: 2.8418 - val_accuracy: 0.6603 - lr: 0.0028\n",
            "Epoch 383/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9091 - accuracy: 0.9675\n",
            "Epoch 00383: val_accuracy improved from 0.66720 to 0.66880, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 44ms/step - loss: 0.9091 - accuracy: 0.9675 - val_loss: 2.7863 - val_accuracy: 0.6688 - lr: 0.0028\n",
            "Epoch 384/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8994 - accuracy: 0.9677\n",
            "Epoch 00384: val_accuracy did not improve from 0.66880\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8996 - accuracy: 0.9676 - val_loss: 2.8068 - val_accuracy: 0.6660 - lr: 0.0028\n",
            "Epoch 385/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9016 - accuracy: 0.9668\n",
            "Epoch 00385: val_accuracy did not improve from 0.66880\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.9016 - accuracy: 0.9668 - val_loss: 2.8320 - val_accuracy: 0.6646 - lr: 0.0028\n",
            "Epoch 386/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8992 - accuracy: 0.9647\n",
            "Epoch 00386: val_accuracy did not improve from 0.66880\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8992 - accuracy: 0.9647 - val_loss: 2.8344 - val_accuracy: 0.6675 - lr: 0.0028\n",
            "Epoch 387/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8979 - accuracy: 0.9657\n",
            "Epoch 00387: val_accuracy did not improve from 0.66880\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8979 - accuracy: 0.9657 - val_loss: 2.7974 - val_accuracy: 0.6655 - lr: 0.0028\n",
            "Epoch 388/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.9649\n",
            "Epoch 00388: val_accuracy did not improve from 0.66880\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8937 - accuracy: 0.9649 - val_loss: 2.7982 - val_accuracy: 0.6686 - lr: 0.0028\n",
            "Epoch 389/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8887 - accuracy: 0.9668\n",
            "Epoch 00389: val_accuracy did not improve from 0.66880\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8887 - accuracy: 0.9668 - val_loss: 2.8166 - val_accuracy: 0.6624 - lr: 0.0028\n",
            "Epoch 390/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8961 - accuracy: 0.9635\n",
            "Epoch 00390: val_accuracy did not improve from 0.66880\n",
            "\n",
            "Epoch 00390: ReduceLROnPlateau reducing learning rate to 0.002503155008889735.\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8961 - accuracy: 0.9635 - val_loss: 2.8167 - val_accuracy: 0.6603 - lr: 0.0028\n",
            "Epoch 391/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8807 - accuracy: 0.9668\n",
            "Epoch 00391: val_accuracy did not improve from 0.66880\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8807 - accuracy: 0.9668 - val_loss: 2.8228 - val_accuracy: 0.6627 - lr: 0.0025\n",
            "Epoch 392/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8696 - accuracy: 0.9689\n",
            "Epoch 00392: val_accuracy improved from 0.66880 to 0.67230, saving model to best_model_vgg16\n",
            "INFO:tensorflow:Assets written to: best_model_vgg16/assets\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 0.8696 - accuracy: 0.9689 - val_loss: 2.7778 - val_accuracy: 0.6723 - lr: 0.0025\n",
            "Epoch 393/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8609 - accuracy: 0.9698\n",
            "Epoch 00393: val_accuracy did not improve from 0.67230\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8609 - accuracy: 0.9698 - val_loss: 2.8326 - val_accuracy: 0.6628 - lr: 0.0025\n",
            "Epoch 394/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8520 - accuracy: 0.9715\n",
            "Epoch 00394: val_accuracy did not improve from 0.67230\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8520 - accuracy: 0.9715 - val_loss: 2.7675 - val_accuracy: 0.6631 - lr: 0.0025\n",
            "Epoch 395/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8521 - accuracy: 0.9694\n",
            "Epoch 00395: val_accuracy did not improve from 0.67230\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8521 - accuracy: 0.9694 - val_loss: 2.7693 - val_accuracy: 0.6690 - lr: 0.0025\n",
            "Epoch 396/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8396 - accuracy: 0.9720\n",
            "Epoch 00396: val_accuracy did not improve from 0.67230\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8396 - accuracy: 0.9720 - val_loss: 2.8335 - val_accuracy: 0.6611 - lr: 0.0025\n",
            "Epoch 397/400\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8357 - accuracy: 0.9724\n",
            "Epoch 00397: val_accuracy did not improve from 0.67230\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8360 - accuracy: 0.9724 - val_loss: 2.7708 - val_accuracy: 0.6673 - lr: 0.0025\n",
            "Epoch 398/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.9695\n",
            "Epoch 00398: val_accuracy did not improve from 0.67230\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8386 - accuracy: 0.9695 - val_loss: 2.7714 - val_accuracy: 0.6653 - lr: 0.0025\n",
            "Epoch 399/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8324 - accuracy: 0.9714\n",
            "Epoch 00399: val_accuracy did not improve from 0.67230\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8324 - accuracy: 0.9714 - val_loss: 2.8045 - val_accuracy: 0.6617 - lr: 0.0025\n",
            "Epoch 400/400\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8302 - accuracy: 0.9703\n",
            "Epoch 00400: val_accuracy did not improve from 0.67230\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.8302 - accuracy: 0.9703 - val_loss: 2.7888 - val_accuracy: 0.6674 - lr: 0.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFkPwJJ_W9Iw",
        "outputId": "3dab10ba-6aa8-410b-f360-51a5f51be52c"
      },
      "source": [
        "X_train,y_train,X_test,y_test=select_dataset(3)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar100(X_train,y_train,X_test,y_test,3)\n",
        "model=ResNet34(image_shape,100)\n",
        "history_resnet=train_model_resnet34(X_train,y_train,X_test,y_test,epochs=300)\n",
        "model.save('Desktop/resnet_cifar100.h5')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "(32, 32, 3)\n",
            "Epoch 1/300\n",
            "390/391 [============================>.] - ETA: 0s - loss: 4.4974 - accuracy: 0.0231\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.02860, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 4.4972 - accuracy: 0.0231 - val_loss: 4.3085 - val_accuracy: 0.0286 - lr: 0.1000\n",
            "Epoch 2/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 4.1364 - accuracy: 0.0458\n",
            "Epoch 00002: val_accuracy improved from 0.02860 to 0.04930, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 4.1356 - accuracy: 0.0459 - val_loss: 4.2191 - val_accuracy: 0.0493 - lr: 0.1000\n",
            "Epoch 3/300\n",
            "390/391 [============================>.] - ETA: 0s - loss: 3.8552 - accuracy: 0.0862\n",
            "Epoch 00003: val_accuracy improved from 0.04930 to 0.10660, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 3.8545 - accuracy: 0.0863 - val_loss: 3.7300 - val_accuracy: 0.1066 - lr: 0.1000\n",
            "Epoch 4/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.5576 - accuracy: 0.1381\n",
            "Epoch 00004: val_accuracy improved from 0.10660 to 0.11070, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 50ms/step - loss: 3.5578 - accuracy: 0.1381 - val_loss: 3.8207 - val_accuracy: 0.1107 - lr: 0.1000\n",
            "Epoch 5/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.3032 - accuracy: 0.1822\n",
            "Epoch 00005: val_accuracy improved from 0.11070 to 0.18370, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 3.3035 - accuracy: 0.1823 - val_loss: 3.3491 - val_accuracy: 0.1837 - lr: 0.1000\n",
            "Epoch 6/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.0843 - accuracy: 0.2240\n",
            "Epoch 00006: val_accuracy improved from 0.18370 to 0.21210, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 3.0830 - accuracy: 0.2241 - val_loss: 3.2986 - val_accuracy: 0.2121 - lr: 0.1000\n",
            "Epoch 7/300\n",
            "390/391 [============================>.] - ETA: 0s - loss: 2.8831 - accuracy: 0.2647\n",
            "Epoch 00007: val_accuracy improved from 0.21210 to 0.26000, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 2.8832 - accuracy: 0.2646 - val_loss: 2.9570 - val_accuracy: 0.2600 - lr: 0.1000\n",
            "Epoch 8/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.6984 - accuracy: 0.3021\n",
            "Epoch 00008: val_accuracy improved from 0.26000 to 0.28880, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 2.6992 - accuracy: 0.3020 - val_loss: 2.8319 - val_accuracy: 0.2888 - lr: 0.1000\n",
            "Epoch 9/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.5408 - accuracy: 0.3358\n",
            "Epoch 00009: val_accuracy improved from 0.28880 to 0.29450, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 2.5417 - accuracy: 0.3357 - val_loss: 2.8471 - val_accuracy: 0.2945 - lr: 0.1000\n",
            "Epoch 10/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.3894 - accuracy: 0.3678\n",
            "Epoch 00010: val_accuracy improved from 0.29450 to 0.30690, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 2.3900 - accuracy: 0.3677 - val_loss: 2.7653 - val_accuracy: 0.3069 - lr: 0.1000\n",
            "Epoch 11/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.2321 - accuracy: 0.4003\n",
            "Epoch 00011: val_accuracy improved from 0.30690 to 0.32150, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 2.2328 - accuracy: 0.4000 - val_loss: 2.7262 - val_accuracy: 0.3215 - lr: 0.1000\n",
            "Epoch 12/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.0769 - accuracy: 0.4361\n",
            "Epoch 00012: val_accuracy improved from 0.32150 to 0.34890, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 2.0761 - accuracy: 0.4364 - val_loss: 2.6597 - val_accuracy: 0.3489 - lr: 0.1000\n",
            "Epoch 13/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.9358 - accuracy: 0.4700\n",
            "Epoch 00013: val_accuracy did not improve from 0.34890\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 1.9354 - accuracy: 0.4701 - val_loss: 2.7068 - val_accuracy: 0.3461 - lr: 0.1000\n",
            "Epoch 14/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.7901 - accuracy: 0.5034\n",
            "Epoch 00014: val_accuracy did not improve from 0.34890\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 1.7911 - accuracy: 0.5033 - val_loss: 2.7546 - val_accuracy: 0.3388 - lr: 0.1000\n",
            "Epoch 15/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.6331 - accuracy: 0.5367\n",
            "Epoch 00015: val_accuracy did not improve from 0.34890\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 1.6327 - accuracy: 0.5367 - val_loss: 2.8297 - val_accuracy: 0.3478 - lr: 0.1000\n",
            "Epoch 16/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.5064 - accuracy: 0.5666\n",
            "Epoch 00016: val_accuracy improved from 0.34890 to 0.36550, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 1.5065 - accuracy: 0.5665 - val_loss: 2.8394 - val_accuracy: 0.3655 - lr: 0.1000\n",
            "Epoch 17/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3769 - accuracy: 0.6023\n",
            "Epoch 00017: val_accuracy improved from 0.36550 to 0.37040, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 1.3774 - accuracy: 0.6021 - val_loss: 2.8256 - val_accuracy: 0.3704 - lr: 0.1000\n",
            "Epoch 18/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2759 - accuracy: 0.6241\n",
            "Epoch 00018: val_accuracy did not improve from 0.37040\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 1.2759 - accuracy: 0.6242 - val_loss: 2.9958 - val_accuracy: 0.3673 - lr: 0.1000\n",
            "Epoch 19/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.1909 - accuracy: 0.6481\n",
            "Epoch 00019: val_accuracy did not improve from 0.37040\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.09000000134110452.\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 1.1913 - accuracy: 0.6480 - val_loss: 3.0138 - val_accuracy: 0.3554 - lr: 0.1000\n",
            "Epoch 20/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9975 - accuracy: 0.7024\n",
            "Epoch 00020: val_accuracy did not improve from 0.37040\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.9985 - accuracy: 0.7020 - val_loss: 3.3442 - val_accuracy: 0.3642 - lr: 0.0900\n",
            "Epoch 21/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8614 - accuracy: 0.7362\n",
            "Epoch 00021: val_accuracy did not improve from 0.37040\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.8623 - accuracy: 0.7360 - val_loss: 3.4935 - val_accuracy: 0.3572 - lr: 0.0900\n",
            "Epoch 22/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7885 - accuracy: 0.7570\n",
            "Epoch 00022: val_accuracy improved from 0.37040 to 0.37250, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.7895 - accuracy: 0.7566 - val_loss: 3.3357 - val_accuracy: 0.3725 - lr: 0.0900\n",
            "Epoch 23/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7050 - accuracy: 0.7803\n",
            "Epoch 00023: val_accuracy did not improve from 0.37250\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.7059 - accuracy: 0.7800 - val_loss: 3.8416 - val_accuracy: 0.3626 - lr: 0.0900\n",
            "Epoch 24/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6564 - accuracy: 0.7949\n",
            "Epoch 00024: val_accuracy did not improve from 0.37250\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.6579 - accuracy: 0.7944 - val_loss: 3.8443 - val_accuracy: 0.3501 - lr: 0.0900\n",
            "Epoch 25/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6172 - accuracy: 0.8079\n",
            "Epoch 00025: val_accuracy did not improve from 0.37250\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.6191 - accuracy: 0.8075 - val_loss: 3.7747 - val_accuracy: 0.3604 - lr: 0.0900\n",
            "Epoch 26/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6974 - accuracy: 0.7876\n",
            "Epoch 00026: val_accuracy did not improve from 0.37250\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.08100000321865082.\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.6983 - accuracy: 0.7874 - val_loss: 3.6756 - val_accuracy: 0.3582 - lr: 0.0900\n",
            "Epoch 27/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.4854 - accuracy: 0.8474\n",
            "Epoch 00027: val_accuracy did not improve from 0.37250\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.4854 - accuracy: 0.8473 - val_loss: 4.0720 - val_accuracy: 0.3639 - lr: 0.0810\n",
            "Epoch 28/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.4080 - accuracy: 0.8718\n",
            "Epoch 00028: val_accuracy improved from 0.37250 to 0.37920, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 0.4082 - accuracy: 0.8717 - val_loss: 4.1779 - val_accuracy: 0.3792 - lr: 0.0810\n",
            "Epoch 29/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8896\n",
            "Epoch 00029: val_accuracy did not improve from 0.37920\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.3515 - accuracy: 0.8895 - val_loss: 4.3801 - val_accuracy: 0.3704 - lr: 0.0810\n",
            "Epoch 30/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.3375 - accuracy: 0.8939\n",
            "Epoch 00030: val_accuracy did not improve from 0.37920\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.3377 - accuracy: 0.8937 - val_loss: 4.4578 - val_accuracy: 0.3715 - lr: 0.0810\n",
            "Epoch 31/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.3501 - accuracy: 0.8899\n",
            "Epoch 00031: val_accuracy did not improve from 0.37920\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.3503 - accuracy: 0.8898 - val_loss: 4.6711 - val_accuracy: 0.3714 - lr: 0.0810\n",
            "Epoch 32/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.9099\n",
            "Epoch 00032: val_accuracy did not improve from 0.37920\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.2821 - accuracy: 0.9097 - val_loss: 4.7210 - val_accuracy: 0.3722 - lr: 0.0810\n",
            "Epoch 33/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9151\n",
            "Epoch 00033: val_accuracy improved from 0.37920 to 0.38530, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.07290000021457672.\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.2721 - accuracy: 0.9152 - val_loss: 4.7055 - val_accuracy: 0.3853 - lr: 0.0810\n",
            "Epoch 34/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9353\n",
            "Epoch 00034: val_accuracy did not improve from 0.38530\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.2063 - accuracy: 0.9352 - val_loss: 4.9032 - val_accuracy: 0.3845 - lr: 0.0729\n",
            "Epoch 35/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1928 - accuracy: 0.9392\n",
            "Epoch 00035: val_accuracy did not improve from 0.38530\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1928 - accuracy: 0.9391 - val_loss: 5.0805 - val_accuracy: 0.3832 - lr: 0.0729\n",
            "Epoch 36/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1759 - accuracy: 0.9438\n",
            "Epoch 00036: val_accuracy improved from 0.38530 to 0.38570, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.1760 - accuracy: 0.9438 - val_loss: 5.2446 - val_accuracy: 0.3857 - lr: 0.0729\n",
            "Epoch 37/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9498\n",
            "Epoch 00037: val_accuracy did not improve from 0.38570\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1592 - accuracy: 0.9498 - val_loss: 5.1609 - val_accuracy: 0.3795 - lr: 0.0729\n",
            "Epoch 38/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1522 - accuracy: 0.9529\n",
            "Epoch 00038: val_accuracy did not improve from 0.38570\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1523 - accuracy: 0.9529 - val_loss: 5.3562 - val_accuracy: 0.3755 - lr: 0.0729\n",
            "Epoch 39/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9502\n",
            "Epoch 00039: val_accuracy improved from 0.38570 to 0.38610, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.1603 - accuracy: 0.9502 - val_loss: 5.3357 - val_accuracy: 0.3861 - lr: 0.0729\n",
            "Epoch 40/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1768 - accuracy: 0.9450\n",
            "Epoch 00040: val_accuracy improved from 0.38610 to 0.38770, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.06560999751091004.\n",
            "391/391 [==============================] - 20s 51ms/step - loss: 0.1769 - accuracy: 0.9449 - val_loss: 5.2791 - val_accuracy: 0.3877 - lr: 0.0729\n",
            "Epoch 41/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9657\n",
            "Epoch 00041: val_accuracy did not improve from 0.38770\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1094 - accuracy: 0.9657 - val_loss: 5.6451 - val_accuracy: 0.3852 - lr: 0.0656\n",
            "Epoch 42/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 0.9744\n",
            "Epoch 00042: val_accuracy did not improve from 0.38770\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0826 - accuracy: 0.9744 - val_loss: 6.1438 - val_accuracy: 0.3785 - lr: 0.0656\n",
            "Epoch 43/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9748\n",
            "Epoch 00043: val_accuracy improved from 0.38770 to 0.39250, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.0799 - accuracy: 0.9747 - val_loss: 5.8370 - val_accuracy: 0.3925 - lr: 0.0656\n",
            "Epoch 44/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9751\n",
            "Epoch 00044: val_accuracy did not improve from 0.39250\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0831 - accuracy: 0.9751 - val_loss: 5.7277 - val_accuracy: 0.3864 - lr: 0.0656\n",
            "Epoch 45/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9630\n",
            "Epoch 00045: val_accuracy did not improve from 0.39250\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1198 - accuracy: 0.9628 - val_loss: 5.4558 - val_accuracy: 0.3864 - lr: 0.0656\n",
            "Epoch 46/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9648\n",
            "Epoch 00046: val_accuracy did not improve from 0.39250\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1112 - accuracy: 0.9649 - val_loss: 5.7233 - val_accuracy: 0.3896 - lr: 0.0656\n",
            "Epoch 47/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9765\n",
            "Epoch 00047: val_accuracy improved from 0.39250 to 0.39520, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.05904899910092354.\n",
            "391/391 [==============================] - 21s 53ms/step - loss: 0.0778 - accuracy: 0.9764 - val_loss: 6.4653 - val_accuracy: 0.3952 - lr: 0.0656\n",
            "Epoch 48/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9806\n",
            "Epoch 00048: val_accuracy improved from 0.39520 to 0.39650, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 6.0007 - val_accuracy: 0.3965 - lr: 0.0590\n",
            "Epoch 49/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9865\n",
            "Epoch 00049: val_accuracy improved from 0.39650 to 0.39990, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.0458 - accuracy: 0.9866 - val_loss: 6.4132 - val_accuracy: 0.3999 - lr: 0.0590\n",
            "Epoch 50/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9881\n",
            "Epoch 00050: val_accuracy improved from 0.39990 to 0.40170, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.0384 - accuracy: 0.9881 - val_loss: 6.2805 - val_accuracy: 0.4017 - lr: 0.0590\n",
            "Epoch 51/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0900 - accuracy: 0.9728\n",
            "Epoch 00051: val_accuracy did not improve from 0.40170\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0902 - accuracy: 0.9728 - val_loss: 6.1606 - val_accuracy: 0.3907 - lr: 0.0590\n",
            "Epoch 52/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0622 - accuracy: 0.9806\n",
            "Epoch 00052: val_accuracy did not improve from 0.40170\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0625 - accuracy: 0.9805 - val_loss: 6.2899 - val_accuracy: 0.3911 - lr: 0.0590\n",
            "Epoch 53/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9847\n",
            "Epoch 00053: val_accuracy did not improve from 0.40170\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 6.4361 - val_accuracy: 0.3967 - lr: 0.0590\n",
            "Epoch 54/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9876\n",
            "Epoch 00054: val_accuracy did not improve from 0.40170\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.053144099190831184.\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0396 - accuracy: 0.9877 - val_loss: 6.6828 - val_accuracy: 0.3916 - lr: 0.0590\n",
            "Epoch 55/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9917\n",
            "Epoch 00055: val_accuracy did not improve from 0.40170\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.0281 - accuracy: 0.9917 - val_loss: 6.8405 - val_accuracy: 0.3915 - lr: 0.0531\n",
            "Epoch 56/300\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9929\n",
            "Epoch 00056: val_accuracy improved from 0.40170 to 0.40590, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 52ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 6.7903 - val_accuracy: 0.4059 - lr: 0.0531\n",
            "Epoch 57/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9949\n",
            "Epoch 00057: val_accuracy did not improve from 0.40590\n",
            "391/391 [==============================] - 12s 30ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 6.8038 - val_accuracy: 0.4059 - lr: 0.0531\n",
            "Epoch 58/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
            "Epoch 00058: val_accuracy improved from 0.40590 to 0.40750, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 20s 50ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 6.9424 - val_accuracy: 0.4075 - lr: 0.0531\n",
            "Epoch 59/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9968\n",
            "Epoch 00059: val_accuracy did not improve from 0.40750\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 7.0167 - val_accuracy: 0.4020 - lr: 0.0531\n",
            "Epoch 60/300\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9954\n",
            "Epoch 00060: val_accuracy did not improve from 0.40750\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 7.0771 - val_accuracy: 0.4056 - lr: 0.0531\n",
            "Epoch 61/300\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9967\n",
            "Epoch 00061: val_accuracy did not improve from 0.40750\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.04782968759536743.\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 7.0152 - val_accuracy: 0.4033 - lr: 0.0531\n",
            "Epoch 62/300\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981\n",
            "Epoch 00062: val_accuracy improved from 0.40750 to 0.41310, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n",
            "391/391 [==============================] - 21s 53ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 6.9968 - val_accuracy: 0.4131 - lr: 0.0478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nByF_LBZLjlT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d145a32-996d-4a7f-95c5-0202dbde9df0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "''' \n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_cnn_model.history['val_loss'])\n",
        "plt.title('Validation loss history cnn_model')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_cnn_model.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history cnn_model')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "'''\n",
        "'''\n",
        "print()\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_resnet.history['val_loss'])\n",
        "plt.title('Validation loss history resnet')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_resnet.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history resnet')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "'''\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_vgg16.history['val_loss'])\n",
        "plt.title('Validation loss history vgg16')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "print()\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_vgg16.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history vgg16')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAcBj-qKPync"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOD9JcqI26C2"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCv-lOO9FiBM"
      },
      "source": [
        "'''X_train,y_train,X_test,y_test=select_dataset(1)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,1)\n",
        "model=define_model_standard_cnn(image_shape,10)\n",
        "history_cnn_model_mnist = train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=100)\n",
        "model.save('Desktop/cnn_model_mnist.h5')'''\n",
        "'''\n",
        "X_train,y_train,X_test,y_test=select_dataset(1)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,1)\n",
        "model=ResNet34(image_shape,10)\n",
        "history_resnet_mnist =train_model_resnet34(X_train,y_train,X_test,y_test,epochs=100)\n",
        "model.save('Desktop/resnet_mnist.h5')'''\n",
        "'''\n",
        "X_train,y_train,X_test,y_test=select_dataset(1)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,1)\n",
        "model=define_model_vgg16(image_shape,10)\n",
        "history_vgg16_mnist=train_model_vgg16(X_train,y_train,X_test,y_test,epochs=100)\n",
        "model.save('Desktop/vgg16_mnist.h5')'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5pRFJsb4_gg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_cnn_model_mnist.history['val_loss'])\n",
        "plt.title('Validation loss history cnn_model')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_cnn_model_mnist.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history cnn_model')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_resnet_mnist.history['val_loss'])\n",
        "plt.title('Validation loss history resnet')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_resnet_mnist.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history resnet')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_vgg16_mnist.history['val_loss'])\n",
        "plt.title('Validation loss history vgg16')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "print()\n",
        "# Plot history: Accuracy\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history_vgg16_mnist.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history vgg16')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft7PyESazG0f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}