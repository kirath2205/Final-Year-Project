{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Test_bench.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+Ktr0S9Ls4yPqa4AoPGwN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirath2205/Final-Year-Project/blob/Test_bench/Test_bench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcyH2uCmqDOG"
      },
      "source": [
        "import keras,os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D , Dropout\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50 , preprocess_input\n",
        "from keras import regularizers\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlBqJ6SIkZ0u",
        "outputId": "60e31b56-82e9-4345-d489-8cd02f6ee195"
      },
      "source": [
        "!pip install Keras-applications\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Keras-applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-applications) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-applications) (1.5.2)\n",
            "Installing collected packages: Keras-applications\n",
            "Successfully installed Keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVVahuJ1t7HD"
      },
      "source": [
        "def select_dataset(index):\n",
        "\n",
        "  if(index==1):\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist\n",
        "\n",
        "  elif(index==2):\n",
        "    cifar_10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar_10\n",
        "  \n",
        "  elif(index==3):\n",
        "    cifar_100 = tf.keras.datasets.cifar100.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar_100\n",
        "    print(len(X_train))\n",
        "\n",
        "    \n",
        "  return X_train,y_train,X_test,y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQV52_6GvrRS"
      },
      "source": [
        "def pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,image_channel):\n",
        "  img_width = X_train.shape[1]\n",
        "  img_height = X_train.shape[2]\n",
        "  input_shape = (img_width, img_height, image_channel)\n",
        "  \n",
        "  # normalize data\n",
        "  X_train, X_test = X_train / 255, X_test / 255\n",
        "\n",
        "  # reshape input \n",
        "  X_train = X_train.reshape(X_train.shape[0], *input_shape)\n",
        "  X_test = X_test.reshape(X_test.shape[0], *input_shape)\n",
        "\n",
        "  # one-hot\n",
        "  y_train = tf.keras.utils.to_categorical(y_train)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  return X_train,y_train,X_test,y_test,input_shape\n",
        "\n",
        "def pre_processing_cifar10(X_train,y_train,X_test,y_test,image_channel):\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "  img_width = X_train[0].shape[0]\n",
        "  img_height = X_train[0].shape[1]\n",
        "  image_channel = image_channel\n",
        "\n",
        "  input_shape=(img_width,img_height,image_channel) \n",
        "  print(input_shape)\n",
        "  return X_train,y_train,X_test,y_test,input_shape\n",
        "  \n",
        "def pre_processing_cifar100(X_train,y_train,X_test,y_test,image_channel):\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_train = preprocess_input(X_train)\n",
        "  X_test = preprocess_input(X_test)\n",
        "\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "  img_width = X_train[0].shape[0]\n",
        "  img_height = X_train[0].shape[1]\n",
        "  image_channel = image_channel\n",
        "\n",
        "  input_shape=(img_width,img_height,image_channel) \n",
        "  print(input_shape)\n",
        "  return X_train,y_train,X_test,y_test,input_shape"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDvpMVLzu3if"
      },
      "source": [
        "def define_model_vgg16(image_shape,total_classes):\n",
        "\n",
        "  model = Sequential()\n",
        "  weight_decay = 0.0005\n",
        "  learning_rate = 0.1\n",
        "  lr_decay = 1e-6\n",
        "  lr_drop = 20\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=image_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(total_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  sgd = keras.optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def define_model_standard_cnn(image_shape,total_classes):\n",
        "  initializer = tf.keras.initializers.HeUniform()\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32,(3,3), activation = 'relu',  padding = 'same', input_shape = image_shape))\n",
        "  model.add(Conv2D(32,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))  \n",
        "  model.add(Conv2D(64,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(Conv2D(64,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(128,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(Conv2D(128,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation = 'relu'))\n",
        "  model.add(Dense(total_classes, activation = 'softmax'))\n",
        "  opt = keras.optimizers.SGD(learning_rate=0.001 , momentum=0.9)\n",
        "  model.compile(optimizer=opt,loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MAaxp2hqAR"
      },
      "source": [
        "def identity_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])     \n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def convolutional_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Processing Residue with conv(1,1)\n",
        "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])     \n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet34(shape, classes):\n",
        "    # Step 1 (Setup Input Layer)\n",
        "    x_input = tf.keras.layers.Input(shape)\n",
        "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
        "    # Step 2 (Initial Conv layer along with maxPool)\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "    # Define size of sub-blocks and initial filter size\n",
        "    block_layers = [3, 4, 6, 3]\n",
        "    filter_size = 64\n",
        "    # Step 3 Add the Resnet Blocks\n",
        "    for i in range(4):\n",
        "        if i == 0:\n",
        "            # For sub-block 1 Residual/Convolutional block not needed\n",
        "            for j in range(block_layers[i]):\n",
        "                x = identity_block(x, filter_size)\n",
        "        else:\n",
        "            # One Residual/Convolutional Block followed by Identity blocks\n",
        "            # The filter size will go on increasing by a factor of 2\n",
        "            filter_size = filter_size*2\n",
        "            x = convolutional_block(x, filter_size)\n",
        "            for j in range(block_layers[i] - 1):\n",
        "                x = identity_block(x, filter_size)\n",
        "    # Step 4 End Dense Network\n",
        "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaRAX4NsO-qR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2525dc03-b01a-4b09-fd98-326ddd836ef4"
      },
      "source": [
        "'''def identity_block(layer,f,nfilters):\n",
        "    Xshortcut=layer\n",
        "    F1,F2,F3=nfilters\n",
        "    layer=Conv2D(F1,(1,1),padding='valid')(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "    \n",
        "    layer=Conv2D(F2,(f,f),padding='same')(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "    \n",
        "    layer=Conv2D(F3,(1,1),padding='valid')(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    \n",
        "    layer=Add()([Xshortcut,layer])\n",
        "    layer=Activation('relu')(layer)\n",
        "    return(layer)\n",
        "\n",
        "def Conv_block(layer,f,nfilters,s=2):\n",
        "    Xshortcut=layer\n",
        "    F1,F2,F3=nfilters\n",
        "    layer=Conv2D(F1,(1,1),strides=(s,s))(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "    \n",
        "    layer=Conv2D(F2,(f,f),padding='same')(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "    \n",
        "    layer=Conv2D(F3,(1,1))(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    \n",
        "    Xshortcut=Conv2D(F3,(1,1),strides=(s,s))(Xshortcut)\n",
        "    Xshortcut=BatchNormalization(axis=-1)(Xshortcut)\n",
        "    \n",
        "    layer=Add()([Xshortcut,layer])\n",
        "    layer=Activation('relu')(layer)\n",
        "    return(layer)\n",
        "\n",
        "def Resnet50(img_shape,numclasses):\n",
        "    img_inp=Input(shape=img_shape,dtype=tf.float32)\n",
        "    X=ZeroPadding2D((3,3))(img_inp)\n",
        "    X=Conv2D(64,(7,7),strides=(2,2))(X)\n",
        "    X=BatchNormalization(axis=-1)(X)\n",
        "    X=Activation('relu')(X)\n",
        "    \n",
        "    X=MaxPooling2D((3,3),strides=(2,2),padding='same')(X)\n",
        "    X=Conv_block(X,3,[64,64,256],s=1)\n",
        "    X=identity_block(X,3,[64,64,256])\n",
        "    X=identity_block(X,3,[64,64,256])\n",
        "    \n",
        "    X=Conv_block(X,3,[128,128,512],s=2)\n",
        "    X=identity_block(X,3,[128,128,512])\n",
        "    X=identity_block(X,3,[128,128,512])\n",
        "    X=identity_block(X,3,[128,128,512])\n",
        "    \n",
        "    X=Conv_block(X,3,[256,256,1024],s=2)\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    \n",
        "    X=Conv_block(X,3,[512,512,2048],s=2)\n",
        "    X=identity_block(X,3,[512,512,2048])\n",
        "    X=identity_block(X,3,[512,512,2048])\n",
        "    \n",
        "    X=AveragePooling2D((7,7) , padding='same')(X)\n",
        "    \n",
        "    X=Flatten()(X)\n",
        "    X=Dense(numclasses,activation='softmax')(X)\n",
        "    model=Model(inputs=img_inp,outputs=X)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return(model)'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"def identity_block(layer,f,nfilters):\\n    Xshortcut=layer\\n    F1,F2,F3=nfilters\\n    layer=Conv2D(F1,(1,1),padding='valid')(layer)\\n    layer=BatchNormalization(axis=-1)(layer)\\n    layer=Activation('relu')(layer)\\n    \\n    layer=Conv2D(F2,(f,f),padding='same')(layer)\\n    layer=BatchNormalization(axis=-1)(layer)\\n    layer=Activation('relu')(layer)\\n    \\n    layer=Conv2D(F3,(1,1),padding='valid')(layer)\\n    layer=BatchNormalization(axis=-1)(layer)\\n    \\n    layer=Add()([Xshortcut,layer])\\n    layer=Activation('relu')(layer)\\n    return(layer)\\n\\ndef Conv_block(layer,f,nfilters,s=2):\\n    Xshortcut=layer\\n    F1,F2,F3=nfilters\\n    layer=Conv2D(F1,(1,1),strides=(s,s))(layer)\\n    layer=BatchNormalization(axis=-1)(layer)\\n    layer=Activation('relu')(layer)\\n    \\n    layer=Conv2D(F2,(f,f),padding='same')(layer)\\n    layer=BatchNormalization(axis=-1)(layer)\\n    layer=Activation('relu')(layer)\\n    \\n    layer=Conv2D(F3,(1,1))(layer)\\n    layer=BatchNormalization(axis=-1)(layer)\\n    \\n    Xshortcut=Conv2D(F3,(1,1),strides=(s,s))(Xshortcut)\\n    Xshortcut=BatchNormalization(axis=-1)(Xshortcut)\\n    \\n    layer=Add()([Xshortcut,layer])\\n    layer=Activation('relu')(layer)\\n    return(layer)\\n\\ndef Resnet50(img_shape,numclasses):\\n    img_inp=Input(shape=img_shape,dtype=tf.float32)\\n    X=ZeroPadding2D((3,3))(img_inp)\\n    X=Conv2D(64,(7,7),strides=(2,2))(X)\\n    X=BatchNormalization(axis=-1)(X)\\n    X=Activation('relu')(X)\\n    \\n    X=MaxPooling2D((3,3),strides=(2,2),padding='same')(X)\\n    X=Conv_block(X,3,[64,64,256],s=1)\\n    X=identity_block(X,3,[64,64,256])\\n    X=identity_block(X,3,[64,64,256])\\n    \\n    X=Conv_block(X,3,[128,128,512],s=2)\\n    X=identity_block(X,3,[128,128,512])\\n    X=identity_block(X,3,[128,128,512])\\n    X=identity_block(X,3,[128,128,512])\\n    \\n    X=Conv_block(X,3,[256,256,1024],s=2)\\n    X=identity_block(X,3,[256,256,1024])\\n    X=identity_block(X,3,[256,256,1024])\\n    X=identity_block(X,3,[256,256,1024])\\n    X=identity_block(X,3,[256,256,1024])\\n    X=identity_block(X,3,[256,256,1024])\\n    \\n    X=Conv_block(X,3,[512,512,2048],s=2)\\n    X=identity_block(X,3,[512,512,2048])\\n    X=identity_block(X,3,[512,512,2048])\\n    \\n    X=AveragePooling2D((7,7) , padding='same')(X)\\n    \\n    X=Flatten()(X)\\n    X=Dense(numclasses,activation='softmax')(X)\\n    model=Model(inputs=img_inp,outputs=X)\\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\\n    \\n    return(model)\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgsl1X29yf2k"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "def train_model_vgg16(X_train,y_train,X_test,y_test,epochs=10,batch_size=128):\n",
        "  \n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_vgg16', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 )\n",
        "  ]\n",
        "  history=model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size,callbacks = callbacks, verbose = 1,validation_data=(X_test,y_test))\n",
        "  return history\n",
        "\n",
        "def train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=10,batch_size=64):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_standard_cnn', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 )\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size=batch_size , callbacks = callbacks)\n",
        "  return history\n",
        "\n",
        "def train_model_resnet50(X_train,y_train,X_test,y_test,epochs=10):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_resnet50', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 )\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size= 64 , callbacks = callbacks)\n",
        "  return history\n",
        "\n",
        "def train_model_resnet34(X_train,y_train,X_test,y_test,epochs=10):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_resnet50', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 )\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size= 64 , callbacks = callbacks)\n",
        "  return history"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeJvjs7VO9-u"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6AWutrFy4V8"
      },
      "source": [
        "def make_prediction(model,X_test,index):\n",
        "\n",
        "  return model.predict(X_test(index))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UiQLmEn1vuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06a3631-2124-4fa0-8a3b-96483289efe1"
      },
      "source": [
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(1)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,1)\n",
        "model=define_model(image_shape,10)\n",
        "train_model(X_train,y_train,X_test,y_test)'''\n",
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(2)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar10(X_train,y_train,X_test,y_test,3)\n",
        "model=define_model_standard_cnn(image_shape,10)\n",
        "train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=75)'''\n",
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(2)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar100(X_train,y_train,X_test,y_test,3)\n",
        "model=Resnet50(image_shape,10)\n",
        "history=train_model_resnet50(X_train,y_train,X_test,y_test,epochs=100)'''\n",
        "\n",
        "X_train,y_train,X_test,y_test=select_dataset(2)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar10(X_train,y_train,X_test,y_test,3)\n",
        "model=ResNet34(image_shape,10)\n",
        "history=train_model_resnet34(X_train,y_train,X_test,y_test,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n",
            "Epoch 1/100\n",
            "782/782 [==============================] - 129s 122ms/step - loss: 1.5428 - accuracy: 0.4353 - val_loss: 1.8306 - val_accuracy: 0.4100\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.41000, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100\n",
            "782/782 [==============================] - 95s 121ms/step - loss: 1.1155 - accuracy: 0.6006 - val_loss: 1.1330 - val_accuracy: 0.5997\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.41000 to 0.59970, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100\n",
            "782/782 [==============================] - 95s 121ms/step - loss: 0.9218 - accuracy: 0.6761 - val_loss: 1.0473 - val_accuracy: 0.6420\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.59970 to 0.64200, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100\n",
            "782/782 [==============================] - 95s 121ms/step - loss: 0.7990 - accuracy: 0.7205 - val_loss: 1.0539 - val_accuracy: 0.6623\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.64200 to 0.66230, saving model to best_model_resnet50\n",
            "INFO:tensorflow:Assets written to: best_model_resnet50/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100\n",
            "406/782 [==============>...............] - ETA: 43s - loss: 0.6777 - accuracy: 0.7656"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nByF_LBZLjlT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Validation loss history')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOD9JcqI26C2"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}