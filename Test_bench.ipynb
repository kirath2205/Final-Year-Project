{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Test_bench.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwEU6qpEH5tmBfXgHH7T0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirath2205/Final-Year-Project/blob/Test_bench/Test_bench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcyH2uCmqDOG"
      },
      "source": [
        "import keras,os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D , Dropout\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50 , preprocess_input\n",
        "from keras import regularizers\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlBqJ6SIkZ0u",
        "outputId": "613cd37d-7b69-449c-a5ba-0f8942a07b7d"
      },
      "source": [
        "!pip install Keras-applications\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Keras-applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-applications) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-applications) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVVahuJ1t7HD"
      },
      "source": [
        "def select_dataset(index):\n",
        "\n",
        "  if(index==1):\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist\n",
        "\n",
        "  elif(index==2):\n",
        "    cifar_10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar_10\n",
        "  \n",
        "  elif(index==3):\n",
        "    cifar_100 = tf.keras.datasets.cifar100.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar_100\n",
        "    print(len(X_train))\n",
        "\n",
        "    \n",
        "  return X_train,y_train,X_test,y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQV52_6GvrRS"
      },
      "source": [
        "def pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,image_channel):\n",
        "  img_width = X_train.shape[1]\n",
        "  img_height = X_train.shape[2]\n",
        "  input_shape = (img_width, img_height, image_channel)\n",
        "  \n",
        "  # normalize data\n",
        "  X_train, X_test = X_train / 255, X_test / 255\n",
        "\n",
        "  # reshape input \n",
        "  X_train = X_train.reshape(X_train.shape[0], *input_shape)\n",
        "  X_test = X_test.reshape(X_test.shape[0], *input_shape)\n",
        "\n",
        "  # one-hot\n",
        "  y_train = tf.keras.utils.to_categorical(y_train)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  return X_train,y_train,X_test,y_test,input_shape\n",
        "\n",
        "def pre_processing_cifar10(X_train,y_train,X_test,y_test,image_channel):\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "  img_width = X_train[0].shape[0]\n",
        "  img_height = X_train[0].shape[1]\n",
        "  image_channel = image_channel\n",
        "\n",
        "  input_shape=(img_width,img_height,image_channel) \n",
        "  print(input_shape)\n",
        "  return X_train,y_train,X_test,y_test,input_shape\n",
        "  \n",
        "def pre_processing_cifar100(X_train,y_train,X_test,y_test,image_channel):\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_train = preprocess_input(X_train)\n",
        "  X_test = preprocess_input(X_test)\n",
        "\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "  img_width = X_train[0].shape[0]\n",
        "  img_height = X_train[0].shape[1]\n",
        "  image_channel = image_channel\n",
        "\n",
        "  input_shape=(img_width,img_height,image_channel) \n",
        "  print(input_shape)\n",
        "  return X_train,y_train,X_test,y_test,input_shape"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDvpMVLzu3if"
      },
      "source": [
        "def define_model_vgg16(image_shape,total_classes):\n",
        "\n",
        "  model = Sequential()\n",
        "  weight_decay = 0.0005\n",
        "  learning_rate = 0.1\n",
        "  lr_decay = 1e-6\n",
        "  lr_drop = 20\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=image_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(total_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  sgd = keras.optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def define_model_standard_cnn(image_shape,total_classes):\n",
        "  initializer = tf.keras.initializers.HeUniform()\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32,(3,3), activation = 'relu',  padding = 'same', input_shape = image_shape))\n",
        "  model.add(Conv2D(32,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))  \n",
        "  model.add(Conv2D(64,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(Conv2D(64,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(128,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(Conv2D(128,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation = 'relu'))\n",
        "  model.add(Dense(total_classes, activation = 'softmax'))\n",
        "  opt = keras.optimizers.SGD(learning_rate=0.001 , momentum=0.9)\n",
        "  model.compile(optimizer=opt,loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MAaxp2hqAR"
      },
      "source": [
        "def identity_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])     \n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def convolutional_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Processing Residue with conv(1,1)\n",
        "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])     \n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet34(shape, classes):\n",
        "    # Step 1 (Setup Input Layer)\n",
        "    x_input = tf.keras.layers.Input(shape)\n",
        "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
        "    # Step 2 (Initial Conv layer along with maxPool)\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "    # Define size of sub-blocks and initial filter size\n",
        "    block_layers = [3, 4, 6, 3]\n",
        "    filter_size = 64\n",
        "    # Step 3 Add the Resnet Blocks\n",
        "    for i in range(4):\n",
        "        if i == 0:\n",
        "            # For sub-block 1 Residual/Convolutional block not needed\n",
        "            for j in range(block_layers[i]):\n",
        "                x = identity_block(x, filter_size)\n",
        "        else:\n",
        "            # One Residual/Convolutional Block followed by Identity blocks\n",
        "            # The filter size will go on increasing by a factor of 2\n",
        "            filter_size = filter_size*2\n",
        "            x = convolutional_block(x, filter_size)\n",
        "            for j in range(block_layers[i] - 1):\n",
        "                x = identity_block(x, filter_size)\n",
        "    # Step 4 End Dense Network\n",
        "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaRAX4NsO-qR"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgsl1X29yf2k"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "def train_model_vgg16(X_train,y_train,X_test,y_test,epochs=10,batch_size=128):\n",
        "  \n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_vgg16', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 10)\n",
        "  ]\n",
        "  history=model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size,callbacks = callbacks, verbose = 1,validation_data=(X_test,y_test))\n",
        "  return history\n",
        "\n",
        "def train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=10,batch_size=64):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_standard_cnn', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 10)\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size=batch_size , callbacks = callbacks)\n",
        "  return history\n",
        "\n",
        "\n",
        "def train_model_resnet34(X_train,y_train,X_test,y_test,epochs=10):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_resnet50', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 10)\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size= 64 , callbacks = callbacks)\n",
        "  return history"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeJvjs7VO9-u"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6AWutrFy4V8"
      },
      "source": [
        "def make_prediction(model,X_test,index):\n",
        "\n",
        "  return model.predict(X_test(index))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UiQLmEn1vuV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6c0795e-064f-473b-82bf-57a2597f2bfb"
      },
      "source": [
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(1)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,1)\n",
        "model=define_model(image_shape,10)\n",
        "train_model(X_train,y_train,X_test,y_test)'''\n",
        "\n",
        "X_train,y_train,X_test,y_test=select_dataset(2)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar10(X_train,y_train,X_test,y_test,3)\n",
        "model=define_model_standard_cnn(image_shape,10)\n",
        "history = train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=50)\n",
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(2)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar100(X_train,y_train,X_test,y_test,3)\n",
        "model=Resnet50(image_shape,10)\n",
        "history=train_model_resnet50(X_train,y_train,X_test,y_test,epochs=100)'''\n",
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(3)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar100(X_train,y_train,X_test,y_test,3)\n",
        "model=ResNet34(image_shape,100)\n",
        "history=train_model_resnet34(X_train,y_train,X_test,y_test,epochs=100)'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n",
            "Epoch 1/50\n",
            "782/782 [==============================] - 19s 22ms/step - loss: 2.2002 - accuracy: 0.2010 - val_loss: 1.9072 - val_accuracy: 0.2995\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.29950, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 1.7906 - accuracy: 0.3464 - val_loss: 1.5734 - val_accuracy: 0.4333\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.29950 to 0.43330, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.5227 - accuracy: 0.4458 - val_loss: 1.3704 - val_accuracy: 0.5072\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.43330 to 0.50720, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.3715 - accuracy: 0.5078 - val_loss: 1.2473 - val_accuracy: 0.5630\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.50720 to 0.56300, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.2669 - accuracy: 0.5486 - val_loss: 1.1403 - val_accuracy: 0.6029\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.56300 to 0.60290, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.1746 - accuracy: 0.5821 - val_loss: 1.1398 - val_accuracy: 0.6040\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.60290 to 0.60400, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.1007 - accuracy: 0.6112 - val_loss: 1.1491 - val_accuracy: 0.5963\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.60400\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.0447 - accuracy: 0.6332 - val_loss: 0.9834 - val_accuracy: 0.6586\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.60400 to 0.65860, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.9906 - accuracy: 0.6520 - val_loss: 0.9627 - val_accuracy: 0.6652\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.65860 to 0.66520, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.9447 - accuracy: 0.6675 - val_loss: 0.9017 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.66520 to 0.68230, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.8949 - accuracy: 0.6858 - val_loss: 0.8441 - val_accuracy: 0.7074\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.68230 to 0.70740, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.8665 - accuracy: 0.6958 - val_loss: 0.9341 - val_accuracy: 0.6858\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.70740\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.8376 - accuracy: 0.7093 - val_loss: 0.8056 - val_accuracy: 0.7222\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.70740 to 0.72220, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.8038 - accuracy: 0.7191 - val_loss: 0.8318 - val_accuracy: 0.7158\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.72220\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.7744 - accuracy: 0.7295 - val_loss: 0.8032 - val_accuracy: 0.7195\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.72220\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.7567 - accuracy: 0.7330 - val_loss: 0.7980 - val_accuracy: 0.7236\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.72220 to 0.72360, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.7290 - accuracy: 0.7457 - val_loss: 0.7907 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.72360 to 0.72660, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.7058 - accuracy: 0.7537 - val_loss: 0.7279 - val_accuracy: 0.7556\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.72660 to 0.75560, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.6888 - accuracy: 0.7572 - val_loss: 0.7238 - val_accuracy: 0.7579\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.75560 to 0.75790, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6685 - accuracy: 0.7651 - val_loss: 0.7403 - val_accuracy: 0.7535\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.75790\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6555 - accuracy: 0.7716 - val_loss: 0.6896 - val_accuracy: 0.7656\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.75790 to 0.76560, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.6328 - accuracy: 0.7777 - val_loss: 0.6930 - val_accuracy: 0.7678\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.76560 to 0.76780, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6204 - accuracy: 0.7831 - val_loss: 0.6860 - val_accuracy: 0.7673\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.76780\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.6016 - accuracy: 0.7900 - val_loss: 0.6850 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.76780 to 0.77500, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5897 - accuracy: 0.7936 - val_loss: 0.6919 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.77500\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5757 - accuracy: 0.7969 - val_loss: 0.6800 - val_accuracy: 0.7727\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.77500\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5637 - accuracy: 0.8035 - val_loss: 0.6701 - val_accuracy: 0.7761\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.77500 to 0.77610, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5499 - accuracy: 0.8087 - val_loss: 0.6912 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.77610\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5404 - accuracy: 0.8107 - val_loss: 0.6772 - val_accuracy: 0.7799\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.77610 to 0.77990, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5327 - accuracy: 0.8127 - val_loss: 0.6633 - val_accuracy: 0.7874\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.77990 to 0.78740, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5188 - accuracy: 0.8158 - val_loss: 0.6956 - val_accuracy: 0.7768\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.78740\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5085 - accuracy: 0.8211 - val_loss: 0.7341 - val_accuracy: 0.7636\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.78740\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.4898 - accuracy: 0.8251 - val_loss: 0.6671 - val_accuracy: 0.7784\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.78740\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.4189 - accuracy: 0.8507 - val_loss: 0.6394 - val_accuracy: 0.8024\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.78740 to 0.80240, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3948 - accuracy: 0.8602 - val_loss: 0.6429 - val_accuracy: 0.8004\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.80240\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3934 - accuracy: 0.8605 - val_loss: 0.6417 - val_accuracy: 0.8008\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.80240\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3870 - accuracy: 0.8613 - val_loss: 0.6430 - val_accuracy: 0.8008\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.80240\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3788 - accuracy: 0.8656 - val_loss: 0.6410 - val_accuracy: 0.8018\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.80240\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3775 - accuracy: 0.8641 - val_loss: 0.6406 - val_accuracy: 0.8027\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.80240 to 0.80270, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3744 - accuracy: 0.8659 - val_loss: 0.6398 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.80270\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3764 - accuracy: 0.8662 - val_loss: 0.6389 - val_accuracy: 0.8028\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.80270 to 0.80280, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3738 - accuracy: 0.8666 - val_loss: 0.6401 - val_accuracy: 0.8017\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.80280\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3747 - accuracy: 0.8669 - val_loss: 0.6402 - val_accuracy: 0.8028\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.80280\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3698 - accuracy: 0.8688 - val_loss: 0.6416 - val_accuracy: 0.8038\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.80280 to 0.80380, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3663 - accuracy: 0.8701 - val_loss: 0.6410 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.80380\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3699 - accuracy: 0.8689 - val_loss: 0.6427 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.80380\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3655 - accuracy: 0.8711 - val_loss: 0.6421 - val_accuracy: 0.8023\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.80380\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3707 - accuracy: 0.8682 - val_loss: 0.6433 - val_accuracy: 0.8023\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.80380\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3716 - accuracy: 0.8673 - val_loss: 0.6424 - val_accuracy: 0.8013\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.80380\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3690 - accuracy: 0.8691 - val_loss: 0.6426 - val_accuracy: 0.8024\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.80380\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train,y_train,X_test,y_test=select_dataset(3)\\nX_train,y_train,X_test,y_test,image_shape=pre_processing_cifar100(X_train,y_train,X_test,y_test,3)\\nmodel=ResNet34(image_shape,100)\\nhistory=train_model_resnet34(X_train,y_train,X_test,y_test,epochs=100)'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nByF_LBZLjlT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "b11616b8-939f-4b3d-eab8-bdd0fde9b80d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Validation loss history')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6426149606704712 / Test accuracy: 0.8023999929428101\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOD9JcqI26C2"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCv-lOO9FiBM",
        "outputId": "9eed4058-e32f-41e9-fa3a-3aec11d16f65"
      },
      "source": [
        "\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-i94_t4bd/cleverhans_d34f3861d5154e969a832e649a7423cb\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-i94_t4bd/cleverhans_d34f3861d5154e969a832e649a7423cb\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.7/dist-packages (from cleverhans) (2.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (3.2.2)\n",
            "Requirement already satisfied: mnist in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.14.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.0.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.9)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.1.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "187nH2VJFjlj"
      },
      "source": [
        "\n",
        "cnn_model = model.load_weights('/content/best_model_standard_cnn')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5pRFJsb4_gg",
        "outputId": "e048d793-a7be-415c-dfe5-eec286d633ac"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "harxUb_H5XWk"
      },
      "source": [
        "\n",
        "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
        "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA6Ntk20qTgn"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}