{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Test_bench.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMq/yQQcBvZtySGcDTnUAQq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirath2205/Final-Year-Project/blob/Test_bench/Test_bench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcyH2uCmqDOG"
      },
      "source": [
        "import keras,os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D , Dropout\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50 , preprocess_input\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlBqJ6SIkZ0u",
        "outputId": "1df2412c-06a0-4130-c19e-f45ba2ad40c9"
      },
      "source": [
        "!pip install Keras-applications\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Keras-applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-applications) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-applications) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVVahuJ1t7HD"
      },
      "source": [
        "def select_dataset(index):\n",
        "\n",
        "  if(index==1):\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist\n",
        "\n",
        "  elif(index==2):\n",
        "    cifar_10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar_10\n",
        "  \n",
        "  elif(index==3):\n",
        "    cifar_100 = tf.keras.datasets.cifar100.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar_100\n",
        "    print(len(X_train))\n",
        "\n",
        "    \n",
        "  return X_train,y_train,X_test,y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQV52_6GvrRS"
      },
      "source": [
        "def pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,image_channel):\n",
        "  img_width = X_train.shape[1]\n",
        "  img_height = X_train.shape[2]\n",
        "  input_shape = (img_width, img_height, image_channel)\n",
        "  \n",
        "  # normalize data\n",
        "  X_train, X_test = X_train / 255, X_test / 255\n",
        "\n",
        "  # reshape input \n",
        "  X_train = X_train.reshape(X_train.shape[0], *input_shape)\n",
        "  X_test = X_test.reshape(X_test.shape[0], *input_shape)\n",
        "\n",
        "  # one-hot\n",
        "  y_train = tf.keras.utils.to_categorical(y_train)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "  return X_train,y_train,X_test,y_test,input_shape\n",
        "\n",
        "def pre_processing_cifar10(X_train,y_train,X_test,y_test,image_channel):\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "  img_width = X_train[0].shape[0]\n",
        "  img_height = X_train[0].shape[1]\n",
        "  image_channel = image_channel\n",
        "\n",
        "  input_shape=(img_width,img_height,image_channel) \n",
        "  print(input_shape)\n",
        "  return X_train,y_train,X_test,y_test,input_shape\n",
        "  \n",
        "def pre_processing_cifar100(X_train,y_train,X_test,y_test,image_channel):\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_train = preprocess_input(X_train)\n",
        "  X_test = preprocess_input(X_test)\n",
        "\n",
        "  y_train = keras.utils.to_categorical(y_train)\n",
        "  y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "  img_width = X_train[0].shape[0]\n",
        "  img_height = X_train[0].shape[1]\n",
        "  image_channel = image_channel\n",
        "\n",
        "  input_shape=(img_width,img_height,image_channel) \n",
        "  print(input_shape)\n",
        "  return X_train,y_train,X_test,y_test,input_shape"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDvpMVLzu3if"
      },
      "source": [
        "def define_model_vgg16(image_shape,total_classes):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(input_shape=image_shape,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=total_classes, activation=\"softmax\"))\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def define_model_standard_cnn(image_shape,total_classes):\n",
        "  initializer = tf.keras.initializers.HeUniform()\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32,(3,3), activation = 'relu',  padding = 'same', input_shape = image_shape))\n",
        "  model.add(Conv2D(32,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))  \n",
        "  model.add(Conv2D(64,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(Conv2D(64,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(128,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(Conv2D(128,(3,3), activation = 'relu',  padding = 'same'))\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation = 'relu'))\n",
        "  model.add(Dense(total_classes, activation = 'softmax'))\n",
        "  opt = keras.optimizers.SGD(learning_rate=0.001 , momentum=0.9)\n",
        "  model.compile(optimizer=opt,loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MAaxp2hqAR"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaRAX4NsO-qR"
      },
      "source": [
        "def identity_block(layer,f,nfilters):\n",
        "    Xshortcut=layer\n",
        "    F1,F2,F3=nfilters\n",
        "    layer=Conv2D(F1,(1,1),padding='valid')(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "    \n",
        "    layer=Conv2D(F2,(f,f),padding='same')(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "    \n",
        "    layer=Conv2D(F3,(1,1),padding='valid')(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    \n",
        "    layer=Add()([Xshortcut,layer])\n",
        "    layer=Activation('relu')(layer)\n",
        "    return(layer)\n",
        "\n",
        "def Conv_block(layer,f,nfilters,s=2):\n",
        "    Xshortcut=layer\n",
        "    F1,F2,F3=nfilters\n",
        "    layer=Conv2D(F1,(1,1),strides=(s,s))(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "    \n",
        "    layer=Conv2D(F2,(f,f),padding='same')(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "    \n",
        "    layer=Conv2D(F3,(1,1))(layer)\n",
        "    layer=BatchNormalization(axis=-1)(layer)\n",
        "    \n",
        "    Xshortcut=Conv2D(F3,(1,1),strides=(s,s))(Xshortcut)\n",
        "    Xshortcut=BatchNormalization(axis=-1)(Xshortcut)\n",
        "    \n",
        "    layer=Add()([Xshortcut,layer])\n",
        "    layer=Activation('relu')(layer)\n",
        "    return(layer)\n",
        "\n",
        "def Resnet50(img_shape,numclasses):\n",
        "    img_inp=Input(shape=img_shape,dtype=tf.float32)\n",
        "    X=ZeroPadding2D((3,3))(img_inp)\n",
        "    X=Conv2D(64,(7,7),strides=(2,2))(X)\n",
        "    X=BatchNormalization(axis=-1)(X)\n",
        "    X=Activation('relu')(X)\n",
        "    \n",
        "    X=MaxPooling2D((3,3),strides=(2,2),padding='same')(X)\n",
        "    X=Conv_block(X,3,[64,64,256],s=1)\n",
        "    X=identity_block(X,3,[64,64,256])\n",
        "    X=identity_block(X,3,[64,64,256])\n",
        "    \n",
        "    X=Conv_block(X,3,[128,128,512],s=2)\n",
        "    X=identity_block(X,3,[128,128,512])\n",
        "    X=identity_block(X,3,[128,128,512])\n",
        "    X=identity_block(X,3,[128,128,512])\n",
        "    \n",
        "    X=Conv_block(X,3,[256,256,1024],s=2)\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    X=identity_block(X,3,[256,256,1024])\n",
        "    \n",
        "    X=Conv_block(X,3,[512,512,2048],s=2)\n",
        "    X=identity_block(X,3,[512,512,2048])\n",
        "    X=identity_block(X,3,[512,512,2048])\n",
        "    \n",
        "    X=AveragePooling2D((7,7) , padding='same')(X)\n",
        "    \n",
        "    X=Flatten()(X)\n",
        "    X=Dense(numclasses,activation='softmax')(X)\n",
        "    model=Model(inputs=img_inp,outputs=X)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return(model)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgsl1X29yf2k"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "def train_model_vgg16(X_train,y_train,X_test,y_test,epochs=10,batch_size=256):\n",
        "  \n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_vgg16', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 )\n",
        "  ]\n",
        "  history=model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size,callbacks = callbacks, verbose = 1,validation_data=(X_test,y_test))\n",
        "  return history\n",
        "\n",
        "def train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=10,batch_size=64):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_standard_cnn', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 )\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size=batch_size , callbacks = callbacks)\n",
        "  return history\n",
        "\n",
        "def train_model_resnet50(X_train,y_train,X_test,y_test,epochs=10):\n",
        "  callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model_resnet50', monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 )\n",
        "  ]\n",
        "  history=model.fit(X_train , y_train , epochs = epochs , validation_data=(X_test,y_test),batch_size=32 , callbacks = callbacks)\n",
        "  return history"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeJvjs7VO9-u"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6AWutrFy4V8"
      },
      "source": [
        "def make_prediction(model,X_test,index):\n",
        "\n",
        "  return model.predict(X_test(index))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0UiQLmEn1vuV",
        "outputId": "e3ae0941-17b4-40d2-80d9-f05e955b9f35"
      },
      "source": [
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(1)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_fashion_mnist(X_train,y_train,X_test,y_test,1)\n",
        "model=define_model(image_shape,10)\n",
        "train_model(X_train,y_train,X_test,y_test)'''\n",
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(2)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar10(X_train,y_train,X_test,y_test,3)\n",
        "model=define_model_standard_cnn(image_shape,10)\n",
        "train_model_standard_cnn(X_train,y_train,X_test,y_test,epochs=75)'''\n",
        "\n",
        "'''X_train,y_train,X_test,y_test=select_dataset(3)\n",
        "X_train,y_train,X_test,y_test,image_shape=pre_processing_cifar100(X_train,y_train,X_test,y_test,3)\n",
        "model=Resnet50(image_shape,100)\n",
        "history=train_model_resnet50(X_train,y_train,X_test,y_test,epochs=100)'''\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n",
            "Epoch 1/75\n",
            "782/782 [==============================] - 19s 22ms/step - loss: 2.1687 - accuracy: 0.2175 - val_loss: 1.8917 - val_accuracy: 0.3248\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.32480, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 2/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.7922 - accuracy: 0.3434 - val_loss: 1.6457 - val_accuracy: 0.4157\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.32480 to 0.41570, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 3/75\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 1.5867 - accuracy: 0.4179 - val_loss: 1.4876 - val_accuracy: 0.4698\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.41570 to 0.46980, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 4/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.4267 - accuracy: 0.4848 - val_loss: 1.3268 - val_accuracy: 0.5377\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.46980 to 0.53770, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 5/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.2947 - accuracy: 0.5384 - val_loss: 1.1788 - val_accuracy: 0.5897\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.53770 to 0.58970, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 6/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.1974 - accuracy: 0.5743 - val_loss: 1.1182 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.58970 to 0.60340, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 7/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.1186 - accuracy: 0.6042 - val_loss: 1.0526 - val_accuracy: 0.6354\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.60340 to 0.63540, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 8/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.0437 - accuracy: 0.6335 - val_loss: 0.9713 - val_accuracy: 0.6582\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.63540 to 0.65820, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 9/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.9882 - accuracy: 0.6536 - val_loss: 0.9468 - val_accuracy: 0.6704\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.65820 to 0.67040, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 10/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.9350 - accuracy: 0.6724 - val_loss: 0.8652 - val_accuracy: 0.7018\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.67040 to 0.70180, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 11/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.8973 - accuracy: 0.6862 - val_loss: 0.8620 - val_accuracy: 0.6997\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.70180\n",
            "Epoch 12/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.8613 - accuracy: 0.6965 - val_loss: 0.8289 - val_accuracy: 0.7112\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.70180 to 0.71120, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 13/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.8281 - accuracy: 0.7112 - val_loss: 0.7723 - val_accuracy: 0.7360\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.71120 to 0.73600, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 14/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.8021 - accuracy: 0.7217 - val_loss: 0.7857 - val_accuracy: 0.7355\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.73600\n",
            "Epoch 15/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.7752 - accuracy: 0.7289 - val_loss: 0.7417 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.73600 to 0.75000, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 16/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.7475 - accuracy: 0.7363 - val_loss: 0.7712 - val_accuracy: 0.7372\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.75000\n",
            "Epoch 17/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.7319 - accuracy: 0.7421 - val_loss: 0.7163 - val_accuracy: 0.7582\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.75000 to 0.75820, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 18/75\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.7101 - accuracy: 0.7521 - val_loss: 0.7130 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.75820\n",
            "Epoch 19/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6845 - accuracy: 0.7620 - val_loss: 0.6851 - val_accuracy: 0.7688\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.75820 to 0.76880, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 20/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6654 - accuracy: 0.7667 - val_loss: 0.7217 - val_accuracy: 0.7544\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.76880\n",
            "Epoch 21/75\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.6524 - accuracy: 0.7713 - val_loss: 0.6905 - val_accuracy: 0.7687\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.76880\n",
            "Epoch 22/75\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.6359 - accuracy: 0.7773 - val_loss: 0.6956 - val_accuracy: 0.7691\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.76880 to 0.76910, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 23/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5568 - accuracy: 0.8060 - val_loss: 0.6389 - val_accuracy: 0.7853\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.76910 to 0.78530, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 24/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5359 - accuracy: 0.8101 - val_loss: 0.6339 - val_accuracy: 0.7876\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.78530 to 0.78760, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 25/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5317 - accuracy: 0.8138 - val_loss: 0.6294 - val_accuracy: 0.7912\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.78760 to 0.79120, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 26/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5262 - accuracy: 0.8151 - val_loss: 0.6330 - val_accuracy: 0.7876\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.79120\n",
            "Epoch 27/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5230 - accuracy: 0.8158 - val_loss: 0.6258 - val_accuracy: 0.7901\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.79120\n",
            "Epoch 28/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5219 - accuracy: 0.8158 - val_loss: 0.6230 - val_accuracy: 0.7926\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.79120 to 0.79260, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 29/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5177 - accuracy: 0.8168 - val_loss: 0.6224 - val_accuracy: 0.7929\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.79260 to 0.79290, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 30/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5147 - accuracy: 0.8164 - val_loss: 0.6232 - val_accuracy: 0.7911\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.79290\n",
            "Epoch 31/75\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5097 - accuracy: 0.8216 - val_loss: 0.6160 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.79290\n",
            "Epoch 32/75\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5076 - accuracy: 0.8227 - val_loss: 0.6202 - val_accuracy: 0.7918\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.79290\n",
            "Epoch 33/75\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5073 - accuracy: 0.8192 - val_loss: 0.6206 - val_accuracy: 0.7923\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.79290\n",
            "Epoch 34/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5007 - accuracy: 0.8224 - val_loss: 0.6192 - val_accuracy: 0.7924\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.79290\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 35/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.4959 - accuracy: 0.8261 - val_loss: 0.6148 - val_accuracy: 0.7950\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.79290 to 0.79500, saving model to best_model_standard_cnn\n",
            "INFO:tensorflow:Assets written to: best_model_standard_cnn/assets\n",
            "Epoch 36/75\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.4926 - accuracy: 0.8260 - val_loss: 0.6156 - val_accuracy: 0.7949\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.79500\n",
            "Epoch 37/75\n",
            "679/782 [=========================>....] - ETA: 2s - loss: 0.4886 - accuracy: 0.8269"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8fc9d4772003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_processing_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefine_model_standard_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_model_standard_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m '''X_train,y_train,X_test,y_test=select_dataset(3)\n",
            "\u001b[0;32m<ipython-input-7-a762734ea230>\u001b[0m in \u001b[0;36mtrain_model_standard_cnn\u001b[0;34m(X_train, y_train, X_test, y_test, epochs, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   ]\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nByF_LBZLjlT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Validation loss history')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOD9JcqI26C2"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}