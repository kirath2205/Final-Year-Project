{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirath2205/Final-Year-Project/blob/main/Inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wT9vgvoPA5LN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-applications"
      ],
      "metadata": {
        "id": "Yzs3HWQuBj9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7c1172-e96c-461c-fce8-5992937899fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Keras-applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-applications) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-applications) (1.5.2)\n",
            "Installing collected packages: Keras-applications\n",
            "Successfully installed Keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D , UpSampling3D\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.datasets import cifar100,cifar10,fashion_mnist\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.transform import resize\n",
        "from keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input , decode_predictions\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "CtDTfJMaBKTx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_dataset(index=1): #1 for cifar10 , 2 for cifar100 , 3 for fashion mnist\n",
        "  if(index == 1):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    channel = 3\n",
        "    num_classes = 10\n",
        "  if(index == 2):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "    num_classes = 100\n",
        "    channel = 3\n",
        "  if(index == 3):\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "    x_train = x_train.reshape((60000, 28, 28, 1))\n",
        "    x_test =  x_test.reshape((10000, 28, 28, 1))\n",
        "    num_classes = 10\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "    channel = 1\n",
        "    return (x_train , y_train , x_test , y_test , num_classes , channel)\n",
        "\n",
        "  #Pre-process the data\n",
        "  x_train = preprocess_input(x_train)\n",
        "  x_test = preprocess_input(x_test)\n",
        "\n",
        "  datagen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
        "  datagen.fit(x_train)\n",
        "  y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "  y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "  return (x_train , y_train , x_test , y_test , num_classes , channel , datagen)"
      ],
      "metadata": {
        "id": "al1qQJxOBM1C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Inception(num_classes , channel=3):\n",
        "  if(channel == 3):\n",
        "    inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(160, 160, 3))\n",
        "  else:\n",
        "    inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(112, 112, 3))\n",
        "\n",
        "  for layer in inception_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "      layer.trainable = True\n",
        "    else:\n",
        "      layer.trainable = False\n",
        "  model = Sequential()\n",
        "  if(channel==1):\n",
        "    model.add(UpSampling3D((4,4,3)))\n",
        "  else:\n",
        "    model.add(UpSampling2D((5,5)))\n",
        "  model.add(inception_model)\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(.25))\n",
        "  #model.add(BatchNormalization())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(.25))\n",
        "  #model.add(BatchNormalization())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  #model.add(Dropout(.25))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "8zq0WGLtB0p_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "x_train , y_train , x_test , y_test , num_classes ,channel , datagen = select_dataset(index)\n",
        "model = Inception(num_classes,channel)\n",
        "model_name = 'inception_cifar10'\n",
        "model_path = '/content/inception_cifar10.h5'"
      ],
      "metadata": {
        "id": "Sb309y2jmmYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 2\n",
        "x_train , y_train , x_test , y_test , num_classes ,channel , datagen = select_dataset(index)\n",
        "model = Inception(num_classes,channel)\n",
        "model_name = 'inception_cifar100'\n",
        "model_path = '/content/inception_cifar100.h5'"
      ],
      "metadata": {
        "id": "qMm7-78JnVa9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 3\n",
        "x_train , y_train , x_test , y_test , num_classes ,channel  = select_dataset(index)\n",
        "model = Inception(num_classes,channel)\n",
        "model_name = 'inception_mnist'\n",
        "model_path = '/content/inception_mnist.h5'"
      ],
      "metadata": {
        "id": "4jlkd0p1B4hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "callbacks = [ \n",
        "    tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau( factor = 0.5, patience = 3, min_lr = 0.000001, verbose = 1 ),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , patience = 5)\n",
        "  ]\n",
        "if(channel == 3):\n",
        "  history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=batch_size),\n",
        "                                  steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                                  epochs=50,\n",
        "                                  validation_data=(x_test, y_test),\n",
        "                                  callbacks = callbacks)\n",
        "\n",
        "  model.save(model_path)\n",
        "else:\n",
        "  history = model.fit(x_train , y_train , batch_size=batch_size ,steps_per_epoch=x_train.shape[0] // batch_size, epochs=50, validation_data=(x_test, y_test),callbacks=callbacks)\n",
        "  model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtmcDNu1B6ss",
        "outputId": "84981c52-5620-4ea3-e46a-7ba5fd7cc7d2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 3.6740 - accuracy: 0.1635\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.37660, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 327s 806ms/step - loss: 3.6740 - accuracy: 0.1635 - val_loss: 2.3522 - val_accuracy: 0.3766 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 2.6588 - accuracy: 0.3218\n",
            "Epoch 00002: val_accuracy improved from 0.37660 to 0.47640, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 312s 801ms/step - loss: 2.6588 - accuracy: 0.3218 - val_loss: 1.9343 - val_accuracy: 0.4764 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 2.3023 - accuracy: 0.3978\n",
            "Epoch 00003: val_accuracy improved from 0.47640 to 0.52380, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 312s 800ms/step - loss: 2.3023 - accuracy: 0.3978 - val_loss: 1.7077 - val_accuracy: 0.5238 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 2.0593 - accuracy: 0.4514\n",
            "Epoch 00004: val_accuracy improved from 0.52380 to 0.56090, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 312s 801ms/step - loss: 2.0593 - accuracy: 0.4514 - val_loss: 1.5564 - val_accuracy: 0.5609 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.9039 - accuracy: 0.4865\n",
            "Epoch 00005: val_accuracy improved from 0.56090 to 0.58330, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 312s 800ms/step - loss: 1.9039 - accuracy: 0.4865 - val_loss: 1.4641 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.7742 - accuracy: 0.5140\n",
            "Epoch 00006: val_accuracy improved from 0.58330 to 0.59660, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 310s 796ms/step - loss: 1.7742 - accuracy: 0.5140 - val_loss: 1.4168 - val_accuracy: 0.5966 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.6905 - accuracy: 0.5364\n",
            "Epoch 00007: val_accuracy improved from 0.59660 to 0.60910, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 310s 796ms/step - loss: 1.6905 - accuracy: 0.5364 - val_loss: 1.3518 - val_accuracy: 0.6091 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.6000 - accuracy: 0.5576\n",
            "Epoch 00008: val_accuracy improved from 0.60910 to 0.63500, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 311s 797ms/step - loss: 1.6000 - accuracy: 0.5576 - val_loss: 1.2704 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.5308 - accuracy: 0.5768\n",
            "Epoch 00009: val_accuracy improved from 0.63500 to 0.64060, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 323s 829ms/step - loss: 1.5308 - accuracy: 0.5768 - val_loss: 1.2478 - val_accuracy: 0.6406 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.4773 - accuracy: 0.5889\n",
            "Epoch 00010: val_accuracy improved from 0.64060 to 0.64850, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 310s 796ms/step - loss: 1.4773 - accuracy: 0.5889 - val_loss: 1.2125 - val_accuracy: 0.6485 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.4367 - accuracy: 0.5993\n",
            "Epoch 00011: val_accuracy improved from 0.64850 to 0.66230, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 323s 828ms/step - loss: 1.4367 - accuracy: 0.5993 - val_loss: 1.1784 - val_accuracy: 0.6623 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.3753 - accuracy: 0.6147\n",
            "Epoch 00012: val_accuracy improved from 0.66230 to 0.66280, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 311s 797ms/step - loss: 1.3753 - accuracy: 0.6147 - val_loss: 1.1630 - val_accuracy: 0.6628 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.3378 - accuracy: 0.6236\n",
            "Epoch 00013: val_accuracy improved from 0.66280 to 0.66730, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 311s 796ms/step - loss: 1.3378 - accuracy: 0.6236 - val_loss: 1.1518 - val_accuracy: 0.6673 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.3025 - accuracy: 0.6325\n",
            "Epoch 00014: val_accuracy improved from 0.66730 to 0.66920, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 310s 795ms/step - loss: 1.3025 - accuracy: 0.6325 - val_loss: 1.1426 - val_accuracy: 0.6692 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.2601 - accuracy: 0.6425\n",
            "Epoch 00015: val_accuracy improved from 0.66920 to 0.68140, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 311s 796ms/step - loss: 1.2601 - accuracy: 0.6425 - val_loss: 1.1089 - val_accuracy: 0.6814 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.2301 - accuracy: 0.6517\n",
            "Epoch 00016: val_accuracy did not improve from 0.68140\n",
            "390/390 [==============================] - 309s 793ms/step - loss: 1.2301 - accuracy: 0.6517 - val_loss: 1.1219 - val_accuracy: 0.6767 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.2205 - accuracy: 0.6530\n",
            "Epoch 00017: val_accuracy did not improve from 0.68140\n",
            "390/390 [==============================] - 310s 794ms/step - loss: 1.2205 - accuracy: 0.6530 - val_loss: 1.1084 - val_accuracy: 0.6790 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.1874 - accuracy: 0.6618\n",
            "Epoch 00018: val_accuracy improved from 0.68140 to 0.68670, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 311s 797ms/step - loss: 1.1874 - accuracy: 0.6618 - val_loss: 1.0833 - val_accuracy: 0.6867 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.1581 - accuracy: 0.6693\n",
            "Epoch 00019: val_accuracy improved from 0.68670 to 0.68690, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 313s 802ms/step - loss: 1.1581 - accuracy: 0.6693 - val_loss: 1.0915 - val_accuracy: 0.6869 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.1360 - accuracy: 0.6747\n",
            "Epoch 00020: val_accuracy improved from 0.68690 to 0.69170, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 326s 835ms/step - loss: 1.1360 - accuracy: 0.6747 - val_loss: 1.0858 - val_accuracy: 0.6917 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.1117 - accuracy: 0.6836\n",
            "Epoch 00021: val_accuracy improved from 0.69170 to 0.69750, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 313s 802ms/step - loss: 1.1117 - accuracy: 0.6836 - val_loss: 1.0614 - val_accuracy: 0.6975 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.0908 - accuracy: 0.6851\n",
            "Epoch 00022: val_accuracy improved from 0.69750 to 0.69930, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 313s 802ms/step - loss: 1.0908 - accuracy: 0.6851 - val_loss: 1.0580 - val_accuracy: 0.6993 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.0705 - accuracy: 0.6929\n",
            "Epoch 00023: val_accuracy did not improve from 0.69930\n",
            "390/390 [==============================] - 312s 800ms/step - loss: 1.0705 - accuracy: 0.6929 - val_loss: 1.0429 - val_accuracy: 0.6972 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.0497 - accuracy: 0.6978\n",
            "Epoch 00024: val_accuracy improved from 0.69930 to 0.70390, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 313s 803ms/step - loss: 1.0497 - accuracy: 0.6978 - val_loss: 1.0342 - val_accuracy: 0.7039 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.0338 - accuracy: 0.7040\n",
            "Epoch 00025: val_accuracy did not improve from 0.70390\n",
            "390/390 [==============================] - 312s 799ms/step - loss: 1.0338 - accuracy: 0.7040 - val_loss: 1.0394 - val_accuracy: 0.7036 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.0200 - accuracy: 0.7030\n",
            "Epoch 00026: val_accuracy did not improve from 0.70390\n",
            "390/390 [==============================] - 324s 831ms/step - loss: 1.0200 - accuracy: 0.7030 - val_loss: 1.0575 - val_accuracy: 0.7009 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.9968 - accuracy: 0.7097\n",
            "Epoch 00027: val_accuracy did not improve from 0.70390\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "390/390 [==============================] - 312s 800ms/step - loss: 0.9968 - accuracy: 0.7097 - val_loss: 1.0437 - val_accuracy: 0.7037 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.9480 - accuracy: 0.7251\n",
            "Epoch 00028: val_accuracy improved from 0.70390 to 0.71210, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 322s 825ms/step - loss: 0.9480 - accuracy: 0.7251 - val_loss: 1.0050 - val_accuracy: 0.7121 - lr: 5.0000e-04\n",
            "Epoch 29/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.9175 - accuracy: 0.7336\n",
            "Epoch 00029: val_accuracy improved from 0.71210 to 0.71450, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 325s 834ms/step - loss: 0.9175 - accuracy: 0.7336 - val_loss: 1.0120 - val_accuracy: 0.7145 - lr: 5.0000e-04\n",
            "Epoch 30/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.9048 - accuracy: 0.7377\n",
            "Epoch 00030: val_accuracy did not improve from 0.71450\n",
            "390/390 [==============================] - 325s 832ms/step - loss: 0.9048 - accuracy: 0.7377 - val_loss: 1.0133 - val_accuracy: 0.7145 - lr: 5.0000e-04\n",
            "Epoch 31/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.8914 - accuracy: 0.7415\n",
            "Epoch 00031: val_accuracy improved from 0.71450 to 0.71520, saving model to /content/inception_cifar100.h5\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "390/390 [==============================] - 313s 803ms/step - loss: 0.8914 - accuracy: 0.7415 - val_loss: 1.0172 - val_accuracy: 0.7152 - lr: 5.0000e-04\n",
            "Epoch 32/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.8717 - accuracy: 0.7463\n",
            "Epoch 00032: val_accuracy improved from 0.71520 to 0.71900, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 313s 803ms/step - loss: 0.8717 - accuracy: 0.7463 - val_loss: 0.9998 - val_accuracy: 0.7190 - lr: 2.5000e-04\n",
            "Epoch 33/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.8528 - accuracy: 0.7532\n",
            "Epoch 00033: val_accuracy improved from 0.71900 to 0.71980, saving model to /content/inception_cifar100.h5\n",
            "390/390 [==============================] - 326s 835ms/step - loss: 0.8528 - accuracy: 0.7532 - val_loss: 1.0096 - val_accuracy: 0.7198 - lr: 2.5000e-04\n",
            "Epoch 34/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.8452 - accuracy: 0.7542\n",
            "Epoch 00034: val_accuracy did not improve from 0.71980\n",
            "390/390 [==============================] - 312s 800ms/step - loss: 0.8452 - accuracy: 0.7542 - val_loss: 1.0126 - val_accuracy: 0.7173 - lr: 2.5000e-04\n",
            "Epoch 35/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.8221 - accuracy: 0.7604\n",
            "Epoch 00035: val_accuracy did not improve from 0.71980\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "390/390 [==============================] - 311s 798ms/step - loss: 0.8221 - accuracy: 0.7604 - val_loss: 1.0071 - val_accuracy: 0.7160 - lr: 2.5000e-04\n",
            "Epoch 36/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.8223 - accuracy: 0.7606\n",
            "Epoch 00036: val_accuracy did not improve from 0.71980\n",
            "390/390 [==============================] - 310s 794ms/step - loss: 0.8223 - accuracy: 0.7606 - val_loss: 1.0028 - val_accuracy: 0.7193 - lr: 1.2500e-04\n",
            "Epoch 37/50\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.8103 - accuracy: 0.7648\n",
            "Epoch 00037: val_accuracy did not improve from 0.71980\n",
            "390/390 [==============================] - 322s 826ms/step - loss: 0.8103 - accuracy: 0.7648 - val_loss: 1.0031 - val_accuracy: 0.7193 - lr: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lKis1belCjmY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}